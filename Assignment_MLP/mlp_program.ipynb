{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVTUa6LZlGbq",
        "colab_type": "code",
        "outputId": "9073bcaa-1654-4b76-d28b-caa8ea212cd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOOCWiWuu7Iw",
        "colab_type": "code",
        "outputId": "4ca51c4c-30af-4f39-bff8-1dd3b309801a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdCKsynT5r2C",
        "colab_type": "code",
        "outputId": "34843460-60e9-4166-a635-9c0bd09434e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#reading the dataset from csv file\n",
        "def read_data(file):\n",
        "    data = pd.read_csv(file, header=None , index_col=None)\n",
        "    return data\n",
        "data = read_data('/content/drive/My Drive/MLP_Assignment/bank.csv')\n",
        "data.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.62160</td>\n",
              "      <td>8.6661</td>\n",
              "      <td>-2.8073</td>\n",
              "      <td>-0.44699</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.54590</td>\n",
              "      <td>8.1674</td>\n",
              "      <td>-2.4586</td>\n",
              "      <td>-1.46210</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.86600</td>\n",
              "      <td>-2.6383</td>\n",
              "      <td>1.9242</td>\n",
              "      <td>0.10645</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.45660</td>\n",
              "      <td>9.5228</td>\n",
              "      <td>-4.0112</td>\n",
              "      <td>-3.59440</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.32924</td>\n",
              "      <td>-4.4552</td>\n",
              "      <td>4.5718</td>\n",
              "      <td>-0.98880</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         0       1       2        3  4\n",
              "0  3.62160  8.6661 -2.8073 -0.44699  0\n",
              "1  4.54590  8.1674 -2.4586 -1.46210  0\n",
              "2  3.86600 -2.6383  1.9242  0.10645  0\n",
              "3  3.45660  9.5228 -4.0112 -3.59440  0\n",
              "4  0.32924 -4.4552  4.5718 -0.98880  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rh3P3ipc5wNg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#shuffling and splitting of the dataset\n",
        "def split_data(data):\n",
        "    df = pd.DataFrame(data)\n",
        "    #shuffle the dataset\n",
        "    df = df.sample(frac=1)\n",
        "    #split the dataset\n",
        "    split = np.random.rand(len(df)) < 0.7\n",
        "    train = np.asmatrix(df[split], dtype = 'float64')\n",
        "    test = np.asmatrix(df[~split], dtype = 'float64')\n",
        "    X_train = train[:, :-1]\n",
        "    y_train = train[:, -1]\n",
        "    X_test = test[:, :-1]\n",
        "    y_test = test[:,-1]\n",
        "    return X_train,y_train,X_test,y_test\n",
        "X_train,y_train,X_test,y_test = split_data(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7NaB0L46YaZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#initializing params\n",
        "alpha = 0.7\n",
        "epoch = 100\n",
        "W = np.zeros(X_train.shape[1]+1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0JXs9josyx0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#activation function\n",
        "def activation(z):\n",
        "        if z>=0:\n",
        "            return 1\n",
        "        else:\n",
        "            return 0   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Chqyq4s5tmB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " #prediction function\n",
        " def predict(x):\n",
        "    z = np.dot(x, W[1:]) + W[0]\n",
        "    g = activation(z)\n",
        "    return g"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlZw8sfe5weh",
        "colab_type": "code",
        "outputId": "92e0367a-b7b2-404f-8ed3-3c392e4eff4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        " #training to learn the weights\n",
        " def train(X_train, y_train):\n",
        "        loss_train = []\n",
        "        epochs = range(1,epoch+1)\n",
        "        for i in range(epoch):\n",
        "            correct = 0\n",
        "            for x, y in zip(X_train, y_train):\n",
        "                prediction = predict(x)\n",
        "                y = np.array(y)[0][0]\n",
        "                x = np.array(x)[0]\n",
        "                error = y - prediction\n",
        "                actual_value = int(y)\n",
        "                if actual_value == prediction:\n",
        "                  correct += 1\n",
        "                W[1:] += alpha * error * x[0]\n",
        "                W[0] += alpha * error\n",
        "            training_accuracy =  correct/float(X_train.shape[0])*100.0      \n",
        "            loss_train.append(training_accuracy)\n",
        "            print(\"epoch:\"+str(i)+\"  weight:\"+str(W)+\"  learning rate:\"+str(alpha)+\"  Training Accuracy:\"+str(training_accuracy))\n",
        "        plt.plot(epochs, loss_train, 'g', label='Training loss')        \n",
        "        plt.xlim(0,epoch)\n",
        "        plt.title('Training loss')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "train(X_train, y_train)            "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:0  weight:[ 17.5        -33.03470835 -33.03470835 -33.03470835 -33.03470835]  learning rate:0.7  Training Accuracy:94.35897435897435\n",
            "epoch:1  weight:[ 32.9       -58.1459207 -58.1459207 -58.1459207 -58.1459207]  learning rate:0.7  Training Accuracy:95.07692307692308\n",
            "epoch:2  weight:[ 46.2        -77.94287305 -77.94287305 -77.94287305 -77.94287305]  learning rate:0.7  Training Accuracy:95.38461538461539\n",
            "epoch:3  weight:[ 58.8       -94.6757154 -94.6757154 -94.6757154 -94.6757154]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:4  weight:[  70.7        -110.11474775 -110.11474775 -110.11474775 -110.11474775]  learning rate:0.7  Training Accuracy:95.58974358974359\n",
            "epoch:5  weight:[  82.6       -125.5537801 -125.5537801 -125.5537801 -125.5537801]  learning rate:0.7  Training Accuracy:95.58974358974359\n",
            "epoch:6  weight:[  93.8        -141.48680245 -141.48680245 -141.48680245 -141.48680245]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:7  weight:[ 105.        -157.4198248 -157.4198248 -157.4198248 -157.4198248]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:8  weight:[ 116.2        -173.35284715 -173.35284715 -173.35284715 -173.35284715]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:9  weight:[ 127.4       -189.2858695 -189.2858695 -189.2858695 -189.2858695]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:10  weight:[ 138.6        -205.21889185 -205.21889185 -205.21889185 -205.21889185]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:11  weight:[ 149.1       -219.3725842 -219.3725842 -219.3725842 -219.3725842]  learning rate:0.7  Training Accuracy:95.58974358974359\n",
            "epoch:12  weight:[ 158.9        -231.67274655 -231.67274655 -231.67274655 -231.67274655]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:13  weight:[ 168.7       -243.9729089 -243.9729089 -243.9729089 -243.9729089]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:14  weight:[ 177.1        -254.56955825 -254.56955825 -254.56955825 -254.56955825]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:15  weight:[ 185.5       -265.1662076 -265.1662076 -265.1662076 -265.1662076]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:16  weight:[ 193.9        -275.76285695 -275.76285695 -275.76285695 -275.76285695]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:17  weight:[ 202.3       -286.3595063 -286.3595063 -286.3595063 -286.3595063]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:18  weight:[ 210.7        -296.95615565 -296.95615565 -296.95615565 -296.95615565]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:19  weight:[ 219.1      -307.552805 -307.552805 -307.552805 -307.552805]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:20  weight:[ 227.5        -318.14945435 -318.14945435 -318.14945435 -318.14945435]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:21  weight:[ 235.9       -328.7461037 -328.7461037 -328.7461037 -328.7461037]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:22  weight:[ 244.3        -339.34275305 -339.34275305 -339.34275305 -339.34275305]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:23  weight:[ 252.7       -349.9394024 -349.9394024 -349.9394024 -349.9394024]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:24  weight:[ 261.1        -360.53605175 -360.53605175 -360.53605175 -360.53605175]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:25  weight:[ 268.8       -373.4895311 -373.4895311 -373.4895311 -373.4895311]  learning rate:0.7  Training Accuracy:95.38461538461539\n",
            "epoch:26  weight:[ 277.2        -384.08618045 -384.08618045 -384.08618045 -384.08618045]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:27  weight:[ 285.6       -394.6828298 -394.6828298 -394.6828298 -394.6828298]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:28  weight:[ 294.         -405.27947915 -405.27947915 -405.27947915 -405.27947915]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:29  weight:[ 301.7       -418.2329585 -418.2329585 -418.2329585 -418.2329585]  learning rate:0.7  Training Accuracy:95.38461538461539\n",
            "epoch:30  weight:[ 310.1        -428.82960785 -428.82960785 -428.82960785 -428.82960785]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:31  weight:[ 318.5       -439.4262572 -439.4262572 -439.4262572 -439.4262572]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:32  weight:[ 326.2        -452.37973655 -452.37973655 -452.37973655 -452.37973655]  learning rate:0.7  Training Accuracy:95.38461538461539\n",
            "epoch:33  weight:[ 334.6       -462.9763859 -462.9763859 -462.9763859 -462.9763859]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:34  weight:[ 343.         -473.57303525 -473.57303525 -473.57303525 -473.57303525]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:35  weight:[ 351.4       -484.1696846 -484.1696846 -484.1696846 -484.1696846]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:36  weight:[ 359.1        -497.12316395 -497.12316395 -497.12316395 -497.12316395]  learning rate:0.7  Training Accuracy:95.38461538461539\n",
            "epoch:37  weight:[ 367.5       -507.7198133 -507.7198133 -507.7198133 -507.7198133]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:38  weight:[ 375.9        -518.31646265 -518.31646265 -518.31646265 -518.31646265]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:39  weight:[ 384.3      -528.913112 -528.913112 -528.913112 -528.913112]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:40  weight:[ 392.         -541.86659135 -541.86659135 -541.86659135 -541.86659135]  learning rate:0.7  Training Accuracy:95.38461538461539\n",
            "epoch:41  weight:[ 400.4       -552.4632407 -552.4632407 -552.4632407 -552.4632407]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:42  weight:[ 408.8        -563.05989005 -563.05989005 -563.05989005 -563.05989005]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:43  weight:[ 417.2       -573.6565394 -573.6565394 -573.6565394 -573.6565394]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:44  weight:[ 424.9        -586.61001875 -586.61001875 -586.61001875 -586.61001875]  learning rate:0.7  Training Accuracy:95.38461538461539\n",
            "epoch:45  weight:[ 433.3       -597.2066681 -597.2066681 -597.2066681 -597.2066681]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:46  weight:[ 441.7        -607.80331745 -607.80331745 -607.80331745 -607.80331745]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:47  weight:[ 450.1       -618.3999668 -618.3999668 -618.3999668 -618.3999668]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:48  weight:[ 457.8        -631.35344615 -631.35344615 -631.35344615 -631.35344615]  learning rate:0.7  Training Accuracy:95.38461538461539\n",
            "epoch:49  weight:[ 466.2       -641.9500955 -641.9500955 -641.9500955 -641.9500955]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:50  weight:[ 474.6        -652.54674485 -652.54674485 -652.54674485 -652.54674485]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:51  weight:[ 482.3       -665.5002242 -665.5002242 -665.5002242 -665.5002242]  learning rate:0.7  Training Accuracy:95.38461538461539\n",
            "epoch:52  weight:[ 490.7        -676.09687355 -676.09687355 -676.09687355 -676.09687355]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:53  weight:[ 499.1       -686.6935229 -686.6935229 -686.6935229 -686.6935229]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:54  weight:[ 507.5        -697.29017225 -697.29017225 -697.29017225 -697.29017225]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:55  weight:[ 515.2       -710.2436516 -710.2436516 -710.2436516 -710.2436516]  learning rate:0.7  Training Accuracy:95.38461538461539\n",
            "epoch:56  weight:[ 523.6        -720.84030095 -720.84030095 -720.84030095 -720.84030095]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:57  weight:[ 532.        -731.4369503 -731.4369503 -731.4369503 -731.4369503]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:58  weight:[ 540.4        -742.03359965 -742.03359965 -742.03359965 -742.03359965]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:59  weight:[ 548.1      -754.987079 -754.987079 -754.987079 -754.987079]  learning rate:0.7  Training Accuracy:95.38461538461539\n",
            "epoch:60  weight:[ 556.5        -765.58372835 -765.58372835 -765.58372835 -765.58372835]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:61  weight:[ 564.9       -776.1803777 -776.1803777 -776.1803777 -776.1803777]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:62  weight:[ 573.3        -786.77702705 -786.77702705 -786.77702705 -786.77702705]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:63  weight:[ 581.        -799.7305064 -799.7305064 -799.7305064 -799.7305064]  learning rate:0.7  Training Accuracy:95.38461538461539\n",
            "epoch:64  weight:[ 589.4        -810.32715575 -810.32715575 -810.32715575 -810.32715575]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:65  weight:[ 597.8       -820.9238051 -820.9238051 -820.9238051 -820.9238051]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:66  weight:[ 605.5        -833.87728445 -833.87728445 -833.87728445 -833.87728445]  learning rate:0.7  Training Accuracy:95.38461538461539\n",
            "epoch:67  weight:[ 613.9       -844.4739338 -844.4739338 -844.4739338 -844.4739338]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:68  weight:[ 622.3        -855.07058315 -855.07058315 -855.07058315 -855.07058315]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:69  weight:[ 630.7       -865.6672325 -865.6672325 -865.6672325 -865.6672325]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:70  weight:[ 638.4        -878.62071185 -878.62071185 -878.62071185 -878.62071185]  learning rate:0.7  Training Accuracy:95.38461538461539\n",
            "epoch:71  weight:[ 646.8       -889.2173612 -889.2173612 -889.2173612 -889.2173612]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:72  weight:[ 655.2        -899.81401055 -899.81401055 -899.81401055 -899.81401055]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:73  weight:[ 663.6       -910.4106599 -910.4106599 -910.4106599 -910.4106599]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:74  weight:[ 671.3        -923.36413925 -923.36413925 -923.36413925 -923.36413925]  learning rate:0.7  Training Accuracy:95.38461538461539\n",
            "epoch:75  weight:[ 679.7       -933.9607886 -933.9607886 -933.9607886 -933.9607886]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:76  weight:[ 688.1        -944.55743795 -944.55743795 -944.55743795 -944.55743795]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:77  weight:[ 696.5       -955.1540873 -955.1540873 -955.1540873 -955.1540873]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:78  weight:[ 704.2        -968.10756665 -968.10756665 -968.10756665 -968.10756665]  learning rate:0.7  Training Accuracy:95.38461538461539\n",
            "epoch:79  weight:[ 712.6      -978.704216 -978.704216 -978.704216 -978.704216]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:80  weight:[ 721.         -989.30086535 -989.30086535 -989.30086535 -989.30086535]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:81  weight:[ 729.4       -999.8975147 -999.8975147 -999.8975147 -999.8975147]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:82  weight:[  737.1        -1012.85099405 -1012.85099405 -1012.85099405\n",
            " -1012.85099405]  learning rate:0.7  Training Accuracy:95.38461538461539\n",
            "epoch:83  weight:[  745.5       -1023.4476434 -1023.4476434 -1023.4476434 -1023.4476434]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:84  weight:[  753.9        -1034.04429275 -1034.04429275 -1034.04429275\n",
            " -1034.04429275]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:85  weight:[  761.6       -1046.9977721 -1046.9977721 -1046.9977721 -1046.9977721]  learning rate:0.7  Training Accuracy:95.38461538461539\n",
            "epoch:86  weight:[  770.         -1057.59442145 -1057.59442145 -1057.59442145\n",
            " -1057.59442145]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:87  weight:[  778.4       -1068.1910708 -1068.1910708 -1068.1910708 -1068.1910708]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:88  weight:[  786.8        -1078.78772015 -1078.78772015 -1078.78772015\n",
            " -1078.78772015]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:89  weight:[  794.5       -1091.7411995 -1091.7411995 -1091.7411995 -1091.7411995]  learning rate:0.7  Training Accuracy:95.38461538461539\n",
            "epoch:90  weight:[  802.9        -1102.33784885 -1102.33784885 -1102.33784885\n",
            " -1102.33784885]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:91  weight:[  811.3       -1112.9344982 -1112.9344982 -1112.9344982 -1112.9344982]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:92  weight:[  819.7        -1123.53114755 -1123.53114755 -1123.53114755\n",
            " -1123.53114755]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:93  weight:[  827.4       -1136.4846269 -1136.4846269 -1136.4846269 -1136.4846269]  learning rate:0.7  Training Accuracy:95.38461538461539\n",
            "epoch:94  weight:[  835.8        -1147.08127625 -1147.08127625 -1147.08127625\n",
            " -1147.08127625]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:95  weight:[  844.2       -1157.6779256 -1157.6779256 -1157.6779256 -1157.6779256]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:96  weight:[  852.6        -1168.27457495 -1168.27457495 -1168.27457495\n",
            " -1168.27457495]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:97  weight:[  860.3       -1181.2280543 -1181.2280543 -1181.2280543 -1181.2280543]  learning rate:0.7  Training Accuracy:95.38461538461539\n",
            "epoch:98  weight:[  868.7        -1191.82470365 -1191.82470365 -1191.82470365\n",
            " -1191.82470365]  learning rate:0.7  Training Accuracy:95.48717948717949\n",
            "epoch:99  weight:[  877.1      -1202.421353 -1202.421353 -1202.421353 -1202.421353]  learning rate:0.7  Training Accuracy:95.48717948717949\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04HqxpXN52es",
        "colab_type": "code",
        "outputId": "4942797e-b57d-4670-9f7e-21bb41c568f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Testset accuracy, Confusion Matrix and Accuracy metrics\n",
        "def test(X_test, y_test):\n",
        "    print(\"Predictions on test data:\")\n",
        "    correct = 0\n",
        "    tp,fp,tn,fn = 0,0,0,0\n",
        "    for x,y in zip(X_test,y_test):\n",
        "        prediction = predict(x)\n",
        "        actual_value = int(np.array(y)[0][0])\n",
        "        print(\"X: \"+str(x)+\" prediction: \"+str(prediction)+\" Actual value:\"+str(actual_value))\n",
        "        if actual_value == prediction:\n",
        "          correct += 1\n",
        "        if actual_value == 0 and prediction == 0:\n",
        "          tp += 1\n",
        "        if actual_value == 1 and prediction ==1:\n",
        "          tn += 1\n",
        "        if actual_value == 0 and prediction ==1:\n",
        "          fn += 1\n",
        "        if actual_value == 1 and prediction == 0:\n",
        "          fp += 1  \n",
        "    test_accuracy =  correct/float(X_test.shape[0])*100.0\n",
        "    print(\"Test Accuracy:\"+str(test_accuracy))\n",
        "    print()\n",
        "    print(\"Accuracy metrics:\")\n",
        "    accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
        "    precision = tp/(tp+fp)\n",
        "    recall = tp/(tp+fn)\n",
        "    print(\"Accuracy: \"+str(accuracy))\n",
        "    print(\"Precision: \"+str(precision))\n",
        "    print(\"Recall: \"+str(recall))\n",
        "    print()    \n",
        "    print(\"Confusion matrix:\")\n",
        "    cm = [[tp,fp],[fn,tn]]\n",
        "    print(cm)\n",
        "    print()\n",
        "    df_cm = pd.DataFrame(cm, range(2), range(2))\n",
        "    plt.figure(figsize = (10,7))\n",
        "    sns.heatmap(df_cm, annot=True)\n",
        "    plt.title('Confusion Matrix', fontsize = 20) \n",
        "    plt.xlabel('Predicted', fontsize = 15) \n",
        "    plt.ylabel('Actual', fontsize = 15) \n",
        "\n",
        "plt.show()\n",
        "test(X_test, y_test)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predictions on test data:\n",
            "X: [[ 1.581    0.86909 -2.3138   0.82412]] prediction: 0 Actual value:1\n",
            "X: [[ 3.4776   8.811   -3.1886  -0.92285]] prediction: 0 Actual value:0\n",
            "X: [[2.5367  2.599   2.0938  0.20085]] prediction: 0 Actual value:0\n",
            "X: [[-1.4377  -1.432    2.1144   0.42067]] prediction: 1 Actual value:1\n",
            "X: [[-0.93587 -5.1008   4.5367   1.3866 ]] prediction: 1 Actual value:1\n",
            "X: [[ 1.7747  -6.4334   8.15    -0.89828]] prediction: 0 Actual value:0\n",
            "X: [[-2.2153   11.9625    0.078538 -7.7853  ]] prediction: 0 Actual value:0\n",
            "X: [[ 0.5195 -3.2633  3.0895 -0.9849]] prediction: 1 Actual value:0\n",
            "X: [[ 4.1038  -4.8069   3.3491  -0.49225]] prediction: 0 Actual value:0\n",
            "X: [[-4.8426  -4.9932  10.4052  -0.53104]] prediction: 1 Actual value:1\n",
            "X: [[-0.10234  1.8189  -2.2169  -0.56725]] prediction: 1 Actual value:1\n",
            "X: [[ 2.4486  -6.3175   7.9632   0.20602]] prediction: 0 Actual value:0\n",
            "X: [[-0.69078 -0.50077 -0.35417  0.47498]] prediction: 1 Actual value:1\n",
            "X: [[-0.36372  3.0439  -3.4816  -2.7836 ]] prediction: 1 Actual value:1\n",
            "X: [[ 0.93584  8.8855  -1.6831  -1.6599 ]] prediction: 0 Actual value:0\n",
            "X: [[ 1.7875  4.78   -5.1362 -3.2362]] prediction: 1 Actual value:1\n",
            "X: [[ 5.591  10.4643 -4.3839 -4.3379]] prediction: 0 Actual value:0\n",
            "X: [[ 0.96788  7.1907   1.2798  -2.4565 ]] prediction: 0 Actual value:0\n",
            "X: [[-2.9786   2.3445   0.52667 -0.40173]] prediction: 1 Actual value:1\n",
            "X: [[ 0.18868    0.70148   -0.51182    0.0055892]] prediction: 1 Actual value:1\n",
            "X: [[-3.3203  -0.02691  2.9618  -0.44958]] prediction: 1 Actual value:1\n",
            "X: [[-2.286   -5.4484   5.8039   0.88231]] prediction: 1 Actual value:1\n",
            "X: [[-0.39416  -0.020702 -0.066267 -0.44699 ]] prediction: 1 Actual value:1\n",
            "X: [[4.0329  0.23175 0.89082 1.1823 ]] prediction: 0 Actual value:0\n",
            "X: [[-1.5732   1.0636  -0.71232 -0.8388 ]] prediction: 1 Actual value:1\n",
            "X: [[-1.4094  -2.1252  -0.10397 -0.19225]] prediction: 1 Actual value:1\n",
            "X: [[-2.62    -6.8555   6.2169  -0.62285]] prediction: 1 Actual value:1\n",
            "X: [[ 0.2952  4.8856 -5.149  -6.2323]] prediction: 1 Actual value:1\n",
            "X: [[ 3.8481 10.1539 -3.8561 -4.2228]] prediction: 0 Actual value:0\n",
            "X: [[-1.4781   0.14277 -1.1622  -0.48579]] prediction: 1 Actual value:1\n",
            "X: [[-0.41965  2.9094  -1.7859  -2.2069 ]] prediction: 1 Actual value:1\n",
            "X: [[-1.5075   1.9224   7.1466   0.89136]] prediction: 0 Actual value:0\n",
            "X: [[-3.1875  -7.5756  11.8678  -0.57889]] prediction: 1 Actual value:1\n",
            "X: [[ 5.7456 10.1808 -4.7857 -4.3366]] prediction: 0 Actual value:0\n",
            "X: [[-0.87834  3.257   -3.6778  -3.2944 ]] prediction: 1 Actual value:1\n",
            "X: [[0.74054 0.36625 2.1992  0.48403]] prediction: 0 Actual value:0\n",
            "X: [[-3.9204   4.0723  -0.23678 -2.1151 ]] prediction: 1 Actual value:1\n",
            "X: [[ 3.9102   6.065   -2.4534  -0.68234]] prediction: 0 Actual value:0\n",
            "X: [[-0.94255   0.039307 -0.24192   0.31593 ]] prediction: 1 Actual value:1\n",
            "X: [[ 0.58836 10.7727  -1.3884  -4.3276 ]] prediction: 0 Actual value:0\n",
            "X: [[-2.5084  -0.22763  1.488    1.2069 ]] prediction: 1 Actual value:1\n",
            "X: [[-5.2406   6.6258  -0.19908 -6.8607 ]] prediction: 1 Actual value:1\n",
            "X: [[ 0.61652  3.8944  -4.7275  -4.3948 ]] prediction: 1 Actual value:1\n",
            "X: [[-2.4349  -9.2497   8.9922  -0.50001]] prediction: 1 Actual value:1\n",
            "X: [[ 0.83625   1.1071   -2.4706   -0.062945]] prediction: 1 Actual value:1\n",
            "X: [[ 0.50813  0.47799 -1.9804   0.57714]] prediction: 1 Actual value:1\n",
            "X: [[-1.0292  -6.3879   5.5255   0.79955]] prediction: 1 Actual value:1\n",
            "X: [[-4.577    3.4515   0.66719 -0.94742]] prediction: 1 Actual value:1\n",
            "X: [[-1.9725  2.8825 -2.3086 -2.3724]] prediction: 1 Actual value:1\n",
            "X: [[-1.7549   -0.080711 -0.75774  -0.3707  ]] prediction: 1 Actual value:1\n",
            "X: [[ 3.9899  -2.7066   2.3946   0.86291]] prediction: 0 Actual value:0\n",
            "X: [[ 5.6084 10.3009 -4.8003 -4.3534]] prediction: 0 Actual value:0\n",
            "X: [[ 3.0333 -2.5928  2.3183  0.303 ]] prediction: 0 Actual value:0\n",
            "X: [[-1.682  -6.8121  7.1398  1.3323]] prediction: 1 Actual value:1\n",
            "X: [[-0.62684 -6.301    4.7843   1.106  ]] prediction: 1 Actual value:1\n",
            "X: [[-4.5046  -5.8126  10.8867  -0.52846]] prediction: 1 Actual value:1\n",
            "X: [[-4.2887 -7.8633 11.8387 -1.8978]] prediction: 1 Actual value:1\n",
            "X: [[ 0.19081  9.1297  -3.725   -5.8224 ]] prediction: 1 Actual value:0\n",
            "X: [[-2.4554  -9.0407   8.862   -0.86983]] prediction: 1 Actual value:1\n",
            "X: [[ 2.3925  9.798  -3.0361 -2.8224]] prediction: 0 Actual value:0\n",
            "X: [[-2.484  12.1611  2.8204 -3.7418]] prediction: 0 Actual value:0\n",
            "X: [[ 3.1541  -5.1711   6.5991   0.57455]] prediction: 0 Actual value:0\n",
            "X: [[ 5.2418 10.5388 -4.1174 -4.2797]] prediction: 0 Actual value:0\n",
            "X: [[-3.8952   3.8157  -0.31304 -3.8194 ]] prediction: 1 Actual value:1\n",
            "X: [[-2.564   -1.7051   1.5026   0.32757]] prediction: 1 Actual value:1\n",
            "X: [[ 0.16358 -3.3584   1.3749   1.3569 ]] prediction: 1 Actual value:1\n",
            "X: [[ 0.87603  6.8141   0.84198 -0.17156]] prediction: 0 Actual value:0\n",
            "X: [[ 3.7935  7.9853 -2.5477 -1.872 ]] prediction: 0 Actual value:0\n",
            "X: [[-1.0941  2.3072 -2.5237 -1.4453]] prediction: 1 Actual value:1\n",
            "X: [[-3.6053  -5.974   10.0916  -0.82846]] prediction: 1 Actual value:1\n",
            "X: [[-1.0116   -0.19038  -0.90597   0.003003]] prediction: 1 Actual value:1\n",
            "X: [[ 0.11739  6.2761  -1.5495  -2.4746 ]] prediction: 0 Actual value:0\n",
            "X: [[ 1.5631   0.89599 -1.9702   0.65472]] prediction: 0 Actual value:1\n",
            "X: [[ 1.0284  9.767  -1.3687 -1.7853]] prediction: 0 Actual value:0\n",
            "X: [[-0.49241  0.89392 -1.6283  -0.56854]] prediction: 1 Actual value:1\n",
            "X: [[ 1.5077   1.9596  -3.0584  -0.12243]] prediction: 1 Actual value:1\n",
            "X: [[ 3.0934  -2.9177   2.2232   0.22283]] prediction: 0 Actual value:0\n",
            "X: [[-1.1313  1.9037  7.5339  1.022 ]] prediction: 0 Actual value:0\n",
            "X: [[ 4.5447  8.2274 -2.4166 -1.5875]] prediction: 0 Actual value:0\n",
            "X: [[-0.65767 -2.8018   3.7115   0.99739]] prediction: 0 Actual value:1\n",
            "X: [[-0.2062  9.2207 -3.7044 -6.8103]] prediction: 1 Actual value:0\n",
            "X: [[-3.5933   0.22968  0.7126  -0.3332 ]] prediction: 1 Actual value:1\n",
            "X: [[-0.17296 -1.1816   1.3818   0.7336 ]] prediction: 0 Actual value:1\n",
            "X: [[-0.014902 -1.0243   -0.94024   0.64955 ]] prediction: 1 Actual value:1\n",
            "X: [[1.0191  2.33    4.9334  0.82929]] prediction: 0 Actual value:0\n",
            "X: [[ 4.2478  7.6956 -2.7696 -1.0767]] prediction: 0 Actual value:0\n",
            "X: [[-0.66008 -3.226    3.8058   1.1836 ]] prediction: 0 Actual value:1\n",
            "X: [[-1.3414  -2.0776   2.8093   0.60688]] prediction: 1 Actual value:1\n",
            "X: [[-2.799    1.9679  -0.42357 -2.1125 ]] prediction: 1 Actual value:1\n",
            "X: [[ 2.1059   7.6046  -0.47755 -1.8461 ]] prediction: 0 Actual value:0\n",
            "X: [[ 3.7982 10.423  -4.1602 -4.9728]] prediction: 0 Actual value:0\n",
            "X: [[-0.98193  2.7956  -1.2341  -1.5668 ]] prediction: 1 Actual value:1\n",
            "X: [[-1.5572 -9.8808  8.1088 -1.0806]] prediction: 1 Actual value:1\n",
            "X: [[-4.7462  3.1205  1.075  -1.2966]] prediction: 1 Actual value:1\n",
            "X: [[ 0.3292 -4.4552  4.5718 -0.9888]] prediction: 1 Actual value:0\n",
            "X: [[ 3.5458  9.3718 -4.0351 -3.9564]] prediction: 0 Actual value:0\n",
            "X: [[-2.121   -0.05588  1.949    1.353  ]] prediction: 0 Actual value:1\n",
            "X: [[ 0.87256  9.2931  -0.7843  -2.1978 ]] prediction: 0 Actual value:0\n",
            "X: [[ 0.63655  5.2022  -5.2159  -6.1211 ]] prediction: 1 Actual value:1\n",
            "X: [[ 1.3754   8.8793  -1.9136  -0.53751]] prediction: 0 Actual value:0\n",
            "X: [[-0.539    -5.167     3.4399    0.052141]] prediction: 1 Actual value:1\n",
            "X: [[ 5.4021  3.1039 -1.1536  1.5651]] prediction: 0 Actual value:0\n",
            "X: [[ 0.38251  6.8121   1.8128  -0.61251]] prediction: 0 Actual value:0\n",
            "X: [[ 2.549   6.1499 -1.1605 -1.2371]] prediction: 0 Actual value:0\n",
            "X: [[ 4.052   -0.16555  0.45383  0.51248]] prediction: 0 Actual value:0\n",
            "X: [[ 2.0922  -6.81     8.4636  -0.60216]] prediction: 0 Actual value:0\n",
            "X: [[-3.7244    1.9037   -0.035421 -2.5095  ]] prediction: 1 Actual value:1\n",
            "X: [[ -1.48   -10.5244   9.9176  -0.5026]] prediction: 1 Actual value:1\n",
            "X: [[ 4.7181 10.0153 -3.9486 -3.8582]] prediction: 0 Actual value:0\n",
            "X: [[-1.2369  -1.6906   2.518    0.51636]] prediction: 1 Actual value:1\n",
            "X: [[ 1.4501  3.6067 -4.0557 -1.5966]] prediction: 1 Actual value:1\n",
            "X: [[-2.8829  3.8964 -0.1888 -1.1672]] prediction: 1 Actual value:1\n",
            "X: [[ 0.26517  2.4066  -2.8416  -0.59958]] prediction: 1 Actual value:1\n",
            "X: [[ 1.1518   1.3864   5.2727  -0.43536]] prediction: 0 Actual value:0\n",
            "X: [[-0.77461 -1.8768   2.4023   1.1319 ]] prediction: 0 Actual value:1\n",
            "X: [[ 4.5597 -2.4211  2.6413  1.6168]] prediction: 0 Actual value:0\n",
            "X: [[-1.7599 11.9211  2.6756 -3.3241]] prediction: 0 Actual value:0\n",
            "X: [[ 4.5459  8.1674 -2.4586 -1.4621]] prediction: 0 Actual value:0\n",
            "X: [[ 1.5904   2.2121  -3.1183  -0.11725]] prediction: 1 Actual value:1\n",
            "X: [[ 3.8832   6.4023  -2.432   -0.98363]] prediction: 0 Actual value:0\n",
            "X: [[ 3.404    8.7261  -2.9915  -0.57242]] prediction: 0 Actual value:0\n",
            "X: [[-4.1958 -8.1819 12.1291 -1.6017]] prediction: 1 Actual value:1\n",
            "X: [[ 3.8496  9.7939 -4.1508 -4.4582]] prediction: 0 Actual value:0\n",
            "X: [[3.4465 2.9508 1.0271 0.5461]] prediction: 0 Actual value:0\n",
            "X: [[ 1.2247   8.7779  -2.2135  -0.80647]] prediction: 0 Actual value:0\n",
            "X: [[-3.      -9.1566   9.5766  -0.73018]] prediction: 1 Actual value:1\n",
            "X: [[ 2.3917  4.5565 -4.9888 -2.8987]] prediction: 1 Actual value:1\n",
            "X: [[-1.8629   -0.84841   2.5377    0.097399]] prediction: 1 Actual value:1\n",
            "X: [[-1.7886  -6.3486   5.6154   0.42584]] prediction: 1 Actual value:1\n",
            "X: [[-2.7264   3.9213  -0.49212 -3.6371 ]] prediction: 1 Actual value:1\n",
            "X: [[-2.9498 -8.273  10.2646  1.1629]] prediction: 1 Actual value:1\n",
            "X: [[ 3.106   9.5414 -4.2536 -4.003 ]] prediction: 0 Actual value:0\n",
            "X: [[3.6702  2.9942  0.85141 0.30688]] prediction: 0 Actual value:0\n",
            "X: [[ 2.4226  -4.5752   5.947    0.21507]] prediction: 0 Actual value:0\n",
            "X: [[ 2.3136 10.6651 -3.5288 -4.7672]] prediction: 0 Actual value:0\n",
            "X: [[3.8027  0.81529 2.1041  1.0245 ]] prediction: 0 Actual value:0\n",
            "X: [[-1.2244  1.7485 -1.4801 -1.4181]] prediction: 1 Actual value:1\n",
            "X: [[ 4.9852  8.3516 -2.5425 -1.2823]] prediction: 0 Actual value:0\n",
            "X: [[-0.3481  -0.38696 -0.47841  0.62627]] prediction: 1 Actual value:1\n",
            "X: [[-0.64326  2.4748  -2.9452  -1.0276 ]] prediction: 1 Actual value:1\n",
            "X: [[-0.90784 -7.9026   6.7807   0.34179]] prediction: 1 Actual value:1\n",
            "X: [[ 1.2198   2.0982  -3.1954   0.12843]] prediction: 1 Actual value:1\n",
            "X: [[ -4.6338 -12.7509  16.7166  -3.2168]] prediction: 1 Actual value:1\n",
            "X: [[-1.3968  -9.6698   9.4652  -0.34872]] prediction: 1 Actual value:1\n",
            "X: [[-1.3414  -1.9162  -0.15538 -0.11984]] prediction: 1 Actual value:1\n",
            "X: [[-4.4996   3.4288   0.56265 -1.1672 ]] prediction: 1 Actual value:1\n",
            "X: [[-1.7263  -6.0237   5.2419   0.29524]] prediction: 1 Actual value:1\n",
            "X: [[-2.3147  3.6668 -0.6969 -1.2474]] prediction: 1 Actual value:1\n",
            "X: [[ 4.3064  8.2068 -2.7824 -1.4336]] prediction: 0 Actual value:0\n",
            "X: [[3.8584  0.78425 1.1033  1.7008 ]] prediction: 0 Actual value:0\n",
            "X: [[ 0.3292 -4.4552  4.5718 -0.9888]] prediction: 1 Actual value:0\n",
            "X: [[3.6244 1.4609 1.3501 1.9284]] prediction: 0 Actual value:0\n",
            "X: [[-2.0441   1.2271   0.18564 -1.091  ]] prediction: 1 Actual value:1\n",
            "X: [[-5.1661    8.0433    0.044265 -4.4983  ]] prediction: 1 Actual value:1\n",
            "X: [[-3.4605   2.6901   0.16165 -1.0224 ]] prediction: 1 Actual value:1\n",
            "X: [[ 0.5195 -3.2633  3.0895 -0.9849]] prediction: 1 Actual value:0\n",
            "X: [[ 0.75108  1.9161  -3.1098  -0.20518]] prediction: 1 Actual value:1\n",
            "X: [[4.2772  2.4955  0.48554 0.36119]] prediction: 0 Actual value:0\n",
            "X: [[ 3.7321    -3.884      3.3577    -0.0060486]] prediction: 0 Actual value:0\n",
            "X: [[ 5.807    5.0097  -2.2384   0.43878]] prediction: 0 Actual value:0\n",
            "X: [[-2.1786  -6.4479   6.0344  -0.20777]] prediction: 1 Actual value:1\n",
            "X: [[-1.1005  -7.2508   6.0139   0.36895]] prediction: 1 Actual value:1\n",
            "X: [[-1.522   -6.6383   5.7491  -0.10691]] prediction: 1 Actual value:1\n",
            "X: [[ 1.3234   3.2964   0.2362  -0.11984]] prediction: 0 Actual value:0\n",
            "X: [[1.6472  0.48213 4.7449  1.225  ]] prediction: 0 Actual value:0\n",
            "X: [[ 1.645    7.8612  -0.87598 -3.5569 ]] prediction: 0 Actual value:0\n",
            "X: [[ 4.988   7.2052 -3.2846 -1.1608]] prediction: 0 Actual value:0\n",
            "X: [[ 3.4642 10.6878 -3.4071 -4.109 ]] prediction: 0 Actual value:0\n",
            "X: [[1.3087  4.9228  2.0013  0.22024]] prediction: 0 Actual value:0\n",
            "X: [[3.744   0.79459 0.95851 1.0077 ]] prediction: 0 Actual value:0\n",
            "X: [[-0.77848  3.4019  -3.4859  -3.5569 ]] prediction: 1 Actual value:1\n",
            "X: [[ 0.94225  5.8561   1.8762  -0.32544]] prediction: 0 Actual value:0\n",
            "X: [[-5.873    9.1752  -0.27448 -6.0422 ]] prediction: 1 Actual value:1\n",
            "X: [[ 0.5706 -0.0248  1.2421 -0.5621]] prediction: 0 Actual value:0\n",
            "X: [[3.9994  0.90427 1.1693  1.6892 ]] prediction: 0 Actual value:0\n",
            "X: [[ 2.4391   6.4417  -0.80743 -0.69139]] prediction: 0 Actual value:0\n",
            "X: [[-1.7697  3.4329 -1.2144 -2.3789]] prediction: 1 Actual value:1\n",
            "X: [[3.6667  4.302   0.55923 0.33791]] prediction: 0 Actual value:0\n",
            "X: [[ 1.2138   8.7986  -2.1672  -0.74182]] prediction: 0 Actual value:0\n",
            "X: [[-1.1859  -1.2519   2.2635   0.77239]] prediction: 1 Actual value:1\n",
            "X: [[-2.6479 10.1374 -1.331  -5.4707]] prediction: 1 Actual value:0\n",
            "X: [[3.5127  2.9073  1.0579  0.40774]] prediction: 0 Actual value:0\n",
            "X: [[-2.2214  -0.23798  0.56008  0.05602]] prediction: 1 Actual value:1\n",
            "X: [[-5.1216 -5.3118 10.3846 -1.0612]] prediction: 1 Actual value:1\n",
            "X: [[ 6.5633  9.8187 -4.4113 -3.2258]] prediction: 0 Actual value:0\n",
            "X: [[ 0.3798  0.7098  0.7572 -0.4444]] prediction: 0 Actual value:0\n",
            "X: [[-6.3679  8.0102  0.4247 -3.2207]] prediction: 1 Actual value:1\n",
            "X: [[-0.27802  8.1881  -3.1338  -2.5276 ]] prediction: 0 Actual value:0\n",
            "X: [[-1.3    10.2678 -2.953  -5.8638]] prediction: 1 Actual value:0\n",
            "X: [[ 5.032   8.2026 -2.6256 -1.0341]] prediction: 0 Actual value:0\n",
            "X: [[-3.3553   0.35591  2.6473  -0.37846]] prediction: 1 Actual value:1\n",
            "X: [[-1.3    10.2678 -2.953  -5.8638]] prediction: 1 Actual value:0\n",
            "X: [[-2.1241  -6.8969   5.5992  -0.47156]] prediction: 1 Actual value:1\n",
            "X: [[ 3.5358   6.7086  -0.81857  0.47886]] prediction: 0 Actual value:0\n",
            "X: [[4.8272  3.0687  0.68604 0.80731]] prediction: 0 Actual value:0\n",
            "X: [[ 4.0215  -2.7004   2.4957   0.36636]] prediction: 0 Actual value:0\n",
            "X: [[ 4.8077   2.2327  -0.26334  1.5534 ]] prediction: 0 Actual value:0\n",
            "X: [[-2.4824  -7.3046   6.839   -0.59053]] prediction: 1 Actual value:1\n",
            "X: [[ 3.4985   3.1639   0.22677 -0.1651 ]] prediction: 0 Actual value:0\n",
            "X: [[-3.38    -0.7077   2.5325   0.71808]] prediction: 1 Actual value:1\n",
            "X: [[-4.8392   6.6755  -0.24278 -6.5775 ]] prediction: 1 Actual value:1\n",
            "X: [[ 2.1943  4.5503 -4.976  -2.7254]] prediction: 1 Actual value:1\n",
            "X: [[-5.9034   6.5679   0.67661 -6.6797 ]] prediction: 1 Actual value:1\n",
            "X: [[ 3.4246  -0.14693  0.80342  0.29136]] prediction: 0 Actual value:0\n",
            "X: [[ 0.32924 -4.4552   4.5718  -0.9888 ]] prediction: 1 Actual value:0\n",
            "X: [[ 2.9421   7.4101  -0.97709 -0.88406]] prediction: 0 Actual value:0\n",
            "X: [[ 0.50225  0.65388 -1.1793   0.39998]] prediction: 1 Actual value:1\n",
            "X: [[ 2.0165  -0.25246  5.1707   1.0763 ]] prediction: 0 Actual value:0\n",
            "X: [[ 3.4626  -4.449    3.5427   0.15429]] prediction: 0 Actual value:0\n",
            "X: [[-2.0046  -0.49457  1.333    1.6543 ]] prediction: 1 Actual value:1\n",
            "X: [[-1.3946   2.3134  -0.44499 -1.4905 ]] prediction: 1 Actual value:1\n",
            "X: [[ 2.4008  9.3593 -3.3565 -3.3526]] prediction: 0 Actual value:0\n",
            "X: [[-2.3675  -0.43663  1.692   -0.43018]] prediction: 1 Actual value:1\n",
            "X: [[ 1.6426   3.0149   0.22849 -0.147  ]] prediction: 0 Actual value:0\n",
            "X: [[-0.023579  7.1742    0.78457  -0.75734 ]] prediction: 0 Actual value:0\n",
            "X: [[ 4.364   -3.1039   2.3757   0.78532]] prediction: 0 Actual value:0\n",
            "X: [[4.2458  1.1981  0.66633 0.94696]] prediction: 0 Actual value:0\n",
            "X: [[1.9647  6.9383  0.57722 0.66377]] prediction: 0 Actual value:0\n",
            "X: [[4.0047  0.45937 1.3621  1.6181 ]] prediction: 0 Actual value:0\n",
            "X: [[-2.0897 10.8265  2.3603 -3.4198]] prediction: 0 Actual value:0\n",
            "X: [[2.8969  0.70768 2.29    1.8663 ]] prediction: 0 Actual value:0\n",
            "X: [[-7.0364   9.2931   0.16594 -4.5396 ]] prediction: 1 Actual value:1\n",
            "X: [[ 1.1472   3.5985   1.9387  -0.43406]] prediction: 0 Actual value:0\n",
            "X: [[ -3.4917  -12.1736   14.3689   -0.61639]] prediction: 1 Actual value:1\n",
            "X: [[-6.8919e-03  9.2931e+00 -4.1243e-01 -1.9638e+00]] prediction: 0 Actual value:0\n",
            "X: [[1.5902  2.2948  3.2403  0.18404]] prediction: 0 Actual value:0\n",
            "X: [[-0.36506  2.8928  -3.6461  -3.0603 ]] prediction: 1 Actual value:1\n",
            "X: [[-3.3884  -8.215   10.3315   0.98187]] prediction: 1 Actual value:1\n",
            "X: [[-1.8411 10.8306  2.769  -3.0901]] prediction: 0 Actual value:0\n",
            "X: [[ 1.0652  8.3682 -1.4004 -1.6509]] prediction: 0 Actual value:0\n",
            "X: [[-2.5961  -9.349    9.7942  -0.28018]] prediction: 1 Actual value:1\n",
            "X: [[4.1962  0.74493 0.83256 0.753  ]] prediction: 0 Actual value:0\n",
            "X: [[2.6799  3.1349  0.34073 0.58489]] prediction: 0 Actual value:0\n",
            "X: [[ 0.67886  4.1199  -4.569   -4.1414 ]] prediction: 1 Actual value:1\n",
            "X: [[ 1.3264   1.0326   5.6566  -0.41337]] prediction: 0 Actual value:0\n",
            "X: [[ 2.0153   0.43661  4.5864  -0.3151 ]] prediction: 0 Actual value:0\n",
            "X: [[-1.3995  -1.9162   2.5154   0.59912]] prediction: 1 Actual value:1\n",
            "X: [[-2.3299 -9.9532  8.4756 -1.8733]] prediction: 1 Actual value:1\n",
            "X: [[-3.8552   3.5219  -0.38415 -3.8608 ]] prediction: 1 Actual value:1\n",
            "X: [[ 0.91315  3.3377  -4.0557  -1.6741 ]] prediction: 1 Actual value:1\n",
            "X: [[ 0.11806  0.39108 -0.98223  0.42843]] prediction: 1 Actual value:1\n",
            "X: [[3.1557  2.8908  0.59693 0.79825]] prediction: 0 Actual value:0\n",
            "X: [[-3.5637 -8.3827 12.393  -1.2823]] prediction: 1 Actual value:1\n",
            "X: [[-6.7387   6.9879   0.67833 -7.5887 ]] prediction: 1 Actual value:1\n",
            "X: [[ 1.2746  8.8172 -1.5323 -1.7957]] prediction: 0 Actual value:0\n",
            "X: [[1.8384  6.063   0.54723 0.51248]] prediction: 0 Actual value:0\n",
            "X: [[ 3.0632 -3.3315  5.1305  0.8267]] prediction: 0 Actual value:0\n",
            "X: [[ 1.7819  6.9176 -1.2744 -1.5759]] prediction: 0 Actual value:0\n",
            "X: [[ 0.5415   6.0319   1.6825  -0.46122]] prediction: 0 Actual value:0\n",
            "X: [[ 1.8114  7.6067 -0.9788 -2.4668]] prediction: 0 Actual value:0\n",
            "X: [[ 1.7496 -0.1759  5.1827  1.2922]] prediction: 0 Actual value:0\n",
            "X: [[-2.8267  -9.0407   9.0694  -0.98233]] prediction: 1 Actual value:1\n",
            "X: [[ 2.8561   6.9176  -0.79372  0.48403]] prediction: 0 Actual value:0\n",
            "X: [[ 0.7376  4.8525 -4.7986 -5.6659]] prediction: 1 Actual value:1\n",
            "X: [[ 1.0182   9.109   -0.62064 -1.7129 ]] prediction: 0 Actual value:0\n",
            "X: [[-0.87874  -2.2121   -0.051701  0.099985]] prediction: 1 Actual value:1\n",
            "X: [[ 0.37984  0.70975  0.75716 -0.44441]] prediction: 0 Actual value:0\n",
            "X: [[-0.071503  3.7412   -4.5415   -4.2526  ]] prediction: 1 Actual value:1\n",
            "X: [[ -4.4775 -13.0303  17.0834  -3.0345]] prediction: 1 Actual value:1\n",
            "X: [[ 4.0215 -2.1914  2.4648  1.1409]] prediction: 0 Actual value:0\n",
            "X: [[ 4.8851e+00  1.5995e+00 -2.9081e-04  1.6401e+00]] prediction: 0 Actual value:0\n",
            "X: [[-1.239    -6.541     4.8151   -0.033204]] prediction: 1 Actual value:1\n",
            "X: [[ 0.3292 -4.4552  4.5718 -0.9888]] prediction: 1 Actual value:0\n",
            "X: [[ 2.5605  9.2683 -3.5913 -1.356 ]] prediction: 0 Actual value:0\n",
            "X: [[ 0.14783  7.946    1.0742  -3.3409 ]] prediction: 0 Actual value:0\n",
            "X: [[4.2027  0.22761 0.96108 0.97282]] prediction: 0 Actual value:0\n",
            "X: [[ 1.5701   7.9129   0.29018 -2.1953 ]] prediction: 0 Actual value:0\n",
            "X: [[-0.47465 -4.3496   1.9901   0.7517 ]] prediction: 1 Actual value:1\n",
            "X: [[ 3.9292  -2.9156   2.2129   0.30817]] prediction: 0 Actual value:0\n",
            "X: [[ 4.9342   2.4107  -0.17594  1.6245 ]] prediction: 0 Actual value:0\n",
            "X: [[ 1.4507   8.7903  -2.2324  -0.65259]] prediction: 0 Actual value:0\n",
            "X: [[-0.36038  4.1158   3.1143  -0.37199]] prediction: 0 Actual value:0\n",
            "X: [[ 2.8297   6.3485  -0.73546 -0.58665]] prediction: 0 Actual value:0\n",
            "X: [[ 3.5862  -3.0957   2.8093   0.24481]] prediction: 0 Actual value:0\n",
            "X: [[ 3.8969   7.4163  -1.8245   0.14007]] prediction: 0 Actual value:0\n",
            "X: [[ 0.74307 11.17    -1.3824  -4.0728 ]] prediction: 0 Actual value:0\n",
            "X: [[-0.81479 -5.7381   4.3919   0.3211 ]] prediction: 1 Actual value:1\n",
            "X: [[ 1.0552   1.1857  -2.6411   0.11033]] prediction: 1 Actual value:1\n",
            "X: [[ 3.5761  9.7753 -3.9795 -3.4638]] prediction: 0 Actual value:0\n",
            "X: [[ 2.093     8.3061    0.022844 -3.2724  ]] prediction: 0 Actual value:0\n",
            "X: [[-4.2859   8.5234   3.1392  -0.91639]] prediction: 0 Actual value:0\n",
            "X: [[ 5.3063   5.2684  -2.8904  -0.52716]] prediction: 0 Actual value:0\n",
            "X: [[ 1.1644  3.8095 -4.9408 -4.0909]] prediction: 1 Actual value:1\n",
            "X: [[ 1.9340e+00 -9.2828e-06  4.8160e+00 -3.3967e-01]] prediction: 0 Actual value:0\n",
            "X: [[3.966   3.9213  0.70574 0.33662]] prediction: 0 Actual value:0\n",
            "X: [[-4.8554  -5.9037  10.9818  -0.82199]] prediction: 1 Actual value:1\n",
            "X: [[ 0.22432 -0.52147 -0.40386  1.2017 ]] prediction: 1 Actual value:1\n",
            "X: [[-0.40951  -0.15521   0.060545 -0.088807]] prediction: 1 Actual value:1\n",
            "X: [[ 2.5678   3.5136   0.61406 -0.40691]] prediction: 0 Actual value:0\n",
            "X: [[-2.0754   1.2767  -0.64206 -1.2642 ]] prediction: 1 Actual value:1\n",
            "X: [[ 5.7867   7.8902  -2.6196  -0.48708]] prediction: 0 Actual value:0\n",
            "X: [[ 1.2262   0.89599  5.7568  -0.11596]] prediction: 0 Actual value:0\n",
            "X: [[ -3.5713  -12.4922   14.8881   -0.47027]] prediction: 1 Actual value:1\n",
            "X: [[ 0.5706   -0.024841  1.2421   -0.56208 ]] prediction: 0 Actual value:0\n",
            "X: [[-1.3971  3.3191 -1.3927 -1.9948]] prediction: 1 Actual value:1\n",
            "X: [[-2.0962  -7.1059   6.6188  -0.33708]] prediction: 1 Actual value:1\n",
            "X: [[-0.60254  1.7237  -2.1501  -0.77027]] prediction: 1 Actual value:1\n",
            "X: [[3.5829 1.4423 1.0219 1.4008]] prediction: 0 Actual value:0\n",
            "X: [[-1.3274  9.498   2.4408 -5.2689]] prediction: 0 Actual value:0\n",
            "X: [[ 3.4591 11.112  -4.2039 -5.0931]] prediction: 0 Actual value:0\n",
            "X: [[ 5.681    7.795   -2.6848  -0.92544]] prediction: 0 Actual value:0\n",
            "X: [[ 1.2572  4.8731 -5.2861 -5.8741]] prediction: 1 Actual value:1\n",
            "X: [[ 1.143    0.83391  5.4552  -0.56984]] prediction: 0 Actual value:0\n",
            "X: [[-4.0218 -8.304  12.555  -1.5099]] prediction: 1 Actual value:1\n",
            "X: [[ 3.5499  8.6165 -3.2794 -1.2009]] prediction: 0 Actual value:0\n",
            "X: [[ 1.5099    0.039307  6.2332   -0.30346 ]] prediction: 0 Actual value:0\n",
            "X: [[-0.77288 -7.4473   6.492    0.36119]] prediction: 1 Actual value:1\n",
            "X: [[-1.2537 10.8803  1.931  -4.3237]] prediction: 0 Actual value:0\n",
            "X: [[ 0.60731  3.9544  -4.772   -4.4853 ]] prediction: 1 Actual value:1\n",
            "X: [[ 2.8084 11.3045 -3.3394 -4.4194]] prediction: 0 Actual value:0\n",
            "X: [[-2.6286   0.18002  1.7956   0.97282]] prediction: 1 Actual value:1\n",
            "X: [[-1.8782   -6.5865    4.8486   -0.021566]] prediction: 1 Actual value:1\n",
            "X: [[ 0.89566  7.7763  -2.7473  -1.9353 ]] prediction: 0 Actual value:0\n",
            "X: [[ 2.108   6.7955 -0.1708  0.4905]] prediction: 0 Actual value:0\n",
            "X: [[ 0.88872  5.3449   2.045   -0.19355]] prediction: 0 Actual value:0\n",
            "X: [[ 3.0009   5.8126  -2.2306  -0.66553]] prediction: 0 Actual value:0\n",
            "X: [[ 1.3403  4.1323 -4.7018 -2.5987]] prediction: 1 Actual value:1\n",
            "X: [[ 4.6054  -4.0765   2.7587   0.31981]] prediction: 0 Actual value:0\n",
            "X: [[-3.9594   4.0289  -0.35845 -3.8957 ]] prediction: 1 Actual value:1\n",
            "X: [[ 2.9736  8.7944 -3.6359 -1.3754]] prediction: 0 Actual value:0\n",
            "X: [[ 2.6104   8.0081  -0.23592 -1.7608 ]] prediction: 0 Actual value:0\n",
            "X: [[ 3.9166 10.2491 -4.0926 -4.4659]] prediction: 0 Actual value:0\n",
            "X: [[ 0.59823  3.5012  -3.9795  -1.7841 ]] prediction: 1 Actual value:1\n",
            "X: [[-0.95403  1.9824  -2.3163  -1.1957 ]] prediction: 1 Actual value:1\n",
            "X: [[-0.33729 -0.64976  7.6659   0.72326]] prediction: 0 Actual value:0\n",
            "X: [[ 0.27331  4.8773  -4.9194  -5.8198 ]] prediction: 1 Actual value:1\n",
            "X: [[-0.23356  3.2405  -3.0669  -2.7784 ]] prediction: 1 Actual value:1\n",
            "X: [[ 3.583   -3.7971   3.4391  -0.12501]] prediction: 0 Actual value:0\n",
            "X: [[ 5.3586  3.7557 -1.7345  1.0789]] prediction: 0 Actual value:0\n",
            "X: [[3.4359  0.66216 2.1041  1.8922 ]] prediction: 0 Actual value:0\n",
            "X: [[-2.0042  -9.3676   9.3333  -0.10303]] prediction: 1 Actual value:1\n",
            "X: [[ 5.438   9.4669 -4.9417 -3.9202]] prediction: 0 Actual value:0\n",
            "X: [[ 0.83292  7.5404   0.65005 -0.92544]] prediction: 0 Actual value:0\n",
            "X: [[ 4.6464 10.5326 -4.5852 -4.206 ]] prediction: 0 Actual value:0\n",
            "X: [[ 2.6562 10.7044 -3.3085 -4.0767]] prediction: 0 Actual value:0\n",
            "X: [[-2.3142   2.0838  -0.46813 -1.6767 ]] prediction: 1 Actual value:1\n",
            "X: [[-0.38214  8.3909   2.1624  -3.7405 ]] prediction: 0 Actual value:0\n",
            "X: [[-6.2003     8.6806     0.0091344 -3.703    ]] prediction: 1 Actual value:1\n",
            "X: [[-0.40804  0.54214 -0.52725  0.6586 ]] prediction: 1 Actual value:1\n",
            "X: [[ 5.1213  8.5565 -3.3917 -1.5474]] prediction: 0 Actual value:0\n",
            "X: [[ 0.51947 -3.2633   3.0895  -0.98492]] prediction: 1 Actual value:0\n",
            "X: [[ 2.9742  8.96   -2.9024 -1.0379]] prediction: 0 Actual value:0\n",
            "X: [[ 0.56953  7.6294   1.5754  -3.2233 ]] prediction: 0 Actual value:0\n",
            "X: [[-4.2932   3.3419   0.77258 -0.99785]] prediction: 1 Actual value:1\n",
            "X: [[4.3634  0.46351 1.4281  2.0202 ]] prediction: 0 Actual value:0\n",
            "X: [[ 0.66365  -0.045533 -0.18794   0.23447 ]] prediction: 1 Actual value:1\n",
            "X: [[1.8205    6.7562    0.0099913 0.39481  ]] prediction: 0 Actual value:0\n",
            "X: [[-1.8215   2.7521  -0.72261 -2.353  ]] prediction: 1 Actual value:1\n",
            "X: [[ 1.5456  8.5482  0.4187 -2.1784]] prediction: 0 Actual value:0\n",
            "X: [[ 0.65497  5.1815   1.0673  -0.42113]] prediction: 0 Actual value:0\n",
            "X: [[-1.1497   1.2954   7.701    0.62627]] prediction: 0 Actual value:0\n",
            "X: [[ 0.88992  2.2638  -3.1046  -0.11855]] prediction: 1 Actual value:1\n",
            "X: [[ 3.3583 10.3567 -3.7301 -3.6991]] prediction: 0 Actual value:0\n",
            "X: [[ 1.5478  9.1814 -1.6326 -1.7375]] prediction: 0 Actual value:0\n",
            "X: [[ 3.6922 -3.9585  4.3439  1.3517]] prediction: 0 Actual value:0\n",
            "X: [[-4.1244  3.7909 -0.6532 -4.1802]] prediction: 1 Actual value:1\n",
            "X: [[2.9543  1.076   0.64577 0.89394]] prediction: 0 Actual value:0\n",
            "X: [[ 0.96414  5.616    2.2138  -0.12501]] prediction: 0 Actual value:0\n",
            "X: [[-6.3979  6.4479  1.0836 -6.6176]] prediction: 1 Actual value:1\n",
            "X: [[-1.7104 -4.778   6.2109  0.3974]] prediction: 1 Actual value:1\n",
            "X: [[ 3.2422   6.2265   0.12224 -1.4466 ]] prediction: 0 Actual value:0\n",
            "X: [[ 0.5734  9.1938 -0.9094 -1.872 ]] prediction: 0 Actual value:0\n",
            "X: [[-1.1667  -1.4237   2.9241   0.66119]] prediction: 0 Actual value:1\n",
            "X: [[-1.2424  -1.7175  -0.52553 -0.21036]] prediction: 1 Actual value:1\n",
            "X: [[ 1.7939  -1.1174   1.5454  -0.26079]] prediction: 0 Actual value:0\n",
            "X: [[2.4673  1.3926  1.7125  0.41421]] prediction: 0 Actual value:0\n",
            "X: [[ 4.6014   5.6264  -2.1235   0.19309]] prediction: 0 Actual value:0\n",
            "X: [[ 0.20977 -0.46146  7.7267   0.90946]] prediction: 0 Actual value:0\n",
            "X: [[-0.41645  0.32487 -0.33617 -0.36036]] prediction: 1 Actual value:1\n",
            "X: [[ 3.4893   6.69    -1.2042  -0.38751]] prediction: 0 Actual value:0\n",
            "X: [[ 4.1197  -2.7956   2.0707   0.67412]] prediction: 0 Actual value:0\n",
            "X: [[-0.55355 -7.9233   6.7156   0.74394]] prediction: 1 Actual value:1\n",
            "X: [[-3.8167   5.1401  -0.65063 -5.4306 ]] prediction: 1 Actual value:1\n",
            "X: [[3.2414  0.40971 1.4015  1.1952 ]] prediction: 0 Actual value:0\n",
            "X: [[0.80355 2.8473  4.3439  0.6017 ]] prediction: 0 Actual value:0\n",
            "X: [[-0.7056  8.7241  2.2215 -4.5965]] prediction: 0 Actual value:0\n",
            "X: [[ 1.3638 -4.7759  8.4182 -1.8836]] prediction: 0 Actual value:0\n",
            "X: [[ 1.742  -4.809   8.2142 -2.0659]] prediction: 0 Actual value:0\n",
            "X: [[-1.7063  2.7956 -2.378  -2.3491]] prediction: 1 Actual value:1\n",
            "X: [[-2.9883    0.31245   0.45041   0.068951]] prediction: 1 Actual value:1\n",
            "X: [[ 5.0452   3.8964  -1.4304   0.86291]] prediction: 0 Actual value:0\n",
            "X: [[-1.0401   9.3987   0.85998 -5.3336 ]] prediction: 0 Actual value:0\n",
            "X: [[-2.0659   1.0512  -0.46298 -1.0974 ]] prediction: 1 Actual value:1\n",
            "X: [[-0.2062  9.2207 -3.7044 -6.8103]] prediction: 1 Actual value:0\n",
            "X: [[-2.5724  -0.95602  2.7073  -0.16639]] prediction: 1 Actual value:1\n",
            "X: [[ 4.8906 -3.3584  3.4202  1.0905]] prediction: 0 Actual value:0\n",
            "X: [[-2.4725  -0.40145  1.4855   1.1189 ]] prediction: 1 Actual value:1\n",
            "X: [[-0.62043  0.5587  -0.38587 -0.66423]] prediction: 1 Actual value:1\n",
            "X: [[-0.30432  2.6528  -2.7756  -0.65647]] prediction: 1 Actual value:1\n",
            "X: [[-1.0833  -0.31247  1.2815   0.41291]] prediction: 1 Actual value:1\n",
            "X: [[ 3.7798   -3.3109    2.6491    0.066365]] prediction: 0 Actual value:0\n",
            "X: [[ 3.3397  -4.6145   3.9823  -0.23751]] prediction: 0 Actual value:0\n",
            "X: [[-6.5773   6.8017   0.85483 -7.5344 ]] prediction: 1 Actual value:1\n",
            "X: [[3.7635  2.7811  0.66119 0.34179]] prediction: 0 Actual value:0\n",
            "X: [[ 4.2134  -2.806    2.0116   0.67412]] prediction: 0 Actual value:0\n",
            "X: [[0.64215 3.1287  4.2933  0.64696]] prediction: 0 Actual value:0\n",
            "X: [[5.4944   1.5478   0.041694 1.9284  ]] prediction: 0 Actual value:0\n",
            "Test Accuracy:94.7103274559194\n",
            "\n",
            "Accuracy metrics:\n",
            "Accuracy: 0.947103274559194\n",
            "Precision: 0.9624413145539906\n",
            "Recall: 0.9403669724770642\n",
            "\n",
            "Confusion matrix:\n",
            "[[205, 8], [13, 171]]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}