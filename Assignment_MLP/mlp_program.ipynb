{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "bVTUa6LZlGbq",
    "outputId": "9073bcaa-1654-4b76-d28b-caa8ea212cd2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "jdCKsynT5r2C",
    "outputId": "34843460-60e9-4166-a635-9c0bd09434e6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.6661</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.1674</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.6383</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.5228</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.4552</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1       2        3  4\n",
       "0  3.62160  8.6661 -2.8073 -0.44699  0\n",
       "1  4.54590  8.1674 -2.4586 -1.46210  0\n",
       "2  3.86600 -2.6383  1.9242  0.10645  0\n",
       "3  3.45660  9.5228 -4.0112 -3.59440  0\n",
       "4  0.32924 -4.4552  4.5718 -0.98880  0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading the dataset from csv file\n",
    "def read_data(file):\n",
    "    data = pd.read_csv(file, header=None , index_col=None)\n",
    "    return data\n",
    "data = read_data('data.txt')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rh3P3ipc5wNg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0         1         2         3  4\n",
      "894  -1.83910  -9.08830   9.24160 -0.104320  1\n",
      "1249 -3.38000  -0.70770   2.53250  0.718080  1\n",
      "588  -0.27802   8.18810  -3.13380 -2.527600  0\n",
      "1353  0.11592   3.22190  -3.43020 -2.845700  1\n",
      "223   4.64640  10.53260  -4.58520 -4.206000  0\n",
      "939  -2.05290   3.83850  -0.79544 -1.213800  1\n",
      "314   1.18110   8.38470  -2.05670 -0.903450  0\n",
      "620   3.46260  -4.44900   3.54270  0.154290  0\n",
      "338   0.96414   5.61600   2.21380 -0.125010  0\n",
      "671   0.51947  -3.26330   3.08950 -0.984920  0\n",
      "856   0.24261   0.57318  -1.94020  0.440070  1\n",
      "1328 -1.39680  -9.66980   9.46520 -0.348720  1\n",
      "390  -0.36279   8.28950  -1.92130 -3.333200  0\n",
      "155   2.48600  -0.99533   5.34040 -0.154750  0\n",
      "1363 -1.16670  -1.42370   2.92410  0.661190  1\n",
      "249   1.01350   8.45510  -1.67200 -2.081500  0\n",
      "373   1.91050   8.87100  -2.33860 -0.756040  0\n",
      "315   0.32920  -4.45520   4.57180 -0.988800  0\n",
      "881  -4.48610 -13.28890  17.30870 -3.219400  1\n",
      "121   4.07130  10.40230  -4.17220 -4.758200  0\n",
      "262   1.81140   7.60670  -0.97880 -2.466800  0\n",
      "147   1.74960  -0.17590   5.18270  1.292200  0\n",
      "428   3.42460  -0.14693   0.80342  0.291360  0\n",
      "1308 -4.63380 -12.75090  16.71660 -3.216800  1\n",
      "221   2.41960   6.46650  -0.75688  0.228000  0\n",
      "1277  0.56232   1.00150  -2.27260 -0.006049  1\n",
      "220  -2.22610  12.53980   2.94380 -3.525800  0\n",
      "297   1.27060   8.03500  -0.19651 -2.188800  0\n",
      "142   4.17360   3.33360  -1.42440  0.604290  0\n",
      "1030 -1.84390  -8.64750   7.67960 -0.666820  1\n",
      "...       ...       ...       ...       ... ..\n",
      "1110 -3.89520   3.81570  -0.31304 -3.819400  1\n",
      "316   5.73530   5.28080  -2.25980  0.075416  0\n",
      "247   2.05970  -0.99326   5.21190 -0.293120  0\n",
      "381   5.41880  10.14570  -4.08400 -3.699100  0\n",
      "581  -1.96670  11.80520  -0.40472 -7.871900  0\n",
      "1178 -2.07540   1.27670  -0.64206 -1.264200  1\n",
      "489   2.82370   2.85970   0.19678  0.571960  0\n",
      "70    3.95290  -2.35480   2.37920  0.482740  0\n",
      "1313 -1.50780  -7.31910   7.89810  1.228900  1\n",
      "267   3.84960   9.79390  -4.15080 -4.458200  0\n",
      "286   1.34190  -4.42210   8.09000 -1.734900  0\n",
      "104   4.20270   0.22761   0.96108  0.972820  0\n",
      "956  -1.07440  -6.31130   5.35500  0.804720  1\n",
      "1151 -2.31420  -0.68494   1.98330 -0.448290  1\n",
      "916  -0.53900  -5.16700   3.43990  0.052141  1\n",
      "1022 -0.66008  -3.22600   3.80580  1.183600  1\n",
      "201   4.00260  -3.59430   3.55730  0.268090  0\n",
      "868  -4.49960   3.42880   0.56265 -1.167200  1\n",
      "1199 -2.91380  -9.47110   9.76680 -0.602160  1\n",
      "320   0.51950  -3.26330   3.08950 -0.984900  0\n",
      "1139 -1.52280  -6.47890   5.75680  0.873250  1\n",
      "447   3.91210   2.97350   0.92852  0.605580  0\n",
      "492  -1.84110  10.83060   2.76900 -3.090100  0\n",
      "1289 -1.40940  -2.12520  -0.10397 -0.192250  1\n",
      "53    2.54900   6.14990  -1.16050 -1.237100  0\n",
      "1196 -2.01490   3.68740  -1.93850 -3.891800  1\n",
      "655   2.65620  10.70440  -3.30850 -4.076700  0\n",
      "1010 -2.99150  -6.62580   8.65210  1.819800  1\n",
      "1371 -2.54190  -0.65804   2.68420  1.195200  1\n",
      "666   1.22620   0.89599   5.75680 -0.115960  0\n",
      "\n",
      "[1372 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#shuffling and splitting of the dataset\n",
    "def split_data(data):\n",
    "    df = pd.DataFrame(data)\n",
    "    #shuffle the dataset\n",
    "    df = df.sample(frac=1)\n",
    "    #split the dataset\n",
    "    split = np.random.rand(len(df)) < 0.7\n",
    "    train = np.asmatrix(df[split], dtype = 'float64')\n",
    "    test = np.asmatrix(df[~split], dtype = 'float64')\n",
    "    X_train = train[:, :-1]\n",
    "    y_train = train[:, -1]\n",
    "    X_test = test[:, :-1]\n",
    "    y_test = test[:,-1]\n",
    "    print(df)\n",
    "    return X_train,y_train,X_test,y_test\n",
    "X_train,y_train,X_test,y_test = split_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T7NaB0L46YaZ"
   },
   "outputs": [],
   "source": [
    "#initializing params\n",
    "alpha = 0.7\n",
    "epoch = 100\n",
    "W = np.zeros(X_train.shape[1]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I0JXs9josyx0"
   },
   "outputs": [],
   "source": [
    "#activation function\n",
    "def activation(z):\n",
    "        if z>=0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Chqyq4s5tmB"
   },
   "outputs": [],
   "source": [
    " #prediction function\n",
    " def predict(x):\n",
    "    z = np.dot(x, W[1:]) + W[0]\n",
    "    g = activation(z)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "xlZw8sfe5weh",
    "outputId": "92e0367a-b7b2-404f-8ed3-3c392e4eff4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0  weight:[ 11.9        -16.82540755 -16.82540755 -16.82540755 -16.82540755]  learning rate:0.7  Training Accuracy:94.64285714285714\n",
      "epoch:1  weight:[ 18.2        -24.44324225 -24.44324225 -24.44324225 -24.44324225]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:2  weight:[ 25.2        -34.56333195 -34.56333195 -34.56333195 -34.56333195]  learning rate:0.7  Training Accuracy:95.58823529411765\n",
      "epoch:3  weight:[ 32.9       -46.9986685 -46.9986685 -46.9986685 -46.9986685]  learning rate:0.7  Training Accuracy:95.69327731092437\n",
      "epoch:4  weight:[ 41.3        -58.96945005 -58.96945005 -58.96945005 -58.96945005]  learning rate:0.7  Training Accuracy:95.58823529411765\n",
      "epoch:5  weight:[ 49.        -71.4047866 -71.4047866 -71.4047866 -71.4047866]  learning rate:0.7  Training Accuracy:95.69327731092437\n",
      "epoch:6  weight:[ 57.4        -83.37556815 -83.37556815 -83.37556815 -83.37556815]  learning rate:0.7  Training Accuracy:95.58823529411765\n",
      "epoch:7  weight:[ 65.1       -95.8109047 -95.8109047 -95.8109047 -95.8109047]  learning rate:0.7  Training Accuracy:95.69327731092437\n",
      "epoch:8  weight:[  73.5        -107.78168625 -107.78168625 -107.78168625 -107.78168625]  learning rate:0.7  Training Accuracy:95.58823529411765\n",
      "epoch:9  weight:[  81.9       -119.7524678 -119.7524678 -119.7524678 -119.7524678]  learning rate:0.7  Training Accuracy:95.58823529411765\n",
      "epoch:10  weight:[  90.3        -133.96713435 -133.96713435 -133.96713435 -133.96713435]  learning rate:0.7  Training Accuracy:95.58823529411765\n",
      "epoch:11  weight:[  99.4       -147.7172459 -147.7172459 -147.7172459 -147.7172459]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:12  weight:[ 108.5        -161.46735745 -161.46735745 -161.46735745 -161.46735745]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:13  weight:[ 117.6      -175.217469 -175.217469 -175.217469 -175.217469]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:14  weight:[ 126.7        -188.96758055 -188.96758055 -188.96758055 -188.96758055]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:15  weight:[ 135.8       -202.7176921 -202.7176921 -202.7176921 -202.7176921]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:16  weight:[ 144.9        -216.46780365 -216.46780365 -216.46780365 -216.46780365]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:17  weight:[ 154.        -230.2179152 -230.2179152 -230.2179152 -230.2179152]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:18  weight:[ 163.1        -243.96802675 -243.96802675 -243.96802675 -243.96802675]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:19  weight:[ 172.2       -257.7181383 -257.7181383 -257.7181383 -257.7181383]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:20  weight:[ 181.3        -271.46824985 -271.46824985 -271.46824985 -271.46824985]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:21  weight:[ 190.4       -285.2183614 -285.2183614 -285.2183614 -285.2183614]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:22  weight:[ 199.5        -298.96847295 -298.96847295 -298.96847295 -298.96847295]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:23  weight:[ 208.6       -312.7185845 -312.7185845 -312.7185845 -312.7185845]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:24  weight:[ 217.7        -326.46869605 -326.46869605 -326.46869605 -326.46869605]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:25  weight:[ 226.8       -340.2188076 -340.2188076 -340.2188076 -340.2188076]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:26  weight:[ 235.9        -353.96891915 -353.96891915 -353.96891915 -353.96891915]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:27  weight:[ 245.        -367.7190307 -367.7190307 -367.7190307 -367.7190307]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:28  weight:[ 254.1        -381.46914225 -381.46914225 -381.46914225 -381.46914225]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:29  weight:[ 263.2       -395.2192538 -395.2192538 -395.2192538 -395.2192538]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:30  weight:[ 272.3        -408.96936535 -408.96936535 -408.96936535 -408.96936535]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:31  weight:[ 281.4       -422.7194769 -422.7194769 -422.7194769 -422.7194769]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:32  weight:[ 290.5        -436.46958845 -436.46958845 -436.46958845 -436.46958845]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:33  weight:[ 299.6    -450.2197 -450.2197 -450.2197 -450.2197]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:34  weight:[ 308.7        -463.96981155 -463.96981155 -463.96981155 -463.96981155]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:35  weight:[ 317.8       -477.7199231 -477.7199231 -477.7199231 -477.7199231]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:36  weight:[ 326.9        -491.47003465 -491.47003465 -491.47003465 -491.47003465]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:37  weight:[ 336.        -505.2201462 -505.2201462 -505.2201462 -505.2201462]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:38  weight:[ 345.1        -518.97025775 -518.97025775 -518.97025775 -518.97025775]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:39  weight:[ 354.2       -532.7203693 -532.7203693 -532.7203693 -532.7203693]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:40  weight:[ 363.3        -546.47048085 -546.47048085 -546.47048085 -546.47048085]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:41  weight:[ 372.4       -560.2205924 -560.2205924 -560.2205924 -560.2205924]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:42  weight:[ 381.5        -573.97070395 -573.97070395 -573.97070395 -573.97070395]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:43  weight:[ 390.6       -587.7208155 -587.7208155 -587.7208155 -587.7208155]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:44  weight:[ 399.7        -601.47092705 -601.47092705 -601.47092705 -601.47092705]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:45  weight:[ 408.8       -615.2210386 -615.2210386 -615.2210386 -615.2210386]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:46  weight:[ 417.9        -628.97115015 -628.97115015 -628.97115015 -628.97115015]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:47  weight:[ 427.        -642.7212617 -642.7212617 -642.7212617 -642.7212617]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:48  weight:[ 436.1        -656.47137325 -656.47137325 -656.47137325 -656.47137325]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:49  weight:[ 445.2       -670.2214848 -670.2214848 -670.2214848 -670.2214848]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:50  weight:[ 454.3        -683.97159635 -683.97159635 -683.97159635 -683.97159635]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:51  weight:[ 463.4       -697.7217079 -697.7217079 -697.7217079 -697.7217079]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:52  weight:[ 472.5        -711.47181945 -711.47181945 -711.47181945 -711.47181945]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:53  weight:[ 481.6      -725.221931 -725.221931 -725.221931 -725.221931]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:54  weight:[ 490.7        -738.97204255 -738.97204255 -738.97204255 -738.97204255]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:55  weight:[ 499.8       -752.7221541 -752.7221541 -752.7221541 -752.7221541]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:56  weight:[ 508.9        -766.47226565 -766.47226565 -766.47226565 -766.47226565]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:57  weight:[ 518.        -780.2223772 -780.2223772 -780.2223772 -780.2223772]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:58  weight:[ 527.1        -793.97248875 -793.97248875 -793.97248875 -793.97248875]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:59  weight:[ 536.2       -807.7226003 -807.7226003 -807.7226003 -807.7226003]  learning rate:0.7  Training Accuracy:95.48319327731093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:60  weight:[ 545.3        -821.47271185 -821.47271185 -821.47271185 -821.47271185]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:61  weight:[ 554.4       -835.2228234 -835.2228234 -835.2228234 -835.2228234]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:62  weight:[ 563.5        -848.97293495 -848.97293495 -848.97293495 -848.97293495]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:63  weight:[ 572.6       -862.7230465 -862.7230465 -862.7230465 -862.7230465]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:64  weight:[ 581.7        -876.47315805 -876.47315805 -876.47315805 -876.47315805]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:65  weight:[ 590.8       -890.2232696 -890.2232696 -890.2232696 -890.2232696]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:66  weight:[ 599.9        -903.97338115 -903.97338115 -903.97338115 -903.97338115]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:67  weight:[ 609.        -917.7234927 -917.7234927 -917.7234927 -917.7234927]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:68  weight:[ 618.1        -931.47360425 -931.47360425 -931.47360425 -931.47360425]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:69  weight:[ 627.2       -945.2237158 -945.2237158 -945.2237158 -945.2237158]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:70  weight:[ 636.3        -958.97382735 -958.97382735 -958.97382735 -958.97382735]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:71  weight:[ 645.4       -972.7239389 -972.7239389 -972.7239389 -972.7239389]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:72  weight:[ 654.5        -986.47405045 -986.47405045 -986.47405045 -986.47405045]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:73  weight:[  663.6      -1000.224162 -1000.224162 -1000.224162 -1000.224162]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:74  weight:[  672.7        -1013.97427355 -1013.97427355 -1013.97427355\n",
      " -1013.97427355]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:75  weight:[  681.8       -1027.7243851 -1027.7243851 -1027.7243851 -1027.7243851]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:76  weight:[  690.9        -1041.47449665 -1041.47449665 -1041.47449665\n",
      " -1041.47449665]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:77  weight:[  700.        -1055.2246082 -1055.2246082 -1055.2246082 -1055.2246082]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:78  weight:[  709.1        -1068.97471975 -1068.97471975 -1068.97471975\n",
      " -1068.97471975]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:79  weight:[  718.2       -1082.7248313 -1082.7248313 -1082.7248313 -1082.7248313]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:80  weight:[  727.3        -1096.47494285 -1096.47494285 -1096.47494285\n",
      " -1096.47494285]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:81  weight:[  736.4       -1110.2250544 -1110.2250544 -1110.2250544 -1110.2250544]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:82  weight:[  745.5        -1123.97516595 -1123.97516595 -1123.97516595\n",
      " -1123.97516595]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:83  weight:[  754.6       -1137.7252775 -1137.7252775 -1137.7252775 -1137.7252775]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:84  weight:[  763.7        -1151.47538905 -1151.47538905 -1151.47538905\n",
      " -1151.47538905]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:85  weight:[  772.8       -1165.2255006 -1165.2255006 -1165.2255006 -1165.2255006]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:86  weight:[  781.9        -1178.97561215 -1178.97561215 -1178.97561215\n",
      " -1178.97561215]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:87  weight:[  791.        -1192.7257237 -1192.7257237 -1192.7257237 -1192.7257237]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:88  weight:[  800.1        -1206.47583525 -1206.47583525 -1206.47583525\n",
      " -1206.47583525]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:89  weight:[  809.2       -1220.2259468 -1220.2259468 -1220.2259468 -1220.2259468]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:90  weight:[  818.3        -1233.97605835 -1233.97605835 -1233.97605835\n",
      " -1233.97605835]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:91  weight:[  827.4       -1247.7261699 -1247.7261699 -1247.7261699 -1247.7261699]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:92  weight:[  836.5        -1261.47628145 -1261.47628145 -1261.47628145\n",
      " -1261.47628145]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:93  weight:[  845.6      -1275.226393 -1275.226393 -1275.226393 -1275.226393]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:94  weight:[  854.7        -1288.97650455 -1288.97650455 -1288.97650455\n",
      " -1288.97650455]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:95  weight:[  863.8       -1302.7266161 -1302.7266161 -1302.7266161 -1302.7266161]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:96  weight:[  872.9        -1316.47672765 -1316.47672765 -1316.47672765\n",
      " -1316.47672765]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:97  weight:[  882.        -1330.2268392 -1330.2268392 -1330.2268392 -1330.2268392]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:98  weight:[  891.1        -1343.97695075 -1343.97695075 -1343.97695075\n",
      " -1343.97695075]  learning rate:0.7  Training Accuracy:95.48319327731093\n",
      "epoch:99  weight:[  900.2       -1357.7270623 -1357.7270623 -1357.7270623 -1357.7270623]  learning rate:0.7  Training Accuracy:95.48319327731093\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3de5xU9X3/8debZbmICLIsXgBFFC/sRshKrFZFY5JHlRgTjWmMxaRGo2mNwaa2sYltjE3705jES5pa723UahNJGzUJ1Bprml+qBhR0F4ISRbOC7IKAIOLOzn76x5xdF9gbu3tm4Mz7+XjMY2fOOd853xkO+97v5ZyjiMDMzKy/hpS6AmZmtmdzkJiZ2YA4SMzMbEAcJGZmNiAOEjMzGxAHiZmZDYiDxKwHkiokbZF00GBu2496fEPSPw/2+5oNhqGlroDZYJK0pdPLvYB3gHzy+pKIuG9X3i8i8sDeg72tWZY4SCxTIqLjF7mkVcBFEfFf3W0vaWhEtBajbmZZ5a4tKytJF9G/Sbpf0mZgrqTjJT0paaOkNZJullSZbD9UUkiakry+N1n/M0mbJf2vpEN2ddtk/emSXpC0SdJ3Jf1/SX/cx8/xMUkNSZ1/LumITuu+Imm1pDcl/UbSKcny4yQ9kyxfK+n6QfhKzRwkVpbOAv4VGAP8G9AKzAPGAycApwGX9FD+POCvgXHAq8Df7uq2kiYAPwD+Itnvy8Cxfam8pKOAe4HLgGrgv4CHJVVKqknqXhcR+wCnJ/sF+C5wfbL8MODBvuzPrDcOEitHv4yIhyOiLSLejohfR8RTEdEaES8BtwEn91D+wYhYFBE54D5gZj+2PQNYEhE/TtbdAKzrY/3PBR6KiJ8nZa8F9gF+j0IojgBqkm67l5PPBJADpkmqiojNEfFUH/dn1iMHiZWj33V+IelIST+R9LqkN4FrKLQSuvN6p+db6XmAvbttD+xcjyhcPbWxD3VvL/tKp7JtSdmJEbEC+HMKn6Ep6cLbP9n0AmA6sELS05Lm9HF/Zj1ykFg52vGS17cC9cBhSbfP3wBKuQ5rgEntLyQJmNjHsquBgzuVHZK812sAEXFvRJwAHAJUAP8vWb4iIs4FJgDfBuZLGjHwj2LlzkFiBqOBTcBbyfhDT+Mjg+URoE7SRyQNpTBGU93Hsj8AzpR0SjIp4C+AzcBTko6S9H5Jw4G3k0ceQNL5ksYnLZhNFAK1bXA/lpUjB4lZoSvoMxR+Gd9KYQA+VRGxFvgk8B1gPXAo8CyF8156K9tAob63AM0UJgecmYyXDAe+SWG85XVgX+CqpOgcYHkyW+1bwCcjomUQP5aVKfnGVmalJ6mCQpfVORHxP6Wuj9mucIvErEQknSZpTNIN9dcUZlw9XeJqme0yB4lZ6ZwIvEShG+o04GMR0WvXltnuxl1bZmY2IG6RmJnZgGTqoo3jx4+PKVOmlLoaZmZ7jMWLF6+LiL5OPe9SpoJkypQpLFq0qNTVMDPbY0h6pfeteuauLTMzGxAHiZmZDYiDxMzMBiRTYyRmtvvJ5XI0Njaybdu2UlelrI0YMYJJkyZRWVk56O/tIDGzVDU2NjJ69GimTJlC4SLHVmwRwfr162lsbOSQQw7pvcAucteWmaVq27ZtVFVVOURKSBJVVVWptQodJGaWOodI6aX5b1DWQfKr3/2KxasXd7nuvufu442339hp+cZtG7ln6T340jJmZgVlHSQXPXQRX1zwxZ2Wr3xjJXP/fS63L759p3V3P3s3n/6PT/Obdb8pRhXNbIDWr1/PzJkzmTlzJvvvvz8TJ07seN3S0rfbsVxwwQWsWLGix22+973vcd999w1GlTnxxBNZsmTJoLxXMZTtYPs7re/wwvoXGDVsFBGxXbPv+bXPA1DfXL9TueebknVN9RxVfVRxKmtm/VZVVdXxS/nqq69m77335oorrthum4ggIhgypOu/re++++5e93PppZcOvLJ7qLJtkaxYv4J85HnznTd5bfNr261raG4o/Gxq2Klcx7rmndeZ2Z5j5cqV1NbW8vnPf566ujrWrFnDxRdfzKxZs6ipqeGaa67p2La9hdDa2srYsWO58sormTFjBscffzxNTU0AXHXVVdx4440d21955ZUce+yxHHHEEfzqV78C4K233uLjH/84M2bM4FOf+hSzZs3qteVx77338p73vIfa2lq+8pWvANDa2sr555/fsfzmm28G4IYbbmD69OnMmDGDuXPnDvp31p2ybZF0Don6pnom7TPp3XVJSCxft5x8W56KIRUAtEVbRzkHidmuu3zB5Sx5fXC7bGbuP5MbT7uxX2WXLVvG3XffzT/90z8BcO211zJu3DhaW1t5//vfzznnnMP06dO3K7Np0yZOPvlkrr32Wr70pS9x1113ceWVV+703hHB008/zUMPPcQ111zDggUL+O53v8v+++/P/PnzWbp0KXV1dT3Wr7GxkauuuopFixYxZswYPvjBD/LII49QXV3NunXreP75Qg/Jxo0bAfjmN7/JK6+8wrBhwzqWFUPZtkjqm+oRhe6sHVse9U31DNEQtrVu46UNL3Usf3XTq7yVe4shGkJ9087dXma2Zzn00EN53/ve1/H6/vvvp66ujrq6OpYvX86yZct2KjNy5EhOP/10AI455hhWrVrV5XufffbZO23zy1/+knPPPReAGTNmUFNT02P9nnrqKU499VTGjx9PZWUl5513Hr/4xS847LDDWLFiBfPmzWPhwoWMGTMGgJqaGubOnct9992XyomH3SnfFklzA0eMP4INb2/YrnWRy+dYsW4FJx98Mo+vepyG5gamVU0rlEkC5+SDT+YXr/yCd1rfYfjQ4SWpv9meqL8th7SMGjWq4/mLL77ITTfdxNNPP83YsWOZO3dul+ddDBs2rON5RUUFra2tXb738OHDd9pmV2d7drd9VVUVzz33HD/72c+4+eabmT9/PrfddhsLFy7kiSee4Mc//jHf+MY3qK+vp6KiYpf22R9l3SKpnVBL7YTa7VoXK99YSa4txyemf6Jju85lAP6w5g/JR54V63uexWFme44333yT0aNHs88++7BmzRoWLlw46Ps48cQT+cEPfgDA888/32WLp7PjjjuOxx9/nPXr19Pa2soDDzzAySefTHNzMxHBJz7xCb7+9a/zzDPPkM/naWxs5NRTT+X666+nubmZrVu3Dvpn6EpZtki25rby0oaXmHv0XDa8vYE7n72Ttmjbrsvq9yb9HlPGTtmutdLQ3MDE0RM5YfIJhddNDRy939El+QxmNrjq6uqYPn06tbW1TJ06lRNOOGHQ93HZZZfx6U9/mqOPPpq6ujpqa2s7uqW6MmnSJK655hpOOeUUIoKPfOQjfPjDH+aZZ57hwgsv7Jhxet1119Ha2sp5553H5s2baWtr48tf/jKjR48e9M/QpfZpb1l4HHPMMdEXi1cvDq4mftjww7h10a3B1cTLG16OiIivPf610NWKrS1b44x/PSPe84/v6ShXd2td/ME9fxDvtL4TQ68ZGl997Kt92p9ZOVu2bFmpq7DbyOVy8fbbb0dExAsvvBBTpkyJXC5XtP139W8BLIoB/u4tyxZJe6ujprqGDds2dCxrb4EcOu5QRlaOpKa6hoUrF5LL5xiiISxrXsafzvpThlUMY9q4aR5wN7NdsmXLFj7wgQ/Q2tpKRHDrrbcydOie/2t4z/8E/dDQ1EDlkEoOG3cYb+Xe6lh2xuFn0NDUQE11YSZFTXUNubYcK99YSWVFJdtat1EzIVk3oWbQpzGaWbaNHTuWxYu7vizTnqwsB9sbmhs4cvyRVFZUMnbEWCaOnkhDc0PH2e61E2oBOn42NDd0zNjqWFddy2/f+C1v594uzYcw24OEr01Xcmn+G5RlkNQ31Xe0LKDQuqhvqueF9S+Qj3xHi+TI8Ud2DMC3d2NNr57eUSYIlq9bXvwPYLYHGTFiBOvXr3eYlFAk9yMZMWJEKu9fdl1bW1q28MqmV7io7qKOZbXVtfzjK//Ic2ufA+gImZGVI5m671QamgtdYQePOZi9h+1d2CYJm4amBuoO6PnsVLNyNmnSJBobG2lubi51Vcpa+x0S01B2QbKsuTBvu72LCgrBsa11Gw+/8DAVquCIqiM61rWfZ1I5pHK7MoeNO4xhFcN8qRSzXlRWVqZyVz7bfaTatSVpnqR6SQ2SLk+WXS3pNUlLksecbsqOlfSgpN9IWi7p+MGoU+cZW+3anz/8wsNMq5q23dnqNdU1vLj+RVasX7FdmcqKSo6oOsIzt8ys7KXWIpFUC3wOOBZoARZI+kmy+oaI+FYvb3ETsCAizpE0DNhrMOrV0NTAiKEjmLrv1I5l7eMeW3NbtwsLKARJPvLk8/ntxlWg0JJ5svHJwaiWmdkeK80WyVHAkxGxNSJagSeAs/pSUNI+wGzgToCIaImIQbmUZUNzA0eNP6rjir4Ao4eP5uAxBwPbd3nt+HqnddW1rNq4ii0tWwajamZme6Q0g6QemC2pStJewBxgcrLuC5Kek3SXpH27KDsVaAbulvSspDskjepiOyRdLGmRpEV9GczbccZWu47zQ3ZokRxedTgVqkCII8cf2WWZ9nEXM7NylFrXVkQsl3Qd8CiwBVgKtAK3AH8LRPLz28Bnu6hXHXBZRDwl6SbgSuCvu9jPbcBtALNmzepxfuHGbRt5bfNr1FbX7rSutrqWn774051aHcOHDufwqsPJteXYq3L73rX2bS986EImjJqw03uOGzmO73/s+4ysHNlTtczM9mipztqKiDtJuqck/T3QGBFr29dLuh14pIuijcm2TyWvH6QQJAPS3nLoqkVy3nvOY+O2jRxedfhO6750/JfIt+V3Wj5136nMPXouqzauoiW//b2fN7+zmZ+//HMuO/YyZh88e6BVNzPbbaUaJJImRESTpIOAs4HjJR0QEWuSTc6i0AW2nYh4XdLvJB0RESuADwAD7j/qasZWuxn7z+DWj9zaZbnO55x0NkRDuOese7pc1/hmI5NvmEx9U72DxMwyLe3zSOZLqgJywKURsUHSPZJmUujaWgVcAiDpQOCOiGifDnwZcF8yY+sl4IKBVqahqYFRlaM4eOzBA32rXk0cPZExw8d0ed93M7MsSbtr66Qulp3fzbarKQzIt79eAswazPo0NDcwvXo6Q5T+lWEkFS690uzzTMws28rqWlvdzdhKS011DQ1NDb7GkJllWtkEybqt61j71touZ2ylpXZCLevfXk/TW01F26eZWbGVTZC0j1UUu0UC+DIqZpZp5RMkzdvfT6QY2kPLF3Y0sywrnyBpamCf4fswcfTEou1zv1H7UTWyyjO3zCzTyiZI6pvrqamuQVLR9umZW2ZWDsoiSCKChqaGonZrtfPMLTPLurIIkqa3mlj/9vouz2hPW+2EWja9s4nVm1cXfd9mZsVQFkHScWmUIs7YaueZW2aWdWURJKWYsdXOM7fMLOvKI0iaGhg3chz7jdqv6Psev9d49hu1n2dumVlmlUWQ1DfXUzuhtqgztjrzzC0zy7LMB0n7jK1SDLS3q62uZVnzMtqirWR1MDNLS+aDZPXm1Wx6Z1NJg6RmQg1bWrbw6qZXS1YHM7O0ZD5I2mdLlWKgvV17iHmcxMyyKO0bW5Xc8nXLAZhePb1kdWifufXRBz5KxZCKktXDzCwNmQ+Sjds2AlC1V1XJ6jB2xFjuPPNOXlz/YsnqYGbWlWu5dsDvkfkgyeVzVKiiKHdF7Mln3/vZku7fzKwrgxEkmR8jacm3MKxiWKmrYWaWWZkPklxbjsqKylJXw8wss7IfJPkclUMcJGZmacl8kLhry8wsXZkPEndtmZmlK/NB4haJmVm6Mh8kuTaPkZiZpSnzQeIWiZlZujIfJLm8x0jMzNKU/SBx15aZWapSDRJJ8yTVS2qQdHmy7GpJr0lakjzm9FC+QtKzkh7pbx3ctWVmlq7UrrUlqRb4HHAs0AIskPSTZPUNEfGtPrzNPGA5sE9/65HL5xg1bFR/i5uZWS/SbJEcBTwZEVsjohV4Ajirr4UlTQI+DNwxkEq4RWJmlq40g6QemC2pStJewBxgcrLuC5Kek3SXpH27KX8j8JdAj/enlXSxpEWSFjU3N++03mMkZmbpSi1IImI5cB3wKLAAWAq0ArcAhwIzgTXAt3csK+kMoCkiFvdhP7dFxKyImFVdXb3Tes/aMjNLV6qD7RFxZ0TURcRs4A3gxYhYGxH5iGgDbqcwhrKjE4AzJa0CHgBOlXRvf+rgri0zs3SlPWtrQvLzIOBs4H5JB3Ta5CwKXWDbiYi/iohJETEFOBf4eUTM7U8d3LVlZpautO+QOF9SFZADLo2IDZLukTQTCGAVcAmApAOBOyKi2+nA/eEWiZlZulINkog4qYtl53ez7WoKA/I7Lv9v4L/7Wwffj8TMLF2ZP7PdLRIzs3RlPkh8PxIzs3RlP0jctWVmlqpMB0lbtJGPvLu2zMxSlOkgyeVzAO7aMjNLUaaDpCXfAuAWiZlZijIdJLm2pEXiMRIzs9RkOkjcIjEzS1+mg8RjJGZm6ct2kLhry8wsdZkOEndtmZmlL9NB4q4tM7P0ZTpI3CIxM0tfpoPEYyRmZunLdpC4a8vMLHWZDhJ3bZmZpS/TQeKuLTOz9GU6SNwiMTNLX6aDxGMkZmbpy3SQuEViZpa+TAeJx0jMzNKX7SBx15aZWeoyHSTu2jIzS1+mg8RdW2Zm6ct0kLhFYmaWvkwHicdIzMzSl+0gcdeWmVnqMh0kLfkWhmgIFUMqSl0VM7PMynSQ5PI5t0bMzFKWapBImiepXlKDpMuTZVdLek3SkuQxp4tykyU9Lml5UnZef/bfkm/xQLuZWcqG9mUjSYcCjRHxjqRTgKOB70fExh7K1AKfA44FWoAFkn6SrL4hIr7Vwy5bgT+PiGckjQYWS3o0Ipb1pb7tcm05D7SbmaWsry2S+UBe0mHAncAhwL/2UuYo4MmI2BoRrcATwFl92VlErImIZ5Lnm4HlwMQ+1rWDWyRmZunra5C0JWFwFnBjRPwZcEAvZeqB2ZKqJO0FzAEmJ+u+IOk5SXdJ2renN5E0BXgv8FQ36y+WtEjSoubm5u3W5do8RmJmlra+BklO0qeAzwCPJMt6/A0dEcuB64BHgQXAUgpdVrcAhwIzgTXAt7t7D0l7U2gNXR4Rb3azn9siYlZEzKqurt6+0nl3bZmZpa2vQXIBcDzwdxHxsqRDgHt7KxQRd0ZEXUTMBt4AXoyItRGRj4g24HYKYyg7kVRJIUTui4gf9bGe23HXlplZ+vo02J4Mcn8RIOmKGh0R1/ZWTtKEiGiSdBBwNnC8pAMiYk2yyVkUusB2LCcKYzHLI+I7ffsoO3PXlplZ+vo6a+u/gTOT7ZcAzZKeiIgv9VJ0vqQqIAdcGhEbJN0jaSYQwCrgkmQfBwJ3RMQc4ATgfOB5SUuS9/pKRPx0Vz6cWyRmZunrU5AAYyLiTUkXAXdHxNckPddboYg4qYtl53ez7WoKA/JExC8B9bFu3fIYiZlZ+vo6RjJU0gHAH/LuYPtuzy0SM7P09TVIrgEWAr+NiF9Lmgq8mF61BofHSMzM0tfXwfYfAj/s9Pol4ONpVWqw5PI59hm+T6mrYWaWaX1qkUiaJOnfJTVJWitpvqRJaVduoNy1ZWaWvr52bd0NPAQcSOFSJQ8ny3Zr7toyM0tfX4OkOiLujojW5PHPQHVvhUrNLRIzs/T1NUjWSZorqSJ5zAXWp1mxweDpv2Zm6etrkHyWwtTf1ylcH+scCpdN2a3l2nIMG+IWiZlZmvoUJBHxakScGRHVETEhIj5G4ZInu7WWfItbJGZmKRvIHRJ7uzxKyflWu2Zm6RtIkAz4EiZp82C7mVn6BhIkMWi1SIlvtWtmlr4ez2yXtJmuA0PAyFRqNEgigta2VrdIzMxS1mOQRMToYlVksOXacgAeIzEzS9lAurZ2a7l8EiTu2jIzS1Vmg6Ql3wLgri0zs5RlNkjctWVmVhyZDRK3SMzMiiOzQeIxEjOz4shukCRdW26RmJmlK7NB0t615TESM7N0ZTZI3LVlZlYcmQ0SD7abmRVHZoPE03/NzIojs0HiFomZWXFkNkg8RmJmVhzZDRJP/zUzK4rMBomn/5qZFUdmg8RdW2ZmxZFqkEiaJ6leUoOky5NlV0t6TdKS5DGnm7KnSVohaaWkK3d13x5sNzMrjh5vbDUQkmqBzwHHAi3AAkk/SVbfEBHf6qFsBfA94ENAI/BrSQ9FxLK+7t/Tf83MiiPNFslRwJMRsTUiWoEngLP6WPZYYGVEvBQRLcADwEd3ZeftXVtukZiZpSvNIKkHZkuqkrQXMAeYnKz7gqTnJN0lad8uyk4EftfpdWOybCeSLpa0SNKi5ubmjuUdg+0eIzEzS1VqQRIRy4HrgEeBBcBSoBW4BTgUmAmsAb7dRXF19Zbd7Oe2iJgVEbOqq6s7lrtry8ysOFIdbI+IOyOiLiJmA28AL0bE2ojIR0QbcDuFbqwdNfJu6wVgErB6V/btwXYzs+JIe9bWhOTnQcDZwP2SDui0yVkUusB29GtgmqRDJA0DzgUe2pV9e/qvmVlxpDZrKzFfUhWQAy6NiA2S7pE0k0JX1SrgEgBJBwJ3RMSciGiV9AVgIVAB3BURDbuy45Z8C0JUqGIwP4+Zme0g1SCJiJO6WHZ+N9uupjAg3/76p8BP+7vvXFuOyopKpK6GW8zMbLBk+sx2j4+YmaUvs0HSkm/xjC0zsyLIbJC0d22ZmVm6MhskLfkWd22ZmRVBZoMk15Zz15aZWRFkNkjcIjEzK47MBkku7zESM7NiyG6QuGvLzKwoMhsk7toyMyuOzAaJu7bMzIojs0HiFomZWXFkNkg8RmJmVhzZDRJfa8vMrCgyGyQt+RaPkZiZFUFmg8RdW2ZmxZHZIPFgu5lZcWQ2SHJ5t0jMzIohs0HiFomZWXFkNkh8PxIzs+LIbpB4+q+ZWVFkNkh8q10zs+LIZJBEhLu2zMyKJJNB0trWCuCuLTOzIshkkOTacgDu2jIzK4JsBkm+ECRukZiZpS+TQdKSbwHwGImZWRFkMkjctWVmVjyZDJL2Fom7tszM0pdqkEiaJ6leUoOky3dYd4WkkDS+m7LfTMotl3SzJPV1v+1jJO7aMjNLX2pBIqkW+BxwLDADOEPStGTdZOBDwKvdlP194ATgaKAWeB9wcl/37RaJmVnxpNkiOQp4MiK2RkQr8ARwVrLuBuAvgeimbAAjgGHAcKASWNvXHXuMxMyseNIMknpgtqQqSXsBc4DJks4EXouIpd0VjIj/BR4H1iSPhRGxvKttJV0saZGkRc3NzYCn/5qZFVNqQZL84r8OeBRYACwFWoGvAn/TU1lJh1Fo0UwCJgKnSprdzX5ui4hZETGruroa8PRfM7NiSnWwPSLujIi6iJgNvAGsAg4BlkpaRSEonpG0/w5Fz6LQLbYlIrYAPwOO6+t+3bVlZlY8ac/ampD8PAg4G/h+REyIiCkRMQVoBOoi4vUdir4KnCxpqKRKCgPtXXZtdcWD7WZmxZP2eSTzJS0DHgYujYgN3W0oaZakO5KXDwK/BZ6n0CW2NCIe7utOPf3XzKx4hqb55hFxUi/rp3R6vgi4KHmeBy7p737dIjEzK55MntnuMRIzs+LJZpB4+q+ZWdFkMkg8/dfMrHgyGSTu2jIzK55MBokH283MiieTQeLpv2ZmxZPNIGnzYLuZWbFkMkg6Bts9RmJmlrpMBkl719bQIameb2lmZmQ0SFryLVQOqWQXbqpoZmb9lMkgybXlPNBuZlYkmQySlnyLB9rNzIokk0GSy+c80G5mViTZDJK2nFskZmZFkskgacm3eIzEzKxIMhkkuTZ3bZmZFUsmg8SD7WZmxZPJIMnlPf3XzKxYshkkHmw3MyuaTAZJ+5ntZmaWvkwGSS7vFomZWbFkMkg8/dfMrHgyGSSe/mtmVjyZDBJP/zUzK55M3rDjQ1M/xMTRE0tdDTOzspDJIPnOH3yn1FUwMysbmezaMjOz4nGQmJnZgDhIzMxsQFINEknzJNVLapB0+Q7rrpAUksZ3U/YgSf8pabmkZZKmpFlXMzPrn9SCRFIt8DngWGAGcIakacm6ycCHgFd7eIvvA9dHxFHJezSlVVczM+u/NFskRwFPRsTWiGgFngDOStbdAPwlEF0VlDQdGBoRjwJExJaI2JpiXc3MrJ/SDJJ6YLakKkl7AXOAyZLOBF6LiKU9lD0c2CjpR5KelXS9pIquNpR0saRFkhY1NzcP/qcwM7MepRYkEbEcuA54FFgALAVaga8Cf9NL8aHAScAVwPuAqcAfd7Of2yJiVkTMqq6uHpzKm5lZnymiy96lwd+R9PfAWgpB0t5NNQlYDRwbEa932vY44NqIOCV5fT5wXERc2ss+NgMrBr/2e6TxwLpSV2I34O/hXf4u3uXv4l1HRMTogbxBqme2S5oQEU2SDgLOBo6PiJs6rV8FzIqIHf9Bfw3sK6k6IpqBU4FFfdjlioiYNUjV36NJWuTvwt9DZ/4u3uXv4l2S+vK7tUdpn0cyX9Iy4GHg0ojY0N2GkmZJugMgIvIUurUek/Q8IOD2lOtqZmb9kGqLJCJO6mX9lE7PFwEXdXr9KHB0apUzM7NBkbUz228rdQV2I/4uCvw9vMvfxbv8XbxrwN9F0Qbbzcwsm7LWIjEzsyJzkJiZ2YBkIkgknSZphaSVkq4sdX2KSdJkSY8nF7dskDQvWT5O0qOSXkx+7lvquhaLpIrkigiPJK8PkfRU8l38m6SyuA+zpLGSHpT0m+T4OL5cjwtJf5b8/6iXdL+kEeVyXEi6S1KTpPpOy7o8DlRwc/K79DlJdX3Zxx4fJMmlU74HnA5MBz6VXKurXLQCf55c3PI44NLk818JPBYR04DHktflYh6wvNPr64Abku9iA3BhSWpVfDcBCyLiSAoXTl1OGR4XkiYCX6RwzlotUAGcS/kcF/8MnLbDsu6Og9OBacnjYuCWvuxgjw8SClcGXhkRL0VEC/AA8NES16loImJNRDyTPN9M4ZfFRArfwb8km/0L8LHS1LC4JE0CPgzckbwWhRNaH0w2KYvvQtI+wGzgToCIaImIjZTpcbH0Q7gAAAQlSURBVEHhVIeRkoYCewFrKJPjIiJ+Abyxw+LujoOPAt+PgieBsZIO6G0fWQiSicDvOr1uTJaVneSeLe8FngL2i4g1UAgbYELpalZUN1K4snRb8roK2JhcgRrK5/iYCjQDdyfdfHdIGkUZHhcR8RrwLQq3rVgDbAIWU57HRbvujoN+/T7NQpCoi2VlN6dZ0t7AfODyiHiz1PUpBUlnAE0Rsbjz4i42LYfjYyhQB9wSEe8F3qIMurG6kvT/fxQ4BDgQGEWhC2dH5XBc9KZf/1+yECSNwOROr9svBFk2JFVSCJH7IuJHyeK17U3S5Gc53BjsBODM5BpuD1DouriRQvO8/SoO5XJ8NAKNEfFU8vpBCsFSjsfFB4GXI6I5InLAj4DfpzyPi3bdHQf9+n2ahSD5NTAtmYExjMIg2kMlrlPRJGMAdwLLI+I7nVY9BHwmef4Z4MfFrluxRcRfRcSk5NI75wI/j4g/Ah4Hzkk2K5fv4nXgd5KOSBZ9AFhGGR4XFLq0jpO0V/L/pf27KLvjopPujoOHgE8ns7eOAza1d4H1JBNntkuaQ+Evzwrgroj4uxJXqWgknQj8D/A8744LfIXCOMkPgIMo/Ef6RETsOOCWWZJOAa6IiDMkTaXQQhkHPAvMjYh3Slm/YpA0k8Kkg2HAS8AFFP54LLvjQtLXgU9SmOX4LIXr+k2kDI4LSfcDp1C4dP5a4GvAf9DFcZAE7T9QmOW1FbgguQ5iz/vIQpCYmVnpZKFry8zMSshBYmZmA+IgMTOzAXGQmJnZgDhIzMxsQBwkZr2QlJe0pNNj0M4QlzSl81VZzfZEqd6z3Swj3o6ImaWuhNnuyi0Ss36StErSdZKeTh6HJcsPlvRYcj+HxyQdlCzfT9K/S1qaPH4/easKSbcn98v4T0kjk+2/KGlZ8j4PlOhjmvXKQWLWu5E7dG19stO6NyPiWApnA9+YLPsHCpfiPhq4D7g5WX4z8EREzKBw3auGZPk04HsRUQNsBD6eLL8SeG/yPp9P68OZDZTPbDfrhaQtEbF3F8tXAadGxEvJhTNfj4gqSeuAAyIilyxfExHjJTUDkzpfhiO59P+jyQ2GkPRloDIiviFpAbCFwuUs/iMitqT8Uc36xS0Ss4GJbp53t01XOl/fKc+7Y5cfpnD3z2OAxZ2uVGu2W3GQmA3MJzv9/N/k+a8oXH0Y4I+AXybPHwP+BDruK79Pd28qaQgwOSIep3CjrrHATq0is92B/8Ix691ISUs6vV4QEe1TgIdLeorCH2WfSpZ9EbhL0l9QuEvhBcnyecBtki6k0PL4Ewp37OtKBXCvpDEUbjZ0Q3KrXLPdjsdIzPopGSOZFRHrSl0Xs1Jy15aZmQ2IWyRmZjYgbpGYmdmAOEjMzGxAHCRmZjYgDhIzMxsQB4mZmQ3I/wHtDLglXh1dWgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " #training to learn the weights\n",
    " def train(X_train, y_train):\n",
    "        loss_train = []\n",
    "        epochs = range(1,epoch+1)\n",
    "        for i in range(epoch):\n",
    "            correct = 0\n",
    "            for x, y in zip(X_train, y_train):\n",
    "                prediction = predict(x)\n",
    "                y = np.array(y)[0][0]\n",
    "                x = np.array(x)[0]\n",
    "                error = y - prediction\n",
    "                actual_value = int(y)\n",
    "                if actual_value == prediction:\n",
    "                  correct += 1\n",
    "                W[1:] += alpha * error * x[0]\n",
    "                W[0] += alpha * error\n",
    "            training_accuracy =  correct/float(X_train.shape[0])*100.0      \n",
    "            loss_train.append(training_accuracy)\n",
    "            print(\"epoch:\"+str(i)+\"  weight:\"+str(W)+\"  learning rate:\"+str(alpha)+\"  Training Accuracy:\"+str(training_accuracy))\n",
    "        plt.plot(epochs, loss_train, 'g', label='Training loss')        \n",
    "        plt.xlim(0,epoch)\n",
    "        plt.title('Training loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "train(X_train, y_train)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "04HqxpXN52es",
    "outputId": "4942797e-b57d-4670-9f7e-21bb41c568f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on test data:\n",
      "X: [[-2.0529   3.8385  -0.79544 -1.2138 ]] prediction: 1 Actual value:1\n",
      "X: [[ 1.1811   8.3847  -2.0567  -0.90345]] prediction: 0 Actual value:0\n",
      "X: [[ 3.4626  -4.449    3.5427   0.15429]] prediction: 0 Actual value:0\n",
      "X: [[ -4.6338 -12.7509  16.7166  -3.2168]] prediction: 1 Actual value:1\n",
      "X: [[ 2.4196   6.4665  -0.75688  0.228  ]] prediction: 0 Actual value:0\n",
      "X: [[-2.2261 12.5398  2.9438 -3.5258]] prediction: 0 Actual value:0\n",
      "X: [[ 4.1736   3.3336  -1.4244   0.60429]] prediction: 0 Actual value:0\n",
      "X: [[-1.2369  -1.6906   2.518    0.51636]] prediction: 1 Actual value:1\n",
      "X: [[ 3.7935  7.9853 -2.5477 -1.872 ]] prediction: 0 Actual value:0\n",
      "X: [[ 4.616  10.1788 -4.2185 -4.4245]] prediction: 0 Actual value:0\n",
      "X: [[-2.5373 -6.959   8.8054  1.5289]] prediction: 0 Actual value:1\n",
      "X: [[2.1948  1.3781  1.1582  0.85774]] prediction: 0 Actual value:0\n",
      "X: [[ 0.49571 10.2243  -1.097   -4.0159 ]] prediction: 0 Actual value:0\n",
      "X: [[ -3.73   -12.9723  12.9817  -2.684 ]] prediction: 1 Actual value:1\n",
      "X: [[ 5.262   3.9834 -1.5572  1.0103]] prediction: 0 Actual value:0\n",
      "X: [[ 1.9476 -4.7738  8.527  -1.8668]] prediction: 0 Actual value:0\n",
      "X: [[ 4.5691e+00 -4.4552e+00  3.1769e+00  4.2961e-03]] prediction: 0 Actual value:0\n",
      "X: [[ 2.3678  -6.839    8.4207  -0.44829]] prediction: 0 Actual value:0\n",
      "X: [[-4.3967   4.9601  -0.64892 -5.4719 ]] prediction: 1 Actual value:1\n",
      "X: [[ 3.7767  9.7794 -3.9075 -3.5323]] prediction: 0 Actual value:0\n",
      "X: [[ 1.9321   6.0423   0.26019 -2.053  ]] prediction: 0 Actual value:0\n",
      "X: [[ -3.9411 -12.8792  13.0597  -3.3125]] prediction: 1 Actual value:1\n",
      "X: [[ 0.87603  6.8141   0.84198 -0.17156]] prediction: 0 Actual value:0\n",
      "X: [[1.8384  6.063   0.54723 0.51248]] prediction: 0 Actual value:0\n",
      "X: [[ 3.0242  -3.3378   2.5865  -0.54785]] prediction: 0 Actual value:0\n",
      "X: [[-0.78689  9.5663  -3.7867  -7.5034 ]] prediction: 1 Actual value:0\n",
      "X: [[-1.7697  3.4329 -1.2144 -2.3789]] prediction: 1 Actual value:1\n",
      "X: [[ 4.1711   8.722   -3.0224  -0.59699]] prediction: 0 Actual value:0\n",
      "X: [[-1.1188  3.3357 -1.3455 -1.9573]] prediction: 1 Actual value:1\n",
      "X: [[ 4.0215 -2.1914  2.4648  1.1409]] prediction: 0 Actual value:0\n",
      "X: [[ 2.8561   6.9176  -0.79372  0.48403]] prediction: 0 Actual value:0\n",
      "X: [[-0.9607  2.6963 -3.1226 -1.3121]] prediction: 1 Actual value:1\n",
      "X: [[ 1.0194   1.1029  -2.3      0.59395]] prediction: 1 Actual value:1\n",
      "X: [[-1.3887  -4.8773   6.4774   0.34179]] prediction: 1 Actual value:1\n",
      "X: [[5.0691  0.21313 0.20278 1.2095 ]] prediction: 0 Actual value:0\n",
      "X: [[-1.7589  -6.4624   8.4773   0.31981]] prediction: 1 Actual value:1\n",
      "X: [[2.5068  1.1588  3.9249  0.12585]] prediction: 0 Actual value:0\n",
      "X: [[-3.0201  -0.67253  2.7056   0.85774]] prediction: 1 Actual value:1\n",
      "X: [[-1.4233  -0.98912  2.3586   0.39481]] prediction: 1 Actual value:1\n",
      "X: [[ 1.1472   3.5985   1.9387  -0.43406]] prediction: 0 Actual value:0\n",
      "X: [[ 4.1654 -3.4495  3.643   1.0879]] prediction: 0 Actual value:0\n",
      "X: [[-0.025314 -0.17383  -0.11339   1.2198  ]] prediction: 0 Actual value:1\n",
      "X: [[ 5.681    7.795   -2.6848  -0.92544]] prediction: 0 Actual value:0\n",
      "X: [[-1.4427  3.2922 -1.9702 -3.4392]] prediction: 1 Actual value:1\n",
      "X: [[-2.9498 -8.273  10.2646  1.1629]] prediction: 1 Actual value:1\n",
      "X: [[-0.9854 -6.661   5.8245  0.5461]] prediction: 1 Actual value:1\n",
      "X: [[ 2.0466    2.03      2.1761   -0.083634]] prediction: 0 Actual value:0\n",
      "X: [[ 3.2403  -3.7082   5.2804   0.41291]] prediction: 0 Actual value:0\n",
      "X: [[ -2.0545 -10.8679   9.4926  -1.4116]] prediction: 1 Actual value:1\n",
      "X: [[-0.96511  9.4111   1.7305  -4.8629 ]] prediction: 0 Actual value:0\n",
      "X: [[2.5989  3.5178  0.7623  0.81119]] prediction: 0 Actual value:0\n",
      "X: [[-0.55008  2.8659  -1.6488  -2.4319 ]] prediction: 1 Actual value:1\n",
      "X: [[-3.9933   2.6218   0.62863 -1.1595 ]] prediction: 1 Actual value:1\n",
      "X: [[-2.3142   2.0838  -0.46813 -1.6767 ]] prediction: 1 Actual value:1\n",
      "X: [[-0.8734   -0.033118 -0.20165   0.55774 ]] prediction: 1 Actual value:1\n",
      "X: [[1.602   6.1251  0.52924 0.47886]] prediction: 0 Actual value:0\n",
      "X: [[ 0.88444  6.5906   0.55837 -0.44182]] prediction: 0 Actual value:0\n",
      "X: [[ 1.4578  -0.08485  4.1785   0.59136]] prediction: 0 Actual value:0\n",
      "X: [[ 3.0948   8.7324  -2.9007  -0.96682]] prediction: 0 Actual value:0\n",
      "X: [[ 5.6084 10.3009 -4.8003 -4.3534]] prediction: 0 Actual value:0\n",
      "X: [[ 2.9742  8.96   -2.9024 -1.0379]] prediction: 0 Actual value:0\n",
      "X: [[3.2718  1.7837  2.1161  0.61334]] prediction: 0 Actual value:0\n",
      "X: [[-1.786  -8.1157  7.0858 -1.2112]] prediction: 1 Actual value:1\n",
      "X: [[ 0.3798  0.7098  0.7572 -0.4444]] prediction: 0 Actual value:0\n",
      "X: [[-0.51003  -0.23591   0.020273  0.76334 ]] prediction: 1 Actual value:1\n",
      "X: [[ 2.3952  9.5083 -3.1783 -3.0086]] prediction: 0 Actual value:0\n",
      "X: [[ 4.8851e+00  1.5995e+00 -2.9081e-04  1.6401e+00]] prediction: 0 Actual value:0\n",
      "X: [[-0.91318  -2.0113   -0.19565   0.066365]] prediction: 1 Actual value:1\n",
      "X: [[-0.28015  3.0729  -3.3857  -2.9155 ]] prediction: 1 Actual value:1\n",
      "X: [[ 5.8519    5.3905   -2.4037   -0.061652]] prediction: 0 Actual value:0\n",
      "X: [[2.2034  5.9947  0.53009 0.84998]] prediction: 0 Actual value:0\n",
      "X: [[ 0.33565  6.8369   0.69718 -0.55691]] prediction: 0 Actual value:0\n",
      "X: [[-1.4454  -8.4385   8.8483   0.96894]] prediction: 1 Actual value:1\n",
      "X: [[ 2.4391   6.4417  -0.80743 -0.69139]] prediction: 0 Actual value:0\n",
      "X: [[ 3.1887 -3.4143  2.7742 -0.2026]] prediction: 0 Actual value:0\n",
      "X: [[ 4.1197  -2.7956   2.0707   0.67412]] prediction: 0 Actual value:0\n",
      "X: [[-1.7886  -6.3486   5.6154   0.42584]] prediction: 1 Actual value:1\n",
      "X: [[-0.83535  0.80494 -1.6411  -0.19225]] prediction: 1 Actual value:1\n",
      "X: [[ 2.5678   3.5136   0.61406 -0.40691]] prediction: 0 Actual value:0\n",
      "X: [[2.9543  1.076   0.64577 0.89394]] prediction: 0 Actual value:0\n",
      "X: [[ 3.82   10.9279 -4.0112 -5.0284]] prediction: 0 Actual value:0\n",
      "X: [[ 4.1038  -4.8069   3.3491  -0.49225]] prediction: 0 Actual value:0\n",
      "X: [[-1.0401   9.3987   0.85998 -5.3336 ]] prediction: 0 Actual value:0\n",
      "X: [[-4.2249   6.2699   0.15822 -5.5457 ]] prediction: 1 Actual value:1\n",
      "X: [[-0.69879 -3.3771   4.1211   1.5043 ]] prediction: 0 Actual value:1\n",
      "X: [[ 4.2969   7.617   -2.3874  -0.96164]] prediction: 0 Actual value:0\n",
      "X: [[ 1.7748  -0.76978  5.5854   1.3039 ]] prediction: 0 Actual value:0\n",
      "X: [[ 4.3846   -4.8794    3.3662   -0.029324]] prediction: 0 Actual value:0\n",
      "X: [[ -4.211  -12.4736  14.9704  -1.3884]] prediction: 1 Actual value:1\n",
      "X: [[ 0.81356  9.1566  -2.1492  -4.1814 ]] prediction: 0 Actual value:0\n",
      "X: [[-2.6479 10.1374 -1.331  -5.4707]] prediction: 0 Actual value:0\n",
      "X: [[ 0.4339   5.5395   2.033   -0.40432]] prediction: 0 Actual value:0\n",
      "X: [[ 3.6181  -3.7454   2.8273  -0.71208]] prediction: 0 Actual value:0\n",
      "X: [[-2.3147  3.6668 -0.6969 -1.2474]] prediction: 1 Actual value:1\n",
      "X: [[ 3.6941 -3.9482  4.2625  1.1577]] prediction: 0 Actual value:0\n",
      "X: [[-2.588   3.8654 -0.3336 -1.2797]] prediction: 1 Actual value:1\n",
      "X: [[1.8994  0.97462 4.2265  0.81377]] prediction: 0 Actual value:0\n",
      "X: [[3.744   0.79459 0.95851 1.0077 ]] prediction: 0 Actual value:0\n",
      "X: [[ 5.7867   7.8902  -2.6196  -0.48708]] prediction: 0 Actual value:0\n",
      "X: [[-3.2238   2.7935   0.32274 -0.86078]] prediction: 1 Actual value:1\n",
      "X: [[ 3.7982 10.423  -4.1602 -4.9728]] prediction: 0 Actual value:0\n",
      "X: [[ -3.3863 -12.9889  13.0545  -2.7202]] prediction: 1 Actual value:1\n",
      "X: [[-2.7908  -5.7133   5.953    0.45946]] prediction: 1 Actual value:1\n",
      "X: [[-5.1216 -5.3118 10.3846 -1.0612]] prediction: 1 Actual value:1\n",
      "X: [[ 0.90407  3.3708  -4.4987  -3.6965 ]] prediction: 1 Actual value:1\n",
      "X: [[ 0.025013  3.3998   -4.4327   -4.2655  ]] prediction: 1 Actual value:1\n",
      "X: [[-1.3931   1.5664   7.5382   0.78403]] prediction: 0 Actual value:0\n",
      "X: [[ 0.12326  8.9848  -0.9351  -2.4332 ]] prediction: 0 Actual value:0\n",
      "X: [[ 4.0948  -2.9674   2.3689   0.75429]] prediction: 0 Actual value:0\n",
      "X: [[ -3.5801 -12.9309  13.1779  -2.5677]] prediction: 1 Actual value:1\n",
      "X: [[-1.7479 -5.823   5.8699  1.212 ]] prediction: 1 Actual value:1\n",
      "X: [[ -4.4775 -13.0303  17.0834  -3.0345]] prediction: 1 Actual value:1\n",
      "X: [[ 1.8238  -6.7748   8.3873  -0.54139]] prediction: 0 Actual value:0\n",
      "X: [[-1.3971  3.3191 -1.3927 -1.9948]] prediction: 1 Actual value:1\n",
      "X: [[ -3.4917  -12.1736   14.3689   -0.61639]] prediction: 1 Actual value:1\n",
      "X: [[-2.4621   2.7645  -0.62578 -2.8573 ]] prediction: 1 Actual value:1\n",
      "X: [[-5.3857   9.1214  -0.41929 -5.9181 ]] prediction: 1 Actual value:1\n",
      "X: [[ 4.2406 -2.4852  1.608   0.7155]] prediction: 0 Actual value:0\n",
      "X: [[-1.3946   2.3134  -0.44499 -1.4905 ]] prediction: 1 Actual value:1\n",
      "X: [[ 3.1896   5.7526  -0.18537 -0.30087]] prediction: 0 Actual value:0\n",
      "X: [[-2.8391  -6.63    10.4849  -0.42113]] prediction: 1 Actual value:1\n",
      "X: [[-1.5768 10.843   2.5462 -2.9362]] prediction: 0 Actual value:0\n",
      "X: [[-1.8584  7.886  -1.6643 -1.8384]] prediction: 0 Actual value:0\n",
      "X: [[-2.7723  3.2777 -0.9351 -3.1457]] prediction: 1 Actual value:1\n",
      "X: [[-6.8919e-03  9.2931e+00 -4.1243e-01 -1.9638e+00]] prediction: 0 Actual value:0\n",
      "X: [[ 1.3638 -4.7759  8.4182 -1.8836]] prediction: 0 Actual value:0\n",
      "X: [[-0.2062  9.2207 -3.7044 -6.8103]] prediction: 1 Actual value:0\n",
      "X: [[ 1.5514  3.8013 -4.9143 -3.7483]] prediction: 1 Actual value:1\n",
      "X: [[ 4.0552 -2.4583  2.2806  1.0323]] prediction: 0 Actual value:0\n",
      "X: [[-0.7056  8.7241  2.2215 -4.5965]] prediction: 0 Actual value:0\n",
      "X: [[-2.3361 11.9604  3.0835 -5.4435]] prediction: 0 Actual value:0\n",
      "X: [[-4.5046  -5.8126  10.8867  -0.52846]] prediction: 1 Actual value:1\n",
      "X: [[ 0.31803 -0.99326  1.0947   0.88619]] prediction: 0 Actual value:1\n",
      "X: [[ 4.1927  -3.2674   2.5839   0.21766]] prediction: 0 Actual value:0\n",
      "X: [[ 4.0102 10.6568 -4.1388 -5.0646]] prediction: 0 Actual value:0\n",
      "X: [[-2.2811   -0.85669   2.7185    0.044382]] prediction: 1 Actual value:1\n",
      "X: [[-2.4349  -9.2497   8.9922  -0.50001]] prediction: 1 Actual value:1\n",
      "X: [[ 3.7022   6.9942  -1.8511  -0.12889]] prediction: 0 Actual value:0\n",
      "X: [[-1.5851 -2.1562  1.7082  0.9017]] prediction: 1 Actual value:1\n",
      "X: [[ 1.8592   3.2074  -0.15966 -0.26208]] prediction: 0 Actual value:0\n",
      "X: [[ 2.5503  -4.9518   6.3729  -0.41596]] prediction: 0 Actual value:0\n",
      "X: [[-3.2778  1.8023  0.1805 -2.3931]] prediction: 1 Actual value:1\n",
      "X: [[-3.5895  -6.572   10.5251  -0.16381]] prediction: 1 Actual value:1\n",
      "X: [[-0.13144 -1.7775   8.3316   0.35214]] prediction: 0 Actual value:0\n",
      "X: [[ 0.37637 -0.82358  0.78543  0.74524]] prediction: 0 Actual value:1\n",
      "X: [[-2.2804  -0.30626  1.3347   1.3763 ]] prediction: 1 Actual value:1\n",
      "X: [[1.5902  2.2948  3.2403  0.18404]] prediction: 0 Actual value:0\n",
      "X: [[-1.7344   2.0175   7.7618   0.93532]] prediction: 0 Actual value:0\n",
      "X: [[-2.41     3.7433  -0.40215 -1.2953 ]] prediction: 1 Actual value:1\n",
      "X: [[-0.95403  1.9824  -2.3163  -1.1957 ]] prediction: 1 Actual value:1\n",
      "X: [[4.3634  0.46351 1.4281  2.0202 ]] prediction: 0 Actual value:0\n",
      "X: [[ 4.1529   -3.9358    2.8633   -0.017686]] prediction: 0 Actual value:0\n",
      "X: [[ 3.5761  9.7753 -3.9795 -3.4638]] prediction: 0 Actual value:0\n",
      "X: [[ 4.6765 -3.3895  3.4896  1.4771]] prediction: 0 Actual value:0\n",
      "X: [[ 3.7321    -3.884      3.3577    -0.0060486]] prediction: 0 Actual value:0\n",
      "X: [[ 1.0987   0.6394   5.989   -0.58277]] prediction: 0 Actual value:0\n",
      "X: [[ 5.2032  3.5116 -1.2538  1.0129]] prediction: 0 Actual value:0\n",
      "X: [[2.4673  1.3926  1.7125  0.41421]] prediction: 0 Actual value:0\n",
      "X: [[-1.8584  7.886  -1.6643 -1.8384]] prediction: 0 Actual value:0\n",
      "X: [[-2.2623  12.1177   0.28846 -7.7581 ]] prediction: 0 Actual value:0\n",
      "X: [[-0.8471  3.1329 -3.0112 -2.9388]] prediction: 1 Actual value:1\n",
      "X: [[-3.5933   0.22968  0.7126  -0.3332 ]] prediction: 1 Actual value:1\n",
      "X: [[4.2458  1.1981  0.66633 0.94696]] prediction: 0 Actual value:0\n",
      "X: [[ 3.482    -4.1634    3.5008   -0.078462]] prediction: 0 Actual value:0\n",
      "X: [[1.594    4.7055   1.3758   0.081882]] prediction: 0 Actual value:0\n",
      "X: [[-1.0802  2.1996 -2.5862 -1.2759]] prediction: 1 Actual value:1\n",
      "X: [[-2.4473  12.6247   0.73573 -7.6612 ]] prediction: 0 Actual value:0\n",
      "X: [[-1.8974  3.5074 -1.7842 -3.8491]] prediction: 1 Actual value:1\n",
      "X: [[-1.979   3.2301 -1.3575 -2.5819]] prediction: 1 Actual value:1\n",
      "X: [[ 2.994   7.2011 -1.2153  0.3211]] prediction: 0 Actual value:0\n",
      "X: [[ 2.9736  8.7944 -3.6359 -1.3754]] prediction: 0 Actual value:0\n",
      "X: [[ 2.8521  9.171  -3.6461 -1.2047]] prediction: 0 Actual value:0\n",
      "X: [[-2.4561   -4.5566    6.4534   -0.056479]] prediction: 1 Actual value:1\n",
      "X: [[ 4.9362   7.6046  -2.3429  -0.85302]] prediction: 0 Actual value:0\n",
      "X: [[-0.55648  3.2136  -3.3085  -2.7965 ]] prediction: 1 Actual value:1\n",
      "X: [[ 0.20977 -0.46146  7.7267   0.90946]] prediction: 0 Actual value:0\n",
      "X: [[ 2.2634  -4.4862   3.6558  -0.61251]] prediction: 0 Actual value:0\n",
      "X: [[ 3.1377  -4.1096   4.5701   0.98963]] prediction: 0 Actual value:0\n",
      "X: [[-1.6001   -9.5828    9.4044    0.081882]] prediction: 1 Actual value:1\n",
      "X: [[ -2.9662 -10.3257   8.784   -2.1138]] prediction: 1 Actual value:1\n",
      "X: [[-2.565    -5.7899    6.0122    0.046968]] prediction: 1 Actual value:1\n",
      "X: [[-3.0799   0.60836  2.7039  -0.23751]] prediction: 1 Actual value:1\n",
      "X: [[-1.8356  -6.7562   5.0585  -0.55044]] prediction: 1 Actual value:1\n",
      "X: [[-2.6864   -0.097265  0.61663   0.061192]] prediction: 1 Actual value:1\n",
      "X: [[ 2.5089    6.841    -0.029423  0.44912 ]] prediction: 0 Actual value:0\n",
      "X: [[ 4.1757 10.2615 -3.8552 -4.3056]] prediction: 0 Actual value:0\n",
      "X: [[-0.77461 -1.8768   2.4023   1.1319 ]] prediction: 0 Actual value:1\n",
      "X: [[ 1.1432  -3.7413   5.5777  -0.63578]] prediction: 0 Actual value:0\n",
      "X: [[ 2.3718    7.4908    0.015989 -1.7414  ]] prediction: 0 Actual value:0\n",
      "X: [[4.0552  0.40143 1.4563  0.65343]] prediction: 0 Actual value:0\n",
      "X: [[ 0.518    0.25865 -0.84085  0.96118]] prediction: 0 Actual value:1\n",
      "X: [[ 0.6818  4.8504 -5.2133 -6.1043]] prediction: 1 Actual value:1\n",
      "X: [[ 3.3583 10.3567 -3.7301 -3.6991]] prediction: 0 Actual value:0\n",
      "X: [[2.0421  1.2436  4.2171  0.90429]] prediction: 0 Actual value:0\n",
      "X: [[ 3.9771 11.1513 -3.9272 -4.3444]] prediction: 0 Actual value:0\n",
      "X: [[3.9772  0.33521 2.2566  2.1625 ]] prediction: 0 Actual value:0\n",
      "X: [[ 2.6881   6.0195  -0.46641 -0.69268]] prediction: 0 Actual value:0\n",
      "X: [[ 0.11032  1.9741  -3.3668  -0.65259]] prediction: 1 Actual value:1\n",
      "X: [[ 4.7926    1.7071   -0.051701  1.4926  ]] prediction: 0 Actual value:0\n",
      "X: [[ 3.2704   6.9321  -1.0456   0.23447]] prediction: 0 Actual value:0\n",
      "X: [[ 0.64376  3.764   -4.4738  -4.0483 ]] prediction: 1 Actual value:1\n",
      "X: [[ 5.032   8.2026 -2.6256 -1.0341]] prediction: 0 Actual value:0\n",
      "X: [[-4.0173 -8.3123 12.4547 -1.4375]] prediction: 1 Actual value:1\n",
      "X: [[ 2.4527    2.9653    0.20021  -0.056479]] prediction: 0 Actual value:0\n",
      "X: [[ 3.866   -2.6383   1.9242   0.10645]] prediction: 0 Actual value:0\n",
      "X: [[-0.40804  0.54214 -0.52725  0.6586 ]] prediction: 1 Actual value:1\n",
      "X: [[2.805   0.57732 1.3424  1.2133 ]] prediction: 0 Actual value:0\n",
      "X: [[ 0.3292 -4.4552  4.5718 -0.9888]] prediction: 1 Actual value:0\n",
      "X: [[ 1.5673    7.9274   -0.056842 -2.1694  ]] prediction: 0 Actual value:0\n",
      "X: [[-2.0336  -1.4092   1.1582   0.36507]] prediction: 1 Actual value:1\n",
      "X: [[-1.4781   0.14277 -1.1622  -0.48579]] prediction: 1 Actual value:1\n",
      "X: [[-1.9116  -6.1603   5.606    0.48533]] prediction: 1 Actual value:1\n",
      "X: [[-2.4115  -9.1359   9.3444  -0.65259]] prediction: 1 Actual value:1\n",
      "X: [[-5.4901   9.1048  -0.38758 -5.9763 ]] prediction: 1 Actual value:1\n",
      "X: [[-1.0112  2.9984 -1.1664 -1.6185]] prediction: 1 Actual value:1\n",
      "X: [[ 3.8832   6.4023  -2.432   -0.98363]] prediction: 0 Actual value:0\n",
      "X: [[-3.6053  -5.974   10.0916  -0.82846]] prediction: 1 Actual value:1\n",
      "X: [[-2.343  12.9516  3.3285 -5.9426]] prediction: 0 Actual value:0\n",
      "X: [[2.7296  2.8701  0.51124 0.5099 ]] prediction: 0 Actual value:0\n",
      "X: [[ 3.534   9.3614 -3.6316 -1.2461]] prediction: 0 Actual value:0\n",
      "X: [[-2.799    1.9679  -0.42357 -2.1125 ]] prediction: 1 Actual value:1\n",
      "X: [[-3.2854   4.0372  -0.45356 -1.8228 ]] prediction: 1 Actual value:1\n",
      "X: [[-1.8219   -6.8824    5.4681    0.057313]] prediction: 1 Actual value:1\n",
      "X: [[ 4.1349   6.1189  -2.4294  -0.19613]] prediction: 0 Actual value:0\n",
      "X: [[-2.2677  3.2964 -2.2563 -2.4642]] prediction: 1 Actual value:1\n",
      "X: [[ 0.32924 -4.4552   4.5718  -0.9888 ]] prediction: 1 Actual value:0\n",
      "X: [[ -3.2692  -12.7406   15.5573   -0.14182]] prediction: 1 Actual value:1\n",
      "X: [[ 4.1665  -0.4449   0.23448  0.27843]] prediction: 0 Actual value:0\n",
      "X: [[-2.341   12.3784   0.70403 -7.5836 ]] prediction: 0 Actual value:0\n",
      "X: [[ 1.3403  4.1323 -4.7018 -2.5987]] prediction: 1 Actual value:1\n",
      "X: [[-1.5572 -9.8808  8.1088 -1.0806]] prediction: 1 Actual value:1\n",
      "X: [[ 1.7875  4.78   -5.1362 -3.2362]] prediction: 1 Actual value:1\n",
      "X: [[-1.2667  2.8183 -2.426  -1.8862]] prediction: 1 Actual value:1\n",
      "X: [[ 0.96708  3.8426  -4.9314  -4.1323 ]] prediction: 1 Actual value:1\n",
      "X: [[ 4.2478  7.6956 -2.7696 -1.0767]] prediction: 0 Actual value:0\n",
      "X: [[ 0.38478  6.5989  -0.3336  -0.56466]] prediction: 0 Actual value:0\n",
      "X: [[-5.873    9.1752  -0.27448 -6.0422 ]] prediction: 1 Actual value:1\n",
      "X: [[3.0329  2.2948  2.1135  0.35084]] prediction: 0 Actual value:0\n",
      "X: [[-2.3221  -9.3304   9.233   -0.79871]] prediction: 1 Actual value:1\n",
      "X: [[-2.5346e+00 -7.7392e-01  3.3602e+00  1.7100e-03]] prediction: 1 Actual value:1\n",
      "X: [[-0.11716   0.60422  -0.38587  -0.059065]] prediction: 1 Actual value:1\n",
      "X: [[-1.0941  2.3072 -2.5237 -1.4453]] prediction: 1 Actual value:1\n",
      "X: [[4.1373  0.49248 1.093   1.8276 ]] prediction: 0 Actual value:0\n",
      "X: [[-1.8629   -0.84841   2.5377    0.097399]] prediction: 1 Actual value:1\n",
      "X: [[ -2.6685 -10.4519   9.1139  -1.7323]] prediction: 1 Actual value:1\n",
      "X: [[ 2.2517 -5.1422  4.2916 -1.2487]] prediction: 1 Actual value:0\n",
      "X: [[-0.64472 -4.6062   8.347   -2.7099 ]] prediction: 1 Actual value:0\n",
      "X: [[ 0.52855  0.96427  4.0243  -1.0483 ]] prediction: 0 Actual value:0\n",
      "X: [[ 3.2697  -4.3414   3.6884  -0.29829]] prediction: 0 Actual value:0\n",
      "X: [[-3.6817   3.2239  -0.69347 -3.4004 ]] prediction: 1 Actual value:1\n",
      "X: [[-2.0759 10.8223  2.6439 -4.837 ]] prediction: 0 Actual value:0\n",
      "X: [[ 4.6361 -2.6611  2.8358  1.1991]] prediction: 0 Actual value:0\n",
      "X: [[ 4.3684  9.6718 -3.9606 -3.1625]] prediction: 0 Actual value:0\n",
      "X: [[ 1.9157   6.0816   0.23705 -2.0116 ]] prediction: 0 Actual value:0\n",
      "X: [[ 0.25035  9.3262  -3.6873  -6.2543 ]] prediction: 1 Actual value:0\n",
      "X: [[-0.71868 -5.7154   3.8298   1.0233 ]] prediction: 1 Actual value:1\n",
      "X: [[ 0.21431 -0.69529  0.87711  0.29653]] prediction: 0 Actual value:1\n",
      "X: [[ 1.5456  8.5482  0.4187 -2.1784]] prediction: 0 Actual value:0\n",
      "X: [[ 2.7365  -5.0325   6.6608  -0.57889]] prediction: 0 Actual value:0\n",
      "X: [[ 0.98296  3.4226  -3.9692  -1.7116 ]] prediction: 1 Actual value:1\n",
      "X: [[-1.6386  3.3584 -1.7302 -3.5646]] prediction: 1 Actual value:1\n",
      "X: [[-1.2244  1.7485 -1.4801 -1.4181]] prediction: 1 Actual value:1\n",
      "X: [[-1.1306  1.8458 -1.3575 -1.3806]] prediction: 1 Actual value:1\n",
      "X: [[ 1.1166   8.6496  -0.96252 -1.8112 ]] prediction: 0 Actual value:0\n",
      "X: [[ 2.7391    7.4018    0.071684 -2.5302  ]] prediction: 0 Actual value:0\n",
      "X: [[-1.7322 -9.2828  7.719  -1.7168]] prediction: 1 Actual value:1\n",
      "X: [[ 4.4072   -0.070365  2.0416    1.1319  ]] prediction: 0 Actual value:0\n",
      "X: [[-5.3012    7.3915    0.029699 -7.3987  ]] prediction: 1 Actual value:1\n",
      "X: [[ 2.9163 10.8306 -3.3437 -4.122 ]] prediction: 0 Actual value:0\n",
      "X: [[ 0.93584  8.8855  -1.6831  -1.6599 ]] prediction: 0 Actual value:0\n",
      "X: [[-1.1804  11.5093   0.15565 -6.8194 ]] prediction: 0 Actual value:0\n",
      "X: [[ 3.0632 -3.3315  5.1305  0.8267]] prediction: 0 Actual value:0\n",
      "X: [[-1.7582  2.7397 -2.5323 -2.234 ]] prediction: 1 Actual value:1\n",
      "X: [[ 0.5706 -0.0248  1.2421 -0.5621]] prediction: 0 Actual value:0\n",
      "X: [[-0.2361  9.3221  2.1307 -4.3793]] prediction: 0 Actual value:0\n",
      "X: [[-2.2987  -5.227    5.63     0.91722]] prediction: 1 Actual value:1\n",
      "X: [[ 4.6499   7.6336  -1.9427  -0.37458]] prediction: 0 Actual value:0\n",
      "X: [[ 1.6032 -4.7863  8.5193 -2.1203]] prediction: 0 Actual value:0\n",
      "X: [[3.8213  0.23175 2.0133  2.0564 ]] prediction: 0 Actual value:0\n",
      "X: [[-2.6286   0.18002  1.7956   0.97282]] prediction: 1 Actual value:1\n",
      "X: [[ 3.4591 11.112  -4.2039 -5.0931]] prediction: 0 Actual value:0\n",
      "X: [[-1.1497   1.2954   7.701    0.62627]] prediction: 0 Actual value:0\n",
      "X: [[-1.239    -6.541     4.8151   -0.033204]] prediction: 1 Actual value:1\n",
      "X: [[ 3.7831 10.0526 -3.8869 -3.7366]] prediction: 0 Actual value:0\n",
      "X: [[2.5227  2.2369  2.7236  0.79438]] prediction: 0 Actual value:0\n",
      "X: [[-6.9599  8.9931  0.2182 -4.572 ]] prediction: 1 Actual value:1\n",
      "X: [[-0.41965  2.9094  -1.7859  -2.2069 ]] prediction: 1 Actual value:1\n",
      "X: [[-0.2062  9.2207 -3.7044 -6.8103]] prediction: 1 Actual value:0\n",
      "X: [[ 3.4642 10.6878 -3.4071 -4.109 ]] prediction: 0 Actual value:0\n",
      "X: [[-1.9389    1.5706    0.045979 -1.122   ]] prediction: 1 Actual value:1\n",
      "X: [[-1.9409  -8.6848   9.155    0.94049]] prediction: 1 Actual value:1\n",
      "X: [[-1.8554  -9.6035   7.7764  -0.97716]] prediction: 1 Actual value:1\n",
      "X: [[ -1.5449 -10.1498   9.6152  -1.2332]] prediction: 1 Actual value:1\n",
      "X: [[4.9294  0.27727 0.20792 0.33662]] prediction: 0 Actual value:0\n",
      "X: [[ 3.6575  7.2797 -2.2692 -1.144 ]] prediction: 0 Actual value:0\n",
      "X: [[-6.2815   6.6651   0.52581 -7.0107 ]] prediction: 1 Actual value:1\n",
      "X: [[-2.0631  -1.5147   1.219    0.44524]] prediction: 1 Actual value:1\n",
      "X: [[-3.8073  -8.0971  10.1772   0.65084]] prediction: 1 Actual value:1\n",
      "X: [[ 4.6562  7.6398 -2.4243 -1.2384]] prediction: 0 Actual value:0\n",
      "X: [[-1.8483   0.31038  0.77344  1.4189 ]] prediction: 1 Actual value:1\n",
      "X: [[-2.1234   1.1815  -0.55552 -0.81165]] prediction: 1 Actual value:1\n",
      "X: [[ 2.7213   7.05    -0.58808  0.41809]] prediction: 0 Actual value:0\n",
      "X: [[-2.1405  -0.16762  1.321   -0.20906]] prediction: 1 Actual value:1\n",
      "X: [[ 0.7057 -5.4981  8.3368 -2.8715]] prediction: 0 Actual value:0\n",
      "X: [[-0.65767 -2.8018   3.7115   0.99739]] prediction: 0 Actual value:1\n",
      "X: [[-2.0441   1.2271   0.18564 -1.091  ]] prediction: 1 Actual value:1\n",
      "X: [[ 0.83625   1.1071   -2.4706   -0.062945]] prediction: 1 Actual value:1\n",
      "X: [[-1.4377  -1.432    2.1144   0.42067]] prediction: 1 Actual value:1\n",
      "X: [[-5.119     6.6486   -0.049987 -6.5206  ]] prediction: 1 Actual value:1\n",
      "X: [[ 2.8084 11.3045 -3.3394 -4.4194]] prediction: 0 Actual value:0\n",
      "X: [[-2.7028    1.6327    0.83598  -0.091393]] prediction: 1 Actual value:1\n",
      "X: [[-1.6988  -7.1163   5.7902   0.16723]] prediction: 1 Actual value:1\n",
      "X: [[ 2.888    0.44696  4.5907  -0.24398]] prediction: 0 Actual value:0\n",
      "X: [[ 1.7939  -1.1174   1.5454  -0.26079]] prediction: 0 Actual value:0\n",
      "X: [[-3.5798   0.45937  2.3457  -0.45734]] prediction: 1 Actual value:1\n",
      "X: [[ 2.6213    5.7919    0.065686 -1.5759  ]] prediction: 0 Actual value:0\n",
      "X: [[-1.2424  -1.7175  -0.52553 -0.21036]] prediction: 1 Actual value:1\n",
      "X: [[ 0.57461 10.1105  -1.6917  -4.3922 ]] prediction: 0 Actual value:0\n",
      "X: [[2.2504  3.5757  0.35273 0.2836 ]] prediction: 0 Actual value:0\n",
      "X: [[ 2.0051 -6.8638  8.132  -0.2401]] prediction: 0 Actual value:0\n",
      "X: [[-0.98193  2.7956  -1.2341  -1.5668 ]] prediction: 1 Actual value:1\n",
      "X: [[ 1.5701   7.9129   0.29018 -2.1953 ]] prediction: 0 Actual value:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: [[-0.38214  8.3909   2.1624  -3.7405 ]] prediction: 0 Actual value:0\n",
      "X: [[-0.62684 -6.301    4.7843   1.106  ]] prediction: 1 Actual value:1\n",
      "X: [[ 4.6014   5.6264  -2.1235   0.19309]] prediction: 0 Actual value:0\n",
      "X: [[-3.3884  -8.215   10.3315   0.98187]] prediction: 1 Actual value:1\n",
      "X: [[-1.5252  -6.2534   5.3524   0.59912]] prediction: 1 Actual value:1\n",
      "X: [[ 1.04   -6.9321  8.2888 -1.2991]] prediction: 0 Actual value:0\n",
      "X: [[ 3.4566  9.5228 -4.0112 -3.5944]] prediction: 0 Actual value:0\n",
      "X: [[-3.0193   1.7775   0.73745 -0.45346]] prediction: 1 Actual value:1\n",
      "X: [[-1.6706  -2.09     1.584    0.71162]] prediction: 1 Actual value:1\n",
      "X: [[-1.8187  -9.0366   9.0162  -0.12243]] prediction: 1 Actual value:1\n",
      "X: [[ 0.53936  3.8944  -4.8166  -4.3418 ]] prediction: 1 Actual value:1\n",
      "X: [[ 3.4647  -3.9172   3.9746   0.36119]] prediction: 0 Actual value:0\n",
      "X: [[ 2.3925  9.798  -3.0361 -2.8224]] prediction: 0 Actual value:0\n",
      "X: [[-1.8046 -6.8141  6.7019  1.1681]] prediction: 1 Actual value:1\n",
      "X: [[ 1.8533  6.1458  1.0176 -2.0401]] prediction: 0 Actual value:0\n",
      "X: [[ 6.0919  2.9673 -1.3267  1.4551]] prediction: 0 Actual value:0\n",
      "X: [[-0.11996  6.8741   0.91995 -0.6694 ]] prediction: 0 Actual value:0\n",
      "X: [[-1.5222 10.8409  2.7827 -4.0974]] prediction: 0 Actual value:0\n",
      "X: [[4.0047  0.45937 1.3621  1.6181 ]] prediction: 0 Actual value:0\n",
      "X: [[ 0.67886  4.1199  -4.569   -4.1414 ]] prediction: 1 Actual value:1\n",
      "X: [[2.5581  2.6218  1.8513  0.40257]] prediction: 0 Actual value:0\n",
      "X: [[-2.899   -0.60424  2.6045   1.3776 ]] prediction: 1 Actual value:1\n",
      "X: [[-1.3274  9.498   2.4408 -5.2689]] prediction: 0 Actual value:0\n",
      "X: [[ 1.518     5.6946    0.094818 -0.026738]] prediction: 0 Actual value:0\n",
      "X: [[ 2.093     8.3061    0.022844 -3.2724  ]] prediction: 0 Actual value:0\n",
      "X: [[ 3.5458  9.3718 -4.0351 -3.9564]] prediction: 0 Actual value:0\n",
      "X: [[4.0972  0.46972 1.6671  0.91593]] prediction: 0 Actual value:0\n",
      "X: [[-1.7104 -4.778   6.2109  0.3974]] prediction: 1 Actual value:1\n",
      "X: [[ 3.6894  9.887  -4.0788 -4.3664]] prediction: 0 Actual value:0\n",
      "X: [[ 2.1319   -2.0403    2.5574   -0.061652]] prediction: 0 Actual value:0\n",
      "X: [[ 1.3451   0.23589 -1.8785   1.3258 ]] prediction: 0 Actual value:1\n",
      "X: [[ 5.9374   6.1664  -2.5905  -0.36553]] prediction: 0 Actual value:0\n",
      "X: [[-1.749   -6.332    6.0987   0.14266]] prediction: 1 Actual value:1\n",
      "X: [[-0.2062  9.2207 -3.7044 -6.8103]] prediction: 1 Actual value:0\n",
      "X: [[-0.69078 -0.50077 -0.35417  0.47498]] prediction: 1 Actual value:1\n",
      "X: [[ 3.4769  -0.15314  2.53     2.4495 ]] prediction: 0 Actual value:0\n",
      "X: [[-0.278   8.1881 -3.1338 -2.5276]] prediction: 0 Actual value:0\n",
      "X: [[4.7432 2.1086 0.1368 1.6543]] prediction: 0 Actual value:0\n",
      "X: [[3.5251  0.7201  1.6928  0.64438]] prediction: 0 Actual value:0\n",
      "X: [[ 0.72252  -0.053811  5.6703   -1.3509  ]] prediction: 0 Actual value:0\n",
      "X: [[-2.1059   1.1815  -0.53324 -0.82716]] prediction: 1 Actual value:1\n",
      "X: [[ 3.1201e-03 -4.0061e+00  1.7956e+00  9.1722e-01]] prediction: 1 Actual value:1\n",
      "X: [[-1.5877  -6.6072   5.8022   0.31593]] prediction: 1 Actual value:1\n",
      "X: [[2.3969  0.23589 4.8477  1.437  ]] prediction: 0 Actual value:0\n",
      "X: [[-1.9922 11.6542  2.6542 -5.2107]] prediction: 0 Actual value:0\n",
      "X: [[-1.7101  -8.7903   7.9735  -0.45475]] prediction: 1 Actual value:1\n",
      "X: [[ 5.1213  8.5565 -3.3917 -1.5474]] prediction: 0 Actual value:0\n",
      "X: [[4.3435  3.3295  0.83598 0.64955]] prediction: 0 Actual value:0\n",
      "X: [[ 0.91315  3.3377  -4.0557  -1.6741 ]] prediction: 1 Actual value:1\n",
      "X: [[ 2.3136 10.6651 -3.5288 -4.7672]] prediction: 0 Actual value:0\n",
      "X: [[-0.83121   0.039307  0.05369  -0.23105 ]] prediction: 1 Actual value:1\n",
      "X: [[ 2.2429  -4.1427   5.2333  -0.40173]] prediction: 0 Actual value:0\n",
      "X: [[ 4.3064  8.2068 -2.7824 -1.4336]] prediction: 0 Actual value:0\n",
      "X: [[ 0.2952  4.8856 -5.149  -6.2323]] prediction: 1 Actual value:1\n",
      "X: [[ 0.85574    0.0082678  6.6042    -0.53104  ]] prediction: 0 Actual value:0\n",
      "X: [[-0.12196  8.8068   0.94566 -4.2267 ]] prediction: 0 Actual value:0\n",
      "X: [[ 5.1731   3.9606  -1.983    0.40774]] prediction: 0 Actual value:0\n",
      "X: [[-3.4605   2.6901   0.16165 -1.0224 ]] prediction: 1 Actual value:1\n",
      "X: [[-6.5084   8.7696   0.23191 -3.937  ]] prediction: 1 Actual value:1\n",
      "X: [[ 5.0617  -0.35799  0.44698  0.99868]] prediction: 0 Actual value:0\n",
      "X: [[-0.77288 -7.4473   6.492    0.36119]] prediction: 1 Actual value:1\n",
      "X: [[ 3.7731   7.2073  -1.6814  -0.94742]] prediction: 0 Actual value:0\n",
      "X: [[-0.3489  3.1929 -3.4054 -3.1832]] prediction: 1 Actual value:1\n",
      "X: [[ 0.88872  5.3449   2.045   -0.19355]] prediction: 0 Actual value:0\n",
      "X: [[ 5.7403  -0.44284  0.38015  1.3763 ]] prediction: 0 Actual value:0\n",
      "X: [[-2.6406  -4.4159   5.983   -0.13924]] prediction: 1 Actual value:1\n",
      "X: [[ 4.3239 -4.8835  3.4356 -0.5776]] prediction: 0 Actual value:0\n",
      "X: [[ 0.6212  3.6771 -4.0771 -2.0711]] prediction: 1 Actual value:1\n",
      "X: [[ 1.8314    6.3672   -0.036278  0.049554]] prediction: 0 Actual value:0\n",
      "X: [[3.3299  0.91254 1.5806  0.39352]] prediction: 0 Actual value:0\n",
      "X: [[ 3.3669 -5.1856  3.6935 -1.1427]] prediction: 0 Actual value:0\n",
      "X: [[-0.52645 -0.24832 -0.45613  0.41938]] prediction: 1 Actual value:1\n",
      "X: [[3.4663 1.1112 1.7425 1.3388]] prediction: 0 Actual value:0\n",
      "X: [[-5.4414   7.2363   0.10938 -7.5642 ]] prediction: 1 Actual value:1\n",
      "X: [[-3.5359   0.30417  0.6569  -0.2957 ]] prediction: 1 Actual value:1\n",
      "X: [[-0.97325 -6.4168   5.6026   1.0323 ]] prediction: 1 Actual value:1\n",
      "X: [[ 3.1219  -3.137    1.9259  -0.37458]] prediction: 0 Actual value:0\n",
      "X: [[ 4.3483 11.1079 -4.0857 -4.2539]] prediction: 0 Actual value:0\n",
      "X: [[ 2.2596   -0.033118  4.7355   -0.2776  ]] prediction: 0 Actual value:0\n",
      "X: [[ 0.5195 -3.2633  3.0895 -0.9849]] prediction: 1 Actual value:0\n",
      "X: [[ 1.2309  3.8923 -4.8277 -4.0069]] prediction: 1 Actual value:1\n",
      "X: [[ 2.2526  9.9636 -3.1749 -2.9944]] prediction: 0 Actual value:0\n",
      "X: [[ 0.59823  3.5012  -3.9795  -1.7841 ]] prediction: 1 Actual value:1\n",
      "X: [[ 1.7257 -4.4697  8.2219 -1.8073]] prediction: 0 Actual value:0\n",
      "X: [[-2.8833   1.7713   0.68946 -0.4638 ]] prediction: 1 Actual value:1\n",
      "X: [[-4.4779   7.3708  -0.31218 -6.7754 ]] prediction: 1 Actual value:1\n",
      "X: [[3.5288  0.71596 1.9507  1.9375 ]] prediction: 0 Actual value:0\n",
      "X: [[3.2414  0.40971 1.4015  1.1952 ]] prediction: 0 Actual value:0\n",
      "X: [[-1.9725  2.8825 -2.3086 -2.3724]] prediction: 1 Actual value:1\n",
      "X: [[-2.0754   1.2767  -0.64206 -1.2642 ]] prediction: 1 Actual value:1\n",
      "X: [[2.8237  2.8597  0.19678 0.57196]] prediction: 0 Actual value:0\n",
      "X: [[ 3.9529  -2.3548   2.3792   0.48274]] prediction: 0 Actual value:0\n",
      "X: [[-0.66008 -3.226    3.8058   1.1836 ]] prediction: 0 Actual value:1\n",
      "X: [[-4.4996   3.4288   0.56265 -1.1672 ]] prediction: 1 Actual value:1\n",
      "X: [[-2.9138  -9.4711   9.7668  -0.60216]] prediction: 1 Actual value:1\n",
      "X: [[-1.5228  -6.4789   5.7568   0.87325]] prediction: 1 Actual value:1\n",
      "X: [[-1.8411 10.8306  2.769  -3.0901]] prediction: 0 Actual value:0\n",
      "X: [[ 1.2262   0.89599  5.7568  -0.11596]] prediction: 0 Actual value:0\n",
      "Test Accuracy:95.0\n",
      "\n",
      "Accuracy metrics:\n",
      "Accuracy: 0.95\n",
      "Precision: 0.9535864978902954\n",
      "Recall: 0.9576271186440678\n",
      "\n",
      "Confusion matrix:\n",
      "[[226, 11], [10, 173]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Testset accuracy, Confusion Matrix and Accuracy metrics\n",
    "def test(X_test, y_test):\n",
    "    print(\"Predictions on test data:\")\n",
    "    correct = 0\n",
    "    tp,fp,tn,fn = 0,0,0,0\n",
    "    for x,y in zip(X_test,y_test):\n",
    "        prediction = predict(x)\n",
    "        actual_value = int(np.array(y)[0][0])\n",
    "        print(\"X: \"+str(x)+\" prediction: \"+str(prediction)+\" Actual value:\"+str(actual_value))\n",
    "        if actual_value == prediction:\n",
    "          correct += 1\n",
    "        if actual_value == 0 and prediction == 0:\n",
    "          tp += 1\n",
    "        if actual_value == 1 and prediction ==1:\n",
    "          tn += 1\n",
    "        if actual_value == 0 and prediction ==1:\n",
    "          fn += 1\n",
    "        if actual_value == 1 and prediction == 0:\n",
    "          fp += 1  \n",
    "    test_accuracy =  correct/float(X_test.shape[0])*100.0\n",
    "    print(\"Test Accuracy:\"+str(test_accuracy))\n",
    "    print()\n",
    "    print(\"Accuracy metrics:\")\n",
    "    accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    print(\"Accuracy: \"+str(accuracy))\n",
    "    print(\"Precision: \"+str(precision))\n",
    "    print(\"Recall: \"+str(recall))\n",
    "    print()    \n",
    "    print(\"Confusion matrix:\")\n",
    "    cm = [[tp,fp],[fn,tn]]\n",
    "    print(cm)\n",
    "    print()\n",
    "    df_cm = pd.DataFrame(cm, range(2), range(2))\n",
    "    plt.figure(figsize = (10,7))\n",
    "    sns.heatmap(df_cm, annot=True)\n",
    "    plt.title('Confusion Matrix', fontsize = 20) \n",
    "    plt.xlabel('Predicted', fontsize = 15) \n",
    "    plt.ylabel('Actual', fontsize = 15) \n",
    "\n",
    "plt.show()\n",
    "test(X_test, y_test)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MLP",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
