{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "bVTUa6LZlGbq",
    "outputId": "9073bcaa-1654-4b76-d28b-caa8ea212cd2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "jdCKsynT5r2C",
    "outputId": "34843460-60e9-4166-a635-9c0bd09434e6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.6661</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.1674</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.6383</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.5228</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.4552</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1       2        3  4\n",
       "0  3.62160  8.6661 -2.8073 -0.44699  0\n",
       "1  4.54590  8.1674 -2.4586 -1.46210  0\n",
       "2  3.86600 -2.6383  1.9242  0.10645  0\n",
       "3  3.45660  9.5228 -4.0112 -3.59440  0\n",
       "4  0.32924 -4.4552  4.5718 -0.98880  0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading the dataset from csv file\n",
    "def read_data(file):\n",
    "    data = pd.read_csv(file, header=None , index_col=None)\n",
    "    return data\n",
    "data = read_data('data.txt')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rh3P3ipc5wNg"
   },
   "outputs": [],
   "source": [
    "#shuffling and splitting of the dataset\n",
    "def split_data(data):\n",
    "    df = pd.DataFrame(data)\n",
    "    #shuffle the dataset\n",
    "    df = df.sample(frac=1)\n",
    "    #split the dataset\n",
    "    split = np.random.rand(len(df)) < 0.7\n",
    "    train = np.asmatrix(df[split], dtype = 'float64')\n",
    "    test = np.asmatrix(df[~split], dtype = 'float64')\n",
    "    X_train = train[:, :-1]\n",
    "    y_train = train[:, -1]\n",
    "    X_test = test[:, :-1]\n",
    "    y_test = test[:,-1]\n",
    "    return X_train,y_train,X_test,y_test\n",
    "X_train,y_train,X_test,y_test = split_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T7NaB0L46YaZ"
   },
   "outputs": [],
   "source": [
    "#initializing params\n",
    "alpha = 0.7\n",
    "epoch = 100\n",
    "W = np.zeros(X_train.shape[1]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I0JXs9josyx0"
   },
   "outputs": [],
   "source": [
    "#activation function\n",
    "def activation(z):\n",
    "        if z>=0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Chqyq4s5tmB"
   },
   "outputs": [],
   "source": [
    " #prediction function\n",
    " def predict(x):\n",
    "    z = np.dot(x, W[1:]) + W[0]\n",
    "    g = activation(z)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "xlZw8sfe5weh",
    "outputId": "92e0367a-b7b2-404f-8ed3-3c392e4eff4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0  weight:[  9.8       -24.0156427 -24.0156427 -24.0156427 -24.0156427]  learning rate:0.7  Training Accuracy:94.64469618949536\n",
      "epoch:1  weight:[ 22.4        -45.71179725 -45.71179725 -45.71179725 -45.71179725]  learning rate:0.7  Training Accuracy:94.85066941297632\n",
      "epoch:2  weight:[ 35.        -68.9516618 -68.9516618 -68.9516618 -68.9516618]  learning rate:0.7  Training Accuracy:94.85066941297632\n",
      "epoch:3  weight:[ 48.3        -93.07128635 -93.07128635 -93.07128635 -93.07128635]  learning rate:0.7  Training Accuracy:94.74768280123584\n",
      "epoch:4  weight:[  61.6       -117.1909109 -117.1909109 -117.1909109 -117.1909109]  learning rate:0.7  Training Accuracy:94.74768280123584\n",
      "epoch:5  weight:[  74.9        -141.31053545 -141.31053545 -141.31053545 -141.31053545]  learning rate:0.7  Training Accuracy:94.74768280123584\n",
      "epoch:6  weight:[  87.5     -163.19891 -163.19891 -163.19891 -163.19891]  learning rate:0.7  Training Accuracy:94.85066941297632\n",
      "epoch:7  weight:[ 100.1        -185.08728455 -185.08728455 -185.08728455 -185.08728455]  learning rate:0.7  Training Accuracy:94.85066941297632\n",
      "epoch:8  weight:[ 112.        -206.0035691 -206.0035691 -206.0035691 -206.0035691]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:9  weight:[ 123.9        -226.91985365 -226.91985365 -226.91985365 -226.91985365]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:10  weight:[ 135.8       -247.8361382 -247.8361382 -247.8361382 -247.8361382]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:11  weight:[ 147.7        -268.75242275 -268.75242275 -268.75242275 -268.75242275]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:12  weight:[ 159.6       -289.6687073 -289.6687073 -289.6687073 -289.6687073]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:13  weight:[ 171.5        -310.58499185 -310.58499185 -310.58499185 -310.58499185]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:14  weight:[ 183.4       -331.5012764 -331.5012764 -331.5012764 -331.5012764]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:15  weight:[ 195.3        -352.41756095 -352.41756095 -352.41756095 -352.41756095]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:16  weight:[ 207.2       -373.3338455 -373.3338455 -373.3338455 -373.3338455]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:17  weight:[ 219.1        -394.25013005 -394.25013005 -394.25013005 -394.25013005]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:18  weight:[ 231.        -415.1664146 -415.1664146 -415.1664146 -415.1664146]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:19  weight:[ 242.9        -436.08269915 -436.08269915 -436.08269915 -436.08269915]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:20  weight:[ 254.8       -456.9989837 -456.9989837 -456.9989837 -456.9989837]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:21  weight:[ 266.7        -477.91526825 -477.91526825 -477.91526825 -477.91526825]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:22  weight:[ 278.6       -498.8315528 -498.8315528 -498.8315528 -498.8315528]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:23  weight:[ 290.5        -519.74783735 -519.74783735 -519.74783735 -519.74783735]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:24  weight:[ 302.4       -540.6641219 -540.6641219 -540.6641219 -540.6641219]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:25  weight:[ 314.3        -561.58040645 -561.58040645 -561.58040645 -561.58040645]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:26  weight:[ 326.2      -582.496691 -582.496691 -582.496691 -582.496691]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:27  weight:[ 338.1        -603.41297555 -603.41297555 -603.41297555 -603.41297555]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:28  weight:[ 350.        -624.3292601 -624.3292601 -624.3292601 -624.3292601]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:29  weight:[ 361.9        -645.24554465 -645.24554465 -645.24554465 -645.24554465]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:30  weight:[ 373.8       -666.1618292 -666.1618292 -666.1618292 -666.1618292]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:31  weight:[ 385.7        -687.07811375 -687.07811375 -687.07811375 -687.07811375]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:32  weight:[ 397.6       -707.9943983 -707.9943983 -707.9943983 -707.9943983]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:33  weight:[ 409.5        -728.91068285 -728.91068285 -728.91068285 -728.91068285]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:34  weight:[ 421.4       -749.8269674 -749.8269674 -749.8269674 -749.8269674]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:35  weight:[ 433.3        -770.74325195 -770.74325195 -770.74325195 -770.74325195]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:36  weight:[ 445.2       -791.6595365 -791.6595365 -791.6595365 -791.6595365]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:37  weight:[ 457.1        -812.57582105 -812.57582105 -812.57582105 -812.57582105]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:38  weight:[ 469.        -833.4921056 -833.4921056 -833.4921056 -833.4921056]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:39  weight:[ 480.9        -854.40839015 -854.40839015 -854.40839015 -854.40839015]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:40  weight:[ 492.8       -875.3246747 -875.3246747 -875.3246747 -875.3246747]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:41  weight:[ 504.7        -896.24095925 -896.24095925 -896.24095925 -896.24095925]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:42  weight:[ 516.6       -917.1572438 -917.1572438 -917.1572438 -917.1572438]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:43  weight:[ 528.5        -938.07352835 -938.07352835 -938.07352835 -938.07352835]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:44  weight:[ 540.4       -958.9898129 -958.9898129 -958.9898129 -958.9898129]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:45  weight:[ 552.3        -979.90609745 -979.90609745 -979.90609745 -979.90609745]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:46  weight:[  564.2      -1000.822382 -1000.822382 -1000.822382 -1000.822382]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:47  weight:[  576.1        -1021.73866655 -1021.73866655 -1021.73866655\n",
      " -1021.73866655]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:48  weight:[  588.        -1042.6549511 -1042.6549511 -1042.6549511 -1042.6549511]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:49  weight:[  599.9        -1063.57123565 -1063.57123565 -1063.57123565\n",
      " -1063.57123565]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:50  weight:[  611.8       -1084.4875202 -1084.4875202 -1084.4875202 -1084.4875202]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:51  weight:[  623.7        -1105.40380475 -1105.40380475 -1105.40380475\n",
      " -1105.40380475]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:52  weight:[  635.6       -1126.3200893 -1126.3200893 -1126.3200893 -1126.3200893]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:53  weight:[  647.5        -1147.23637385 -1147.23637385 -1147.23637385\n",
      " -1147.23637385]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:54  weight:[  659.4       -1168.1526584 -1168.1526584 -1168.1526584 -1168.1526584]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:55  weight:[  671.3        -1189.06894295 -1189.06894295 -1189.06894295\n",
      " -1189.06894295]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:56  weight:[  683.2       -1209.9852275 -1209.9852275 -1209.9852275 -1209.9852275]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:57  weight:[  695.1        -1230.90151205 -1230.90151205 -1230.90151205\n",
      " -1230.90151205]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:58  weight:[  707.        -1251.8177966 -1251.8177966 -1251.8177966 -1251.8177966]  learning rate:0.7  Training Accuracy:94.95365602471678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:59  weight:[  718.9        -1272.73408115 -1272.73408115 -1272.73408115\n",
      " -1272.73408115]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:60  weight:[  730.8       -1293.6503657 -1293.6503657 -1293.6503657 -1293.6503657]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:61  weight:[  742.7        -1314.56665025 -1314.56665025 -1314.56665025\n",
      " -1314.56665025]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:62  weight:[  754.6       -1335.4829348 -1335.4829348 -1335.4829348 -1335.4829348]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:63  weight:[  766.5        -1356.39921935 -1356.39921935 -1356.39921935\n",
      " -1356.39921935]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:64  weight:[  778.4       -1377.3155039 -1377.3155039 -1377.3155039 -1377.3155039]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:65  weight:[  790.3        -1398.23178845 -1398.23178845 -1398.23178845\n",
      " -1398.23178845]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:66  weight:[  802.2      -1419.148073 -1419.148073 -1419.148073 -1419.148073]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:67  weight:[  814.1        -1440.06435755 -1440.06435755 -1440.06435755\n",
      " -1440.06435755]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:68  weight:[  826.        -1460.9806421 -1460.9806421 -1460.9806421 -1460.9806421]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:69  weight:[  837.9        -1481.89692665 -1481.89692665 -1481.89692665\n",
      " -1481.89692665]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:70  weight:[  849.8       -1502.8132112 -1502.8132112 -1502.8132112 -1502.8132112]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:71  weight:[  861.7        -1523.72949575 -1523.72949575 -1523.72949575\n",
      " -1523.72949575]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:72  weight:[  873.6       -1544.6457803 -1544.6457803 -1544.6457803 -1544.6457803]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:73  weight:[  885.5        -1565.56206485 -1565.56206485 -1565.56206485\n",
      " -1565.56206485]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:74  weight:[  897.4       -1586.4783494 -1586.4783494 -1586.4783494 -1586.4783494]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:75  weight:[  909.3        -1607.39463395 -1607.39463395 -1607.39463395\n",
      " -1607.39463395]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:76  weight:[  921.2       -1628.3109185 -1628.3109185 -1628.3109185 -1628.3109185]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:77  weight:[  933.1        -1649.22720305 -1649.22720305 -1649.22720305\n",
      " -1649.22720305]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:78  weight:[  945.        -1670.1434876 -1670.1434876 -1670.1434876 -1670.1434876]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:79  weight:[  956.9        -1691.05977215 -1691.05977215 -1691.05977215\n",
      " -1691.05977215]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:80  weight:[  968.8       -1711.9760567 -1711.9760567 -1711.9760567 -1711.9760567]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:81  weight:[  980.7        -1732.89234125 -1732.89234125 -1732.89234125\n",
      " -1732.89234125]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:82  weight:[  992.6       -1753.8086258 -1753.8086258 -1753.8086258 -1753.8086258]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:83  weight:[ 1004.5        -1774.72491035 -1774.72491035 -1774.72491035\n",
      " -1774.72491035]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:84  weight:[ 1016.4       -1795.6411949 -1795.6411949 -1795.6411949 -1795.6411949]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:85  weight:[ 1028.3        -1816.55747945 -1816.55747945 -1816.55747945\n",
      " -1816.55747945]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:86  weight:[ 1040.2      -1837.473764 -1837.473764 -1837.473764 -1837.473764]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:87  weight:[ 1052.1        -1858.39004855 -1858.39004855 -1858.39004855\n",
      " -1858.39004855]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:88  weight:[ 1064.        -1879.3063331 -1879.3063331 -1879.3063331 -1879.3063331]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:89  weight:[ 1075.9        -1900.22261765 -1900.22261765 -1900.22261765\n",
      " -1900.22261765]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:90  weight:[ 1087.8       -1921.1389022 -1921.1389022 -1921.1389022 -1921.1389022]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:91  weight:[ 1099.7        -1942.05518675 -1942.05518675 -1942.05518675\n",
      " -1942.05518675]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:92  weight:[ 1111.6       -1962.9714713 -1962.9714713 -1962.9714713 -1962.9714713]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:93  weight:[ 1123.5        -1983.88775585 -1983.88775585 -1983.88775585\n",
      " -1983.88775585]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:94  weight:[ 1135.4       -2004.8040404 -2004.8040404 -2004.8040404 -2004.8040404]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:95  weight:[ 1147.3        -2025.72032495 -2025.72032495 -2025.72032495\n",
      " -2025.72032495]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:96  weight:[ 1159.2       -2046.6366095 -2046.6366095 -2046.6366095 -2046.6366095]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:97  weight:[ 1171.1        -2067.55289405 -2067.55289405 -2067.55289405\n",
      " -2067.55289405]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:98  weight:[ 1183.        -2088.4691786 -2088.4691786 -2088.4691786 -2088.4691786]  learning rate:0.7  Training Accuracy:94.95365602471678\n",
      "epoch:99  weight:[ 1194.9        -2109.38546315 -2109.38546315 -2109.38546315\n",
      " -2109.38546315]  learning rate:0.7  Training Accuracy:94.95365602471678\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " #training to learn the weights\n",
    " def train(X_train, y_train):\n",
    "        loss_train = []\n",
    "        epochs = range(1,epoch+1)\n",
    "        for i in range(epoch):\n",
    "            correct = 0\n",
    "            for x, y in zip(X_train, y_train):\n",
    "                prediction = predict(x)\n",
    "                y = np.array(y)[0][0]\n",
    "                x = np.array(x)[0]\n",
    "                error = y - prediction\n",
    "                actual_value = int(y)\n",
    "                if actual_value == prediction:\n",
    "                  correct += 1\n",
    "                W[1:] += alpha * error * x[0]\n",
    "                W[0] += alpha * error\n",
    "            training_accuracy =  correct/float(X_train.shape[0])*100.0      \n",
    "            loss_train.append(training_accuracy)\n",
    "            print(\"epoch:\"+str(i)+\"  weight:\"+str(W)+\"  learning rate:\"+str(alpha)+\"  Training Accuracy:\"+str(training_accuracy))\n",
    "        plt.plot(epochs, loss_train, 'g', label='Training loss')        \n",
    "        plt.xlim(0,epoch)\n",
    "        plt.title('Training loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "train(X_train, y_train)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "04HqxpXN52es",
    "outputId": "4942797e-b57d-4670-9f7e-21bb41c568f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on test data:\n",
      "X: [[-1.749   -6.332    6.0987   0.14266]] prediction: 1 Actual value:1\n",
      "X: [[ 2.4287  9.3821 -3.2477 -1.4543]] prediction: 0 Actual value:0\n",
      "X: [[ 0.64376  3.764   -4.4738  -4.0483 ]] prediction: 1 Actual value:1\n",
      "X: [[-0.53072  -0.097265 -0.21793   1.0426  ]] prediction: 1 Actual value:1\n",
      "X: [[ 0.64295  7.1018   0.3493  -0.41337]] prediction: 0 Actual value:0\n",
      "X: [[ 3.8244  -3.1081   2.4537   0.52024]] prediction: 0 Actual value:0\n",
      "X: [[ 0.75896  0.29176 -1.6506   0.83834]] prediction: 1 Actual value:1\n",
      "X: [[-4.2333   4.9166  -0.49212 -5.3207 ]] prediction: 1 Actual value:1\n",
      "X: [[2.6719  3.0646  0.37158 0.58619]] prediction: 0 Actual value:0\n",
      "X: [[1.8799  2.4707  2.4931  0.37671]] prediction: 0 Actual value:0\n",
      "X: [[-1.8076  -8.8131   8.7086  -0.21682]] prediction: 1 Actual value:1\n",
      "X: [[-1.2369  -1.6906   2.518    0.51636]] prediction: 1 Actual value:1\n",
      "X: [[-2.4458   1.6285  -0.88541 -1.4802 ]] prediction: 1 Actual value:1\n",
      "X: [[1.3562  3.2136  4.3465  0.78662]] prediction: 0 Actual value:0\n",
      "X: [[ 3.757  -5.4236  3.8255 -1.2526]] prediction: 0 Actual value:0\n",
      "X: [[ 1.3264   1.0326   5.6566  -0.41337]] prediction: 0 Actual value:0\n",
      "X: [[-1.0833  -0.31247  1.2815   0.41291]] prediction: 1 Actual value:1\n",
      "X: [[-0.82053  0.65181 -0.48869 -0.52716]] prediction: 1 Actual value:1\n",
      "X: [[-5.4414   7.2363   0.10938 -7.5642 ]] prediction: 1 Actual value:1\n",
      "X: [[-2.0529   3.8385  -0.79544 -1.2138 ]] prediction: 1 Actual value:1\n",
      "X: [[-1.1022  -5.8395   4.5641   0.68705]] prediction: 1 Actual value:1\n",
      "X: [[ 0.9297 -3.7971  4.6429 -0.2957]] prediction: 0 Actual value:0\n",
      "X: [[-1.6176   1.0926  -0.35502 -0.59958]] prediction: 1 Actual value:1\n",
      "X: [[-2.2918 -7.257   7.9597  0.9211]] prediction: 1 Actual value:1\n",
      "X: [[4.2027  0.22761 0.96108 0.97282]] prediction: 0 Actual value:0\n",
      "X: [[-1.7589  -6.4624   8.4773   0.31981]] prediction: 0 Actual value:1\n",
      "X: [[ 1.2616  4.4303 -1.3335 -1.7517]] prediction: 0 Actual value:0\n",
      "X: [[ -2.9672 -13.2869  13.4727  -2.6271]] prediction: 1 Actual value:1\n",
      "X: [[ 0.5195 -3.2633  3.0895 -0.9849]] prediction: 1 Actual value:0\n",
      "X: [[-0.16735  7.6274   1.2061  -3.6241 ]] prediction: 0 Actual value:0\n",
      "X: [[-2.5346e+00 -7.7392e-01  3.3602e+00  1.7100e-03]] prediction: 1 Actual value:1\n",
      "X: [[ 2.1319   -2.0403    2.5574   -0.061652]] prediction: 0 Actual value:0\n",
      "X: [[ 1.5799 -4.7076  7.9186 -1.5487]] prediction: 0 Actual value:0\n",
      "X: [[ 3.6077   6.8576  -1.1622   0.28231]] prediction: 0 Actual value:0\n",
      "X: [[ 5.504  10.3671 -4.413  -4.0211]] prediction: 0 Actual value:0\n",
      "X: [[ 0.21431 -0.69529  0.87711  0.29653]] prediction: 0 Actual value:1\n",
      "X: [[ 2.4391   6.4417  -0.80743 -0.69139]] prediction: 0 Actual value:0\n",
      "X: [[-0.26654 -0.64562 -0.42014  0.89136]] prediction: 1 Actual value:1\n",
      "X: [[-0.64326  2.4748  -2.9452  -1.0276 ]] prediction: 1 Actual value:1\n",
      "X: [[-2.3142  -0.68494  1.9833  -0.44829]] prediction: 1 Actual value:1\n",
      "X: [[-2.9883    0.31245   0.45041   0.068951]] prediction: 1 Actual value:1\n",
      "X: [[ 3.0864  -2.5845   2.2309   0.30947]] prediction: 0 Actual value:0\n",
      "X: [[ 5.681    7.795   -2.6848  -0.92544]] prediction: 0 Actual value:0\n",
      "X: [[3.4663 1.1112 1.7425 1.3388]] prediction: 0 Actual value:0\n",
      "X: [[ 4.068   -2.9363   2.1992   0.50084]] prediction: 0 Actual value:0\n",
      "X: [[ 3.6922 -3.9585  4.3439  1.3517]] prediction: 0 Actual value:0\n",
      "X: [[-2.1333    1.5685   -0.084261 -1.7453  ]] prediction: 1 Actual value:1\n",
      "X: [[ 2.888    0.44696  4.5907  -0.24398]] prediction: 0 Actual value:0\n",
      "X: [[-3.3604  -0.32696  2.1324   0.6017 ]] prediction: 1 Actual value:1\n",
      "X: [[-3.3458  -0.50491  2.6328   0.53705]] prediction: 1 Actual value:1\n",
      "X: [[-2.2527 11.5321  2.5899 -3.2737]] prediction: 0 Actual value:0\n",
      "X: [[-1.5768 10.843   2.5462 -2.9362]] prediction: 0 Actual value:0\n",
      "X: [[-4.3667   6.0692   0.57208 -5.4668 ]] prediction: 1 Actual value:1\n",
      "X: [[4.0972  0.46972 1.6671  0.91593]] prediction: 0 Actual value:0\n",
      "X: [[-0.65767 -2.8018   3.7115   0.99739]] prediction: 0 Actual value:1\n",
      "X: [[-0.50816  2.868   -1.8108  -2.2612 ]] prediction: 1 Actual value:1\n",
      "X: [[ 1.2262   0.89599  5.7568  -0.11596]] prediction: 0 Actual value:0\n",
      "X: [[-1.7263  -6.0237   5.2419   0.29524]] prediction: 1 Actual value:1\n",
      "X: [[-6.1632   8.7096  -0.21621 -3.6345 ]] prediction: 1 Actual value:1\n",
      "X: [[-2.7908  -5.7133   5.953    0.45946]] prediction: 1 Actual value:1\n",
      "X: [[ 3.0934  -2.9177   2.2232   0.22283]] prediction: 0 Actual value:0\n",
      "X: [[ 0.7057 -5.4981  8.3368 -2.8715]] prediction: 0 Actual value:0\n",
      "X: [[ 4.988   7.2052 -3.2846 -1.1608]] prediction: 0 Actual value:0\n",
      "X: [[4.0552  0.40143 1.4563  0.65343]] prediction: 0 Actual value:0\n",
      "X: [[-1.1193 10.7271  2.0938 -5.6504]] prediction: 0 Actual value:0\n",
      "X: [[-3.3884  -8.215   10.3315   0.98187]] prediction: 1 Actual value:1\n",
      "X: [[-2.0662   0.16967 -1.0054  -0.82975]] prediction: 1 Actual value:1\n",
      "X: [[-2.3242 11.5176  1.8231 -5.375 ]] prediction: 0 Actual value:0\n",
      "X: [[-2.4365  3.6026 -1.4166 -2.8948]] prediction: 1 Actual value:1\n",
      "X: [[ 3.0333 -2.5928  2.3183  0.303 ]] prediction: 0 Actual value:0\n",
      "X: [[ 5.1302  8.6703 -2.8913 -1.5086]] prediction: 0 Actual value:0\n",
      "X: [[ 0.5706 -0.0248  1.2421 -0.5621]] prediction: 0 Actual value:0\n",
      "X: [[ 4.8077   2.2327  -0.26334  1.5534 ]] prediction: 0 Actual value:0\n",
      "X: [[3.5127  2.9073  1.0579  0.40774]] prediction: 0 Actual value:0\n",
      "X: [[-2.7419 11.4038  2.5394 -5.5793]] prediction: 0 Actual value:0\n",
      "X: [[ 3.4805  9.7008 -3.7541 -3.4379]] prediction: 0 Actual value:0\n",
      "X: [[ 4.9923   7.8653  -2.3515  -0.71984]] prediction: 0 Actual value:0\n",
      "X: [[ 5.0429  -0.52974  0.50439  1.106  ]] prediction: 0 Actual value:0\n",
      "X: [[-4.7462  3.1205  1.075  -1.2966]] prediction: 1 Actual value:1\n",
      "X: [[ 4.65    -4.8297   3.4553  -0.25174]] prediction: 0 Actual value:0\n",
      "X: [[-0.0012852  0.13863   -0.19651    0.0081754]] prediction: 1 Actual value:1\n",
      "X: [[1.6472  0.48213 4.7449  1.225  ]] prediction: 0 Actual value:0\n",
      "X: [[ 3.1219  -3.137    1.9259  -0.37458]] prediction: 0 Actual value:0\n",
      "X: [[ 1.5268 -5.5871  8.6564 -1.722 ]] prediction: 0 Actual value:0\n",
      "X: [[-0.83535  0.80494 -1.6411  -0.19225]] prediction: 1 Actual value:1\n",
      "X: [[ 2.4226  -4.5752   5.947    0.21507]] prediction: 0 Actual value:0\n",
      "X: [[-2.5665  -6.8824   7.5416   0.70774]] prediction: 1 Actual value:1\n",
      "X: [[2.4673  1.3926  1.7125  0.41421]] prediction: 0 Actual value:0\n",
      "X: [[-2.3518   -4.8359    6.6479   -0.060358]] prediction: 1 Actual value:1\n",
      "X: [[ 2.7213   7.05    -0.58808  0.41809]] prediction: 0 Actual value:0\n",
      "X: [[-0.7869  9.5663 -3.7867 -7.5034]] prediction: 1 Actual value:0\n",
      "X: [[3.8999  1.734   1.6011  0.96765]] prediction: 0 Actual value:0\n",
      "X: [[-2.8829  3.8964 -0.1888 -1.1672]] prediction: 1 Actual value:1\n",
      "X: [[-0.60975 -4.002    1.8471   0.6017 ]] prediction: 1 Actual value:1\n",
      "X: [[ 1.581    0.86909 -2.3138   0.82412]] prediction: 0 Actual value:1\n",
      "X: [[-0.89569  3.0025  -3.6067  -3.4457 ]] prediction: 1 Actual value:1\n",
      "X: [[-0.8734   1.6533  -2.1964  -0.78061]] prediction: 1 Actual value:1\n",
      "X: [[ 3.4626  -4.449    3.5427   0.15429]] prediction: 0 Actual value:0\n",
      "X: [[-0.47465 -4.3496   1.9901   0.7517 ]] prediction: 1 Actual value:1\n",
      "X: [[-2.0046  -0.49457  1.333    1.6543 ]] prediction: 1 Actual value:1\n",
      "X: [[-0.8172  3.3812 -3.6684 -3.456 ]] prediction: 1 Actual value:1\n",
      "X: [[ 4.6352 -3.0087  2.6773  1.212 ]] prediction: 0 Actual value:0\n",
      "X: [[ 4.1757 10.2615 -3.8552 -4.3056]] prediction: 0 Actual value:0\n",
      "X: [[ 3.8481 10.1539 -3.8561 -4.2228]] prediction: 0 Actual value:0\n",
      "X: [[ 4.2969   7.617   -2.3874  -0.96164]] prediction: 0 Actual value:0\n",
      "X: [[ 2.5605  9.2683 -3.5913 -1.356 ]] prediction: 0 Actual value:0\n",
      "X: [[-3.6085   3.3253  -0.51954 -3.5737 ]] prediction: 1 Actual value:1\n",
      "X: [[3.6667  4.302   0.55923 0.33791]] prediction: 0 Actual value:0\n",
      "X: [[-0.2361  9.3221  2.1307 -4.3793]] prediction: 0 Actual value:0\n",
      "X: [[ 1.0552   1.1857  -2.6411   0.11033]] prediction: 1 Actual value:1\n",
      "X: [[0.80355 2.8473  4.3439  0.6017 ]] prediction: 0 Actual value:0\n",
      "X: [[-1.3274  9.498   2.4408 -5.2689]] prediction: 0 Actual value:0\n",
      "X: [[ 3.2422   6.2265   0.12224 -1.4466 ]] prediction: 0 Actual value:0\n",
      "X: [[-4.3876 -7.7267 11.9655 -1.4543]] prediction: 1 Actual value:1\n",
      "X: [[-1.7582  2.7397 -2.5323 -2.234 ]] prediction: 1 Actual value:1\n",
      "X: [[-0.95403  1.9824  -2.3163  -1.1957 ]] prediction: 1 Actual value:1\n",
      "X: [[ 2.8672 10.0008 -3.2049 -3.1095]] prediction: 0 Actual value:0\n",
      "X: [[ -3.7503 -13.4586  17.5932  -2.7771]] prediction: 1 Actual value:1\n",
      "X: [[0.86202 2.6963  4.2908  0.54739]] prediction: 0 Actual value:0\n",
      "X: [[ 3.1836  7.2321 -1.0713 -2.5909]] prediction: 0 Actual value:0\n",
      "X: [[ 3.4667 -4.0724  4.2882  1.5418]] prediction: 0 Actual value:0\n",
      "X: [[-1.6677  -7.1535   7.8929   0.96765]] prediction: 1 Actual value:1\n",
      "X: [[ 0.57461 10.1105  -1.6917  -4.3922 ]] prediction: 0 Actual value:0\n",
      "X: [[-1.3    10.2678 -2.953  -5.8638]] prediction: 1 Actual value:0\n",
      "X: [[ 1.3234   3.2964   0.2362  -0.11984]] prediction: 0 Actual value:0\n",
      "X: [[-1.6386  3.3584 -1.7302 -3.5646]] prediction: 1 Actual value:1\n",
      "X: [[ -3.73   -12.9723  12.9817  -2.684 ]] prediction: 1 Actual value:1\n",
      "X: [[ 0.32924 -4.4552   4.5718  -0.9888 ]] prediction: 1 Actual value:0\n",
      "X: [[-3.1366    0.42212   2.6225   -0.064238]] prediction: 1 Actual value:1\n",
      "X: [[-0.49281  3.0605  -1.8356  -2.834  ]] prediction: 1 Actual value:1\n",
      "X: [[ 1.6799  4.2068 -4.5398 -2.3931]] prediction: 1 Actual value:1\n",
      "X: [[ 0.21084   9.4359   -0.094543 -1.859   ]] prediction: 0 Actual value:0\n",
      "X: [[-5.1661    8.0433    0.044265 -4.4983  ]] prediction: 1 Actual value:1\n",
      "X: [[-2.2183  -1.254    2.9986   0.36378]] prediction: 1 Actual value:1\n",
      "X: [[ 2.9163 10.8306 -3.3437 -4.122 ]] prediction: 0 Actual value:0\n",
      "X: [[1.3087  4.9228  2.0013  0.22024]] prediction: 0 Actual value:0\n",
      "X: [[-0.95923 -6.7128   4.9857   0.32886]] prediction: 1 Actual value:1\n",
      "X: [[-0.98193  2.7956  -1.2341  -1.5668 ]] prediction: 1 Actual value:1\n",
      "X: [[-5.0477 -5.8023 11.244  -0.3901]] prediction: 1 Actual value:1\n",
      "X: [[-6.7526    8.8172   -0.061983 -3.725   ]] prediction: 1 Actual value:1\n",
      "X: [[-3.6227   3.9958  -0.35845 -3.9047 ]] prediction: 1 Actual value:1\n",
      "X: [[ 3.3577  -4.3062   6.0241   0.18274]] prediction: 0 Actual value:0\n",
      "X: [[ 3.5458  9.3718 -4.0351 -3.9564]] prediction: 0 Actual value:0\n",
      "X: [[ 1.6849  8.7489 -1.2641 -1.3858]] prediction: 0 Actual value:0\n",
      "X: [[-1.5621  -2.2121   4.2591   0.27972]] prediction: 0 Actual value:1\n",
      "X: [[-2.0659   1.0512  -0.46298 -1.0974 ]] prediction: 1 Actual value:1\n",
      "X: [[ 4.052   -0.16555  0.45383  0.51248]] prediction: 0 Actual value:0\n",
      "X: [[-2.341   12.3784   0.70403 -7.5836 ]] prediction: 0 Actual value:0\n",
      "X: [[-3.551   1.8955  0.1865 -2.4409]] prediction: 1 Actual value:1\n",
      "X: [[ 0.77805  6.6424  -1.1425  -1.0573 ]] prediction: 0 Actual value:0\n",
      "X: [[-3.8953  4.0392 -0.3019 -2.1836]] prediction: 1 Actual value:1\n",
      "X: [[-0.24811 -0.17797  4.9068   0.15429]] prediction: 0 Actual value:0\n",
      "X: [[ 0.60731  3.9544  -4.772   -4.4853 ]] prediction: 1 Actual value:1\n",
      "X: [[ 4.9852  8.3516 -2.5425 -1.2823]] prediction: 0 Actual value:0\n",
      "X: [[ 0.14329 -1.0885   1.0039   0.48791]] prediction: 1 Actual value:1\n",
      "X: [[-0.37013 -5.554    4.7749   1.547  ]] prediction: 1 Actual value:1\n",
      "X: [[ 2.6213    5.7919    0.065686 -1.5759  ]] prediction: 0 Actual value:0\n",
      "X: [[-2.5919  -1.0553   3.8949   0.77757]] prediction: 0 Actual value:1\n",
      "X: [[ 2.565   8.633  -2.9941 -1.3082]] prediction: 0 Actual value:0\n",
      "X: [[2.2504  3.5757  0.35273 0.2836 ]] prediction: 0 Actual value:0\n",
      "X: [[-4.2091   4.7283  -0.49126 -5.2159 ]] prediction: 1 Actual value:1\n",
      "X: [[1.1558 6.4003 1.5506 0.6961]] prediction: 0 Actual value:0\n",
      "X: [[ 1.2572  4.8731 -5.2861 -5.8741]] prediction: 1 Actual value:1\n",
      "X: [[1.8384  6.063   0.54723 0.51248]] prediction: 0 Actual value:0\n",
      "X: [[-5.2049    7.259     0.070827 -7.3004  ]] prediction: 1 Actual value:1\n",
      "X: [[ 1.4378   0.66837 -2.0267   1.0271 ]] prediction: 0 Actual value:1\n",
      "X: [[2.0007  1.8644  2.6491  0.47369]] prediction: 0 Actual value:0\n",
      "X: [[-1.9881   0.99945 -0.28562 -0.70044]] prediction: 1 Actual value:1\n",
      "X: [[-3.0193   1.7775   0.73745 -0.45346]] prediction: 1 Actual value:1\n",
      "X: [[3.5257 1.2829 1.9276 1.7991]] prediction: 0 Actual value:0\n",
      "X: [[ 3.5862  -3.0957   2.8093   0.24481]] prediction: 0 Actual value:0\n",
      "X: [[ 3.8905 -2.1521  2.6302  1.1047]] prediction: 0 Actual value:0\n",
      "X: [[ 2.0177  1.7982 -2.9581  0.2099]] prediction: 0 Actual value:1\n",
      "X: [[ 4.8368 10.0132 -4.3239 -4.3276]] prediction: 0 Actual value:0\n",
      "X: [[-0.30432  2.6528  -2.7756  -0.65647]] prediction: 1 Actual value:1\n",
      "X: [[ 3.0672  -4.4117   3.8238  -0.81682]] prediction: 0 Actual value:0\n",
      "X: [[ 3.4893   6.69    -1.2042  -0.38751]] prediction: 0 Actual value:0\n",
      "X: [[-1.6988  -7.1163   5.7902   0.16723]] prediction: 1 Actual value:1\n",
      "X: [[-1.5951  -6.572    4.7689  -0.94354]] prediction: 1 Actual value:1\n",
      "X: [[ 2.5698   -4.4076    5.9856    0.078002]] prediction: 0 Actual value:0\n",
      "X: [[-2.6989  12.1984   0.67661 -8.5482 ]] prediction: 0 Actual value:0\n",
      "X: [[ 1.6406   3.5488   1.3964  -0.36424]] prediction: 0 Actual value:0\n",
      "X: [[ 2.9499    2.2493    1.3458   -0.037083]] prediction: 0 Actual value:0\n",
      "X: [[ 0.26637  0.73252 -0.67891  0.03533]] prediction: 1 Actual value:1\n",
      "X: [[ 4.0715  7.6398 -2.0824 -1.1698]] prediction: 0 Actual value:0\n",
      "X: [[-0.16682  5.8974   0.49839 -0.70044]] prediction: 0 Actual value:0\n",
      "X: [[ 3.8117 10.1457 -4.0463 -4.5629]] prediction: 0 Actual value:0\n",
      "X: [[ 1.164   3.913  -4.5544 -3.8672]] prediction: 1 Actual value:1\n",
      "X: [[0.44125 2.9487  4.3225  0.7155 ]] prediction: 0 Actual value:0\n",
      "X: [[-3.5359   0.30417  0.6569  -0.2957 ]] prediction: 1 Actual value:1\n",
      "X: [[-5.9034   6.5679   0.67661 -6.6797 ]] prediction: 1 Actual value:1\n",
      "X: [[ 2.6917 10.8161 -3.3    -4.2888]] prediction: 0 Actual value:0\n",
      "X: [[ 3.7982 10.423  -4.1602 -4.9728]] prediction: 0 Actual value:0\n",
      "X: [[ -2.8957 -12.0205  11.9149  -2.7552]] prediction: 1 Actual value:1\n",
      "X: [[ 0.88444  6.5906   0.55837 -0.44182]] prediction: 0 Actual value:0\n",
      "X: [[-0.96511  9.4111   1.7305  -4.8629 ]] prediction: 0 Actual value:0\n",
      "X: [[-4.0679   2.4955   0.79571 -1.1039 ]] prediction: 1 Actual value:1\n",
      "X: [[ 1.5456  8.5482  0.4187 -2.1784]] prediction: 0 Actual value:0\n",
      "X: [[ 2.1526  -6.1665   8.0831  -0.34355]] prediction: 0 Actual value:0\n",
      "X: [[-1.1497   1.2954   7.701    0.62627]] prediction: 0 Actual value:0\n",
      "X: [[-0.71868 -5.7154   3.8298   1.0233 ]] prediction: 1 Actual value:1\n",
      "X: [[ 4.0948  -2.9674   2.3689   0.75429]] prediction: 0 Actual value:0\n",
      "X: [[ 1.0987   0.6394   5.989   -0.58277]] prediction: 0 Actual value:0\n",
      "X: [[-2.3898  -0.78427  3.0141   0.76205]] prediction: 0 Actual value:1\n",
      "X: [[ 0.3223  -0.89808  8.0883   0.69222]] prediction: 0 Actual value:0\n",
      "X: [[-0.9607  2.6963 -3.1226 -1.3121]] prediction: 1 Actual value:1\n",
      "X: [[ 2.0962    2.4769    1.9379   -0.040962]] prediction: 0 Actual value:0\n",
      "X: [[ 3.583   -3.7971   3.4391  -0.12501]] prediction: 0 Actual value:0\n",
      "X: [[ 0.50225  0.65388 -1.1793   0.39998]] prediction: 1 Actual value:1\n",
      "X: [[ 0.27331  4.8773  -4.9194  -5.8198 ]] prediction: 1 Actual value:1\n",
      "X: [[ 5.0452   3.8964  -1.4304   0.86291]] prediction: 0 Actual value:0\n",
      "X: [[-0.72068 -6.7583   5.8408   0.62369]] prediction: 1 Actual value:1\n",
      "X: [[ 2.7365  -5.0325   6.6608  -0.57889]] prediction: 0 Actual value:0\n",
      "X: [[-0.75793  2.5349  -3.0464  -1.2629 ]] prediction: 1 Actual value:1\n",
      "X: [[ 0.2346 -4.5152  2.1195  1.4448]] prediction: 1 Actual value:1\n",
      "X: [[ 4.6361 -2.6611  2.8358  1.1991]] prediction: 0 Actual value:0\n",
      "X: [[4.3937  0.35798 2.0416  1.2004 ]] prediction: 0 Actual value:0\n",
      "X: [[ 0.5195 -3.2633  3.0895 -0.9849]] prediction: 1 Actual value:0\n",
      "X: [[2.5581  2.6218  1.8513  0.40257]] prediction: 0 Actual value:0\n",
      "X: [[-4.9447  3.3005  1.063  -1.444 ]] prediction: 1 Actual value:1\n",
      "X: [[ 3.8962  -4.7904   3.3954  -0.53751]] prediction: 0 Actual value:0\n",
      "X: [[ 1.4896  3.4288 -4.0309 -1.4259]] prediction: 1 Actual value:1\n",
      "X: [[ -3.5985 -13.6593  17.6052  -2.4927]] prediction: 1 Actual value:1\n",
      "X: [[-1.4375  -1.8624   4.026    0.55127]] prediction: 0 Actual value:1\n",
      "X: [[ 2.1274  5.1939 -1.7971 -1.1763]] prediction: 0 Actual value:0\n",
      "X: [[-1.2576   1.5892   7.0078   0.42455]] prediction: 0 Actual value:0\n",
      "X: [[-1.7344   2.0175   7.7618   0.93532]] prediction: 0 Actual value:0\n",
      "X: [[-1.4377  -1.432    2.1144   0.42067]] prediction: 1 Actual value:1\n",
      "X: [[-1.8046 -6.8141  6.7019  1.1681]] prediction: 1 Actual value:1\n",
      "X: [[1.8373  6.1292  0.84027 0.55257]] prediction: 0 Actual value:0\n",
      "X: [[-0.71494 -4.4448   2.2241   0.49826]] prediction: 1 Actual value:1\n",
      "X: [[-4.1429   2.7749   0.68261 -0.71984]] prediction: 1 Actual value:1\n",
      "X: [[-0.39416  -0.020702 -0.066267 -0.44699 ]] prediction: 1 Actual value:1\n",
      "X: [[4.1962  0.74493 0.83256 0.753  ]] prediction: 0 Actual value:0\n",
      "X: [[ 4.8451  8.1116 -2.9512 -1.4724]] prediction: 0 Actual value:0\n",
      "X: [[-0.025314 -0.17383  -0.11339   1.2198  ]] prediction: 0 Actual value:1\n",
      "X: [[ 6.8248  5.2187 -2.5425  0.5461]] prediction: 0 Actual value:0\n",
      "X: [[-4.8861   7.0542  -0.17252 -6.959  ]] prediction: 1 Actual value:1\n",
      "X: [[-1.3066   0.25244  0.7623   1.7758 ]] prediction: 0 Actual value:1\n",
      "X: [[-2.4198  -0.24418  0.70146  0.41809]] prediction: 1 Actual value:1\n",
      "X: [[-0.49081  2.8452  -3.6436  -3.1004 ]] prediction: 1 Actual value:1\n",
      "X: [[ 0.26877  4.987   -5.1508  -6.3913 ]] prediction: 1 Actual value:1\n",
      "X: [[ 2.3729 10.4726 -3.0087 -3.2013]] prediction: 0 Actual value:0\n",
      "X: [[-2.4835  -7.4494   6.8964  -0.64484]] prediction: 1 Actual value:1\n",
      "X: [[ 0.94732 -0.57113  7.1903  -0.67587]] prediction: 0 Actual value:0\n",
      "X: [[ 2.8297   6.3485  -0.73546 -0.58665]] prediction: 0 Actual value:0\n",
      "X: [[-4.1244  3.7909 -0.6532 -4.1802]] prediction: 1 Actual value:1\n",
      "X: [[-1.1005  -7.2508   6.0139   0.36895]] prediction: 1 Actual value:1\n",
      "X: [[2.8237  2.8597  0.19678 0.57196]] prediction: 0 Actual value:0\n",
      "X: [[-0.7869  9.5663 -3.7867 -7.5034]] prediction: 1 Actual value:0\n",
      "X: [[ 4.1605 11.2196 -3.6136 -4.0819]] prediction: 0 Actual value:0\n",
      "X: [[ 1.518     5.6946    0.094818 -0.026738]] prediction: 0 Actual value:0\n",
      "X: [[ 0.19081  9.1297  -3.725   -5.8224 ]] prediction: 1 Actual value:0\n",
      "X: [[-0.95923   0.091039  6.2204   -1.4828  ]] prediction: 0 Actual value:0\n",
      "X: [[-0.77995  3.2322  -3.282   -3.1004 ]] prediction: 1 Actual value:1\n",
      "X: [[ -3.0986 -10.4602   8.9717  -2.3427]] prediction: 1 Actual value:1\n",
      "X: [[ 3.4916   8.5709  -3.0326  -0.59182]] prediction: 0 Actual value:0\n",
      "X: [[3.744   0.79459 0.95851 1.0077 ]] prediction: 0 Actual value:0\n",
      "X: [[-1.6029  -0.38903  1.62     1.9103 ]] prediction: 0 Actual value:1\n",
      "X: [[ 4.5679   3.1929  -2.1055   0.29653]] prediction: 0 Actual value:0\n",
      "X: [[ 2.0597  -0.99326  5.2119  -0.29312]] prediction: 0 Actual value:0\n",
      "X: [[ 0.74841  7.2756   1.1504  -0.5388 ]] prediction: 0 Actual value:0\n",
      "X: [[2.0421  1.2436  4.2171  0.90429]] prediction: 0 Actual value:0\n",
      "X: [[ 3.8197  8.9951 -4.383  -4.0327]] prediction: 0 Actual value:0\n",
      "X: [[ 0.93584  8.8855  -1.6831  -1.6599 ]] prediction: 0 Actual value:0\n",
      "X: [[ 2.6648 10.754  -3.3994 -4.1685]] prediction: 0 Actual value:0\n",
      "X: [[3.7791 2.5762 1.3098 0.5655]] prediction: 0 Actual value:0\n",
      "X: [[ 0.74428 -3.7723   1.6131   1.5754 ]] prediction: 1 Actual value:1\n",
      "X: [[ 3.2294   7.7391  -0.37816 -2.5405 ]] prediction: 0 Actual value:0\n",
      "X: [[-1.9116  -6.1603   5.606    0.48533]] prediction: 1 Actual value:1\n",
      "X: [[ 2.9719   6.8369  -0.2702   0.71291]] prediction: 0 Actual value:0\n",
      "X: [[-2.2987  -5.227    5.63     0.91722]] prediction: 1 Actual value:1\n",
      "X: [[-3.1158  -8.6289  10.4403   0.97153]] prediction: 1 Actual value:1\n",
      "X: [[-0.36038  4.1158   3.1143  -0.37199]] prediction: 0 Actual value:0\n",
      "X: [[ 4.1195 10.9258 -3.8929 -4.1802]] prediction: 0 Actual value:0\n",
      "X: [[-0.4294   -0.14693   0.044265 -0.15605 ]] prediction: 1 Actual value:1\n",
      "X: [[-2.2501   3.3129  -0.88369 -2.8974 ]] prediction: 1 Actual value:1\n",
      "X: [[2.5068  1.1588  3.9249  0.12585]] prediction: 0 Actual value:0\n",
      "X: [[-0.78289 11.3603  -0.37644 -7.0495 ]] prediction: 0 Actual value:0\n",
      "X: [[-0.016103  9.7484    0.15394  -1.6134  ]] prediction: 0 Actual value:0\n",
      "X: [[-7.0421   9.2      0.25933 -4.6832 ]] prediction: 1 Actual value:1\n",
      "X: [[-2.6864   -0.097265  0.61663   0.061192]] prediction: 1 Actual value:1\n",
      "X: [[ 0.98296  3.4226  -3.9692  -1.7116 ]] prediction: 1 Actual value:1\n",
      "X: [[-1.8448   1.254    0.27218 -1.0728 ]] prediction: 1 Actual value:1\n",
      "X: [[-3.7181  -8.5089  12.363   -0.95518]] prediction: 1 Actual value:1\n",
      "X: [[-0.1269  -1.1505  -0.95138  0.57843]] prediction: 1 Actual value:1\n",
      "X: [[-1.8411 10.8306  2.769  -3.0901]] prediction: 0 Actual value:0\n",
      "X: [[ 2.2123  -5.8395   7.7687  -0.85302]] prediction: 0 Actual value:0\n",
      "X: [[ 3.8384    6.1851   -2.0439   -0.033204]] prediction: 0 Actual value:0\n",
      "X: [[ 5.8862   5.8747  -2.8167  -0.30087]] prediction: 0 Actual value:0\n",
      "X: [[-2.5463   3.1101  -0.83228 -3.0358 ]] prediction: 1 Actual value:1\n",
      "X: [[ 3.7352  9.5911 -3.9032 -3.3487]] prediction: 0 Actual value:0\n",
      "X: [[3.5829 1.4423 1.0219 1.4008]] prediction: 0 Actual value:0\n",
      "X: [[-2.902   -7.6563  11.8318  -0.84268]] prediction: 1 Actual value:1\n",
      "X: [[-2.9915 -6.6258  8.6521  1.8198]] prediction: 0 Actual value:1\n",
      "X: [[ 2.2596   -0.033118  4.7355   -0.2776  ]] prediction: 0 Actual value:0\n",
      "X: [[-1.9551  -6.9756   5.5383  -0.12889]] prediction: 1 Actual value:1\n",
      "X: [[ 4.0127 10.1477 -3.9366 -4.0728]] prediction: 0 Actual value:0\n",
      "X: [[-0.27802  8.1881  -3.1338  -2.5276 ]] prediction: 0 Actual value:0\n",
      "X: [[ 1.7317  -0.34765  4.1905  -0.99138]] prediction: 0 Actual value:0\n",
      "X: [[ 2.5817  9.7546 -3.1749 -2.9957]] prediction: 0 Actual value:0\n",
      "X: [[ 3.3669 -5.1856  3.6935 -1.1427]] prediction: 0 Actual value:0\n",
      "X: [[-3.3582  -7.2404  11.4419  -0.57113]] prediction: 1 Actual value:1\n",
      "X: [[ 3.9922 -4.4676  3.7304 -0.1095]] prediction: 0 Actual value:0\n",
      "X: [[-1.4275  11.8797   0.41613 -6.9978 ]] prediction: 0 Actual value:0\n",
      "X: [[-3.9297 -6.0816 10.0958 -1.0147]] prediction: 1 Actual value:1\n",
      "X: [[ 0.81583  4.84    -5.2613  -6.0823 ]] prediction: 1 Actual value:1\n",
      "X: [[-5.873    9.1752  -0.27448 -6.0422 ]] prediction: 1 Actual value:1\n",
      "X: [[-3.8053  2.4273  0.6809 -1.0871]] prediction: 1 Actual value:1\n",
      "X: [[ 1.8967  -2.5163   2.8093  -0.79742]] prediction: 0 Actual value:0\n",
      "X: [[ 0.3292 -4.4552  4.5718 -0.9888]] prediction: 1 Actual value:0\n",
      "X: [[ 2.3678  -6.839    8.4207  -0.44829]] prediction: 0 Actual value:0\n",
      "X: [[-4.2249   6.2699   0.15822 -5.5457 ]] prediction: 1 Actual value:1\n",
      "X: [[-5.525    6.3258   0.89768 -6.6241 ]] prediction: 1 Actual value:1\n",
      "X: [[-2.2677  3.2964 -2.2563 -2.4642]] prediction: 1 Actual value:1\n",
      "X: [[ 5.7227   5.8312  -2.4097  -0.24527]] prediction: 0 Actual value:0\n",
      "X: [[ 0.81356  9.1566  -2.1492  -4.1814 ]] prediction: 0 Actual value:0\n",
      "X: [[-1.6641  -1.3678   1.997    0.52283]] prediction: 1 Actual value:1\n",
      "X: [[3.2414  0.40971 1.4015  1.1952 ]] prediction: 0 Actual value:0\n",
      "X: [[-3.3203  -0.02691  2.9618  -0.44958]] prediction: 1 Actual value:1\n",
      "X: [[ 4.5691e+00 -4.4552e+00  3.1769e+00  4.2961e-03]] prediction: 0 Actual value:0\n",
      "X: [[-3.6053  -5.974   10.0916  -0.82846]] prediction: 1 Actual value:1\n",
      "X: [[ 3.5499  8.6165 -3.2794 -1.2009]] prediction: 0 Actual value:0\n",
      "X: [[ 4.8851e+00  1.5995e+00 -2.9081e-04  1.6401e+00]] prediction: 0 Actual value:0\n",
      "X: [[ 4.2188   6.8162  -1.2804   0.76076]] prediction: 0 Actual value:0\n",
      "X: [[ 5.262   3.9834 -1.5572  1.0103]] prediction: 0 Actual value:0\n",
      "X: [[ 0.0096613  3.5612    -4.407     -4.4103   ]] prediction: 1 Actual value:1\n",
      "X: [[-2.5701 -6.8452  8.9999  2.1353]] prediction: 0 Actual value:1\n",
      "X: [[4.0405  0.51524 1.0279  1.106  ]] prediction: 0 Actual value:0\n",
      "X: [[ 2.1616   -6.8804    8.1517   -0.081048]] prediction: 0 Actual value:0\n",
      "X: [[ -4.4775 -13.0303  17.0834  -3.0345]] prediction: 1 Actual value:1\n",
      "X: [[ 0.74307 11.17    -1.3824  -4.0728 ]] prediction: 0 Actual value:0\n",
      "X: [[ 0.040498  8.5234    1.4461   -3.9306  ]] prediction: 0 Actual value:0\n",
      "X: [[ 1.3451   0.23589 -1.8785   1.3258 ]] prediction: 0 Actual value:1\n",
      "X: [[-3.8894  -7.8322   9.8208   0.47498]] prediction: 1 Actual value:1\n",
      "X: [[-2.2482  3.0915 -2.3969 -2.6711]] prediction: 1 Actual value:1\n",
      "X: [[-4.1958 -8.1819 12.1291 -1.6017]] prediction: 1 Actual value:1\n",
      "X: [[-1.4094  -2.1252  -0.10397 -0.19225]] prediction: 1 Actual value:1\n",
      "X: [[ 3.404    8.7261  -2.9915  -0.57242]] prediction: 0 Actual value:0\n",
      "X: [[ 3.7767  9.7794 -3.9075 -3.5323]] prediction: 0 Actual value:0\n",
      "X: [[-0.092194  0.39315  -0.32846  -0.13794 ]] prediction: 1 Actual value:1\n",
      "X: [[-2.6479 10.1374 -1.331  -5.4707]] prediction: 0 Actual value:0\n",
      "X: [[-0.55648  3.2136  -3.3085  -2.7965 ]] prediction: 1 Actual value:1\n",
      "X: [[ 5.4188 10.1457 -4.084  -3.6991]] prediction: 0 Actual value:0\n",
      "X: [[ 4.2406 -2.4852  1.608   0.7155]] prediction: 0 Actual value:0\n",
      "X: [[ 2.6463e+00 -4.8152e+00  6.3549e+00  3.0030e-03]] prediction: 0 Actual value:0\n",
      "X: [[4.9249  0.68906 0.77344 1.2095 ]] prediction: 0 Actual value:0\n",
      "X: [[ 4.9264   5.496   -2.4774  -0.50648]] prediction: 0 Actual value:0\n",
      "X: [[4.7432 2.1086 0.1368 1.6543]] prediction: 0 Actual value:0\n",
      "X: [[ 3.0009   5.8126  -2.2306  -0.66553]] prediction: 0 Actual value:0\n",
      "X: [[-2.0441   1.2271   0.18564 -1.091  ]] prediction: 1 Actual value:1\n",
      "X: [[ 1.9157   6.0816   0.23705 -2.0116 ]] prediction: 0 Actual value:0\n",
      "X: [[ 3.8832   6.4023  -2.432   -0.98363]] prediction: 0 Actual value:0\n",
      "X: [[ 4.3684  9.6718 -3.9606 -3.1625]] prediction: 0 Actual value:0\n",
      "X: [[ 4.2164  9.4607 -4.9288 -5.2366]] prediction: 0 Actual value:0\n",
      "X: [[-1.8343  -6.5907   5.6429   0.54998]] prediction: 1 Actual value:1\n",
      "X: [[-1.3968  -9.6698   9.4652  -0.34872]] prediction: 1 Actual value:1\n",
      "X: [[-1.3931   1.5664   7.5382   0.78403]] prediction: 0 Actual value:0\n",
      "X: [[-1.4106  -7.108    5.6454   0.31335]] prediction: 1 Actual value:1\n",
      "X: [[-2.4604  12.7302   0.91738 -7.6418 ]] prediction: 0 Actual value:0\n",
      "X: [[-5.0301   7.5032  -0.13396 -7.5034 ]] prediction: 1 Actual value:1\n",
      "X: [[4.3634  0.46351 1.4281  2.0202 ]] prediction: 0 Actual value:0\n",
      "X: [[ 3.5358   6.7086  -0.81857  0.47886]] prediction: 0 Actual value:0\n",
      "X: [[ 3.9102   6.065   -2.4534  -0.68234]] prediction: 0 Actual value:0\n",
      "X: [[ 0.96414  5.616    2.2138  -0.12501]] prediction: 0 Actual value:0\n",
      "X: [[-2.564   -1.7051   1.5026   0.32757]] prediction: 1 Actual value:1\n",
      "X: [[ 0.38251  6.8121   1.8128  -0.61251]] prediction: 0 Actual value:0\n",
      "X: [[ 1.7331  3.9544 -4.7412 -2.5017]] prediction: 1 Actual value:1\n",
      "X: [[-2.2173   1.4671  -0.72689 -1.1724 ]] prediction: 1 Actual value:1\n",
      "X: [[ 5.8782   5.9409  -2.8544  -0.60863]] prediction: 0 Actual value:0\n",
      "X: [[ 3.2697  -4.3414   3.6884  -0.29829]] prediction: 0 Actual value:0\n",
      "X: [[ 4.5645  -3.6275   2.8684   0.27714]] prediction: 0 Actual value:0\n",
      "X: [[ 3.2032   5.7588  -0.75345 -0.61251]] prediction: 0 Actual value:0\n",
      "X: [[ 0.23874  2.0879  -3.3522  -0.66553]] prediction: 1 Actual value:1\n",
      "X: [[-0.071503  3.7412   -4.5415   -4.2526  ]] prediction: 1 Actual value:1\n",
      "X: [[-2.899   -0.60424  2.6045   1.3776 ]] prediction: 1 Actual value:1\n",
      "X: [[ 3.359   9.8022 -3.8209 -3.7133]] prediction: 0 Actual value:0\n",
      "X: [[ 4.0215  -2.7004   2.4957   0.36636]] prediction: 0 Actual value:0\n",
      "X: [[-0.55355 -7.9233   6.7156   0.74394]] prediction: 1 Actual value:1\n",
      "X: [[-1.3    10.2678 -2.953  -5.8638]] prediction: 1 Actual value:0\n",
      "X: [[-4.8554  -5.9037  10.9818  -0.82199]] prediction: 1 Actual value:1\n",
      "X: [[ 5.591  10.4643 -4.3839 -4.3379]] prediction: 0 Actual value:0\n",
      "X: [[ -4.4861 -13.2889  17.3087  -3.2194]] prediction: 1 Actual value:1\n",
      "X: [[3.8584  0.78425 1.1033  1.7008 ]] prediction: 0 Actual value:0\n",
      "X: [[-4.577    3.4515   0.66719 -0.94742]] prediction: 1 Actual value:1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: [[4.4682  2.2907  0.95766 0.83058]] prediction: 0 Actual value:0\n",
      "X: [[ 1.1676   9.1566  -2.0867  -0.80647]] prediction: 0 Actual value:0\n",
      "X: [[-3.9172   2.6652   0.78886 -0.7819 ]] prediction: 1 Actual value:1\n",
      "X: [[ 4.3239 -4.8835  3.4356 -0.5776]] prediction: 0 Actual value:0\n",
      "X: [[-1.3389  1.552   7.0806  1.031 ]] prediction: 0 Actual value:0\n",
      "X: [[1.3114  4.5462  2.2935  0.22541]] prediction: 0 Actual value:0\n",
      "X: [[ 2.5503  -4.9518   6.3729  -0.41596]] prediction: 0 Actual value:0\n",
      "X: [[-1.2792   2.1376  -0.47584 -1.3974 ]] prediction: 1 Actual value:1\n",
      "X: [[-0.278   8.1881 -3.1338 -2.5276]] prediction: 0 Actual value:0\n",
      "X: [[-2.258   -9.3263   9.3727  -0.85949]] prediction: 1 Actual value:1\n",
      "X: [[ 4.3848 -3.0729  3.0423  1.2741]] prediction: 0 Actual value:0\n",
      "X: [[2.0153  1.8479  3.1375  0.42843]] prediction: 0 Actual value:0\n",
      "X: [[ 2.1265   6.8783   0.44784 -2.2224 ]] prediction: 0 Actual value:0\n",
      "X: [[-0.7351  1.7361 -1.4938 -1.1582]] prediction: 1 Actual value:1\n",
      "X: [[-4.3967   4.9601  -0.64892 -5.4719 ]] prediction: 1 Actual value:1\n",
      "X: [[ 0.84546  3.4826  -3.6307  -1.3961 ]] prediction: 1 Actual value:1\n",
      "Test Accuracy:93.76558603491272\n",
      "\n",
      "Accuracy metrics:\n",
      "Accuracy: 0.9376558603491272\n",
      "Precision: 0.9304347826086956\n",
      "Recall: 0.9596412556053812\n",
      "\n",
      "Confusion matrix:\n",
      "[[214, 16], [9, 162]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Testset accuracy, Confusion Matrix and Accuracy metrics\n",
    "def test(X_test, y_test):\n",
    "    print(\"Predictions on test data:\")\n",
    "    correct = 0\n",
    "    tp,fp,tn,fn = 0,0,0,0\n",
    "    for x,y in zip(X_test,y_test):\n",
    "        prediction = predict(x)\n",
    "        actual_value = int(np.array(y)[0][0])\n",
    "        print(\"X: \"+str(x)+\" prediction: \"+str(prediction)+\" Actual value:\"+str(actual_value))\n",
    "        if actual_value == prediction:\n",
    "          correct += 1\n",
    "        if actual_value == 0 and prediction == 0:\n",
    "          tp += 1\n",
    "        if actual_value == 1 and prediction ==1:\n",
    "          tn += 1\n",
    "        if actual_value == 0 and prediction ==1:\n",
    "          fn += 1\n",
    "        if actual_value == 1 and prediction == 0:\n",
    "          fp += 1  \n",
    "    test_accuracy =  correct/float(X_test.shape[0])*100.0\n",
    "    print(\"Test Accuracy:\"+str(test_accuracy))\n",
    "    print()\n",
    "    print(\"Accuracy metrics:\")\n",
    "    accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    print(\"Accuracy: \"+str(accuracy))\n",
    "    print(\"Precision: \"+str(precision))\n",
    "    print(\"Recall: \"+str(recall))\n",
    "    print()    \n",
    "    print(\"Confusion matrix:\")\n",
    "    cm = [[tp,fp],[fn,tn]]\n",
    "    print(cm)\n",
    "    print()\n",
    "    df_cm = pd.DataFrame(cm, range(2), range(2))\n",
    "    plt.figure(figsize = (10,7))\n",
    "    sns.heatmap(df_cm, annot=True)\n",
    "    plt.title('Confusion Matrix', fontsize = 20) \n",
    "    plt.xlabel('Predicted', fontsize = 15) \n",
    "    plt.ylabel('Actual', fontsize = 15) \n",
    "\n",
    "plt.show()\n",
    "test(X_test, y_test)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MLP",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
